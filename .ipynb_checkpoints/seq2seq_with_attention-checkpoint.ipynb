{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pandas as pd\n",
    "from fastText import load_model\n",
    "from matplotlib import pylab\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fasttext embeddings trained on train and val sets\n",
    "# ./fasttext skipgram -input input_text_file -output output_model -dim 128 (fastText-0.1.0)\n",
    "fasttext_model = load_model('word_vectors/fasttext_model.bin')\n",
    "num_dims = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab contains frequent words apperaing in the text along with their frequencies\n",
    "# minimum frequency = 6\n",
    "vocab_file = open('finished_files/vocab')\n",
    "# Store appearing words\n",
    "vocab_words = {}\n",
    "for line in vocab_file:\n",
    "    li = line.split()\n",
    "    if len(li) == 2:\n",
    "        word, freq = li\n",
    "        vocab_words[word] = freq\n",
    "# Final word to id dictionary    \n",
    "word2id = {}\n",
    "tokens = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
    "for token in tokens:\n",
    "    word2id[token] = len(word2id)\n",
    "# Retrieve words from fasttext model and keep only those which are also present in 'vocab'\n",
    "fasttext_words = fasttext_model.get_words()\n",
    "for word in fasttext_words:\n",
    "    if word in vocab_words:\n",
    "        word2id[word] = len(word2id)        \n",
    "vocab_size = len(word2id)\n",
    "# Reverse dictionary\n",
    "id2word = dict(zip(word2id.values(), word2id.keys()))\n",
    "# Embeddings\n",
    "embeddings = np.zeros((vocab_size, num_dims))\n",
    "# <pad> token vector contains all zeros. Rest sampled from a normal distribution\n",
    "mu, sigma = 0, 0.05\n",
    "for i in range(1, len(tokens)):\n",
    "    embeddings[i] = np.random.normal(mu, sigma, num_dims)\n",
    "# Get word vectors from fasttext model and store in embeddings matrix\n",
    "for i in range(len(tokens), vocab_size):\n",
    "    embeddings[i] = fasttext_model.get_word_vector(id2word[i])\n",
    "    \n",
    "del fasttext_model, vocab_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {}\n",
    "for i in range(10000):\n",
    "    temp[i] = id2word[i]\n",
    "id2word = temp\n",
    "embeddings = embeddings[:10000]\n",
    "word2id = dict(zip(id2word.values(), id2word.keys()))\n",
    "\n",
    "vocab_size = len(word2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_points = 500\n",
    "\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')\n",
    "two_d_embeddings = tsne.fit_transform(embeddings[1:num_points+1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def plot(embeddings, labels):\n",
    "    assert embeddings.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "    pylab.figure(figsize=(15,15))  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = embeddings[i,:]\n",
    "        pylab.scatter(x, y)\n",
    "        pylab.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')\n",
    "    pylab.show()\n",
    "\n",
    "words = [id2word[i] for i in range(1, num_points+1)]\n",
    "plot(two_d_embeddings, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "max_article_size = 50 #400\n",
    "max_abstract_size = 15 #100\n",
    "hidden_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self):\n",
    "        self.abstract = (None, None)\n",
    "        self.article = (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator: \n",
    "    \n",
    "    def __init__(self, batch_size, dataframe):\n",
    "        self.batch_size = batch_size\n",
    "        # train, valid, or test dataframe imported from csv\n",
    "        self.df = dataframe\n",
    "        self.generator = self.row_generator()\n",
    "        \n",
    "        \n",
    "    def row_generator(self):\n",
    "        for row in self.df.itertuples(index=False):\n",
    "            yield row\n",
    "            \n",
    "    def build_batch(self, rows):\n",
    "        # If number of rows less than batch size, get extra rows from the beginning of the dataframe\n",
    "        if len(rows) < self.batch_size:\n",
    "            temp_generator = self.row_generator()\n",
    "            for i in range(self.batch_size - len(rows)):\n",
    "                rows.append(self.get_row(temp_generator))\n",
    "                \n",
    "        # Get lengths of all the sequences in the batch upto max number of tokens\n",
    "        # + 1 is for the <eos> token\n",
    "        abstract_lengths = torch.cuda.LongTensor(\n",
    "            [len(row.abstract.split()[:max_abstract_size]) for row in rows]) + 1\n",
    "        article_lengths = torch.cuda.LongTensor(\n",
    "            [len(row.article.split()[:max_article_size]) for row in rows]) + 1 \n",
    "        abs_len = torch.max(abstract_lengths)\n",
    "        art_len = torch.max(article_lengths) \n",
    "        \n",
    "        # Variables containing abstracts and articles of the batch\n",
    "        abstracts = torch.cuda.LongTensor(abs_len, self.batch_size).fill_(0) # zero padding\n",
    "        articles = torch.cuda.LongTensor(art_len, self.batch_size).fill_(0) # zero padding\n",
    "        \n",
    "        # Sort rows in descending order of sequence (article) lengths\n",
    "        article_lengths, indices = torch.sort(article_lengths, descending=True)\n",
    "        rows = [rows[i] for i in indices]\n",
    "        abstract_lengths = torch.cuda.LongTensor([abstract_lengths[i] for i in indices])\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            # Tokenize abstract and take max_abstract_size number of tokens\n",
    "            tokens = rows[i].abstract.split()[:max_abstract_size]\n",
    "            tokens.append('<eos>')\n",
    "            # Convert each token to word index\n",
    "            # <unk> token index for unknown words\n",
    "            token_list = torch.LongTensor([word2id[token] if token in word2id \n",
    "                                           else word2id['<unk>'] for token in tokens])\n",
    "            # Store as column in abstracts variable with zero padding\n",
    "            abstracts[:,i][:len(token_list)] = token_list\n",
    "            \n",
    "            # Same for articles\n",
    "            tokens = rows[i].article.split()[:max_article_size]\n",
    "            tokens.append('<eos>')\n",
    "            token_list = torch.LongTensor([word2id[token] if token in word2id \n",
    "                                           else word2id['<unk>'] for token in tokens])\n",
    "            articles[:,i][:len(token_list)] = token_list\n",
    "            \n",
    "        batch = Batch()\n",
    "        batch.article = (Variable(articles), article_lengths)\n",
    "        batch.abstract = (Variable(abstracts), abstract_lengths)\n",
    "        return batch\n",
    "            \n",
    "    def get_row(self, generator):\n",
    "        row = generator.__next__()\n",
    "        while not isinstance(row.article, str):\n",
    "            row = generator.__next__()\n",
    "        return row\n",
    "        \n",
    "        \n",
    "    def get_batch(self):\n",
    "        rows = []\n",
    "        for b in range(self.batch_size):\n",
    "            try: rows.append(self.get_row(self.generator))\n",
    "            except StopIteration: break\n",
    "        if rows: return self.build_batch(rows)\n",
    "        else: raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (embed): Embedding(10000, 128)\n",
       "  (lstm): LSTM(128, 512, bidirectional=True)\n",
       "  (linear_transform): Linear(in_features=512, out_features=10000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Hidden layer and cell state of model\n",
    "        # Initialize before calling model\n",
    "        self.hidden = None\n",
    "        \n",
    "        # Lookup table that stores word embeddings\n",
    "        self.embed = nn.Embedding(vocab_size, num_dims).cuda()\n",
    "        self.embed.weight.data.copy_(torch.from_numpy(embeddings))\n",
    "        self.embed.weight.requires_grad = False\n",
    "        \n",
    "        # Pytorch lstm module\n",
    "        self.lstm = nn.LSTM(num_dims, hidden_size, num_layers=1, bidirectional=True)\n",
    "        self.lstm.cuda()\n",
    "        \n",
    "        # Linear transformation \n",
    "        self.linear_transform = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    # Funtion to initialize hidden layers\n",
    "    def init_hidden(self, batch_size, volatile=False):\n",
    "        tensor1 = torch.cuda.FloatTensor(1 * 2, batch_size, hidden_size).fill_(0)\n",
    "        tensor2 = torch.cuda.FloatTensor(1 * 2, batch_size, hidden_size).fill_(0)\n",
    "        return (Variable(tensor1, volatile=volatile), Variable(tensor2, volatile=volatile))\n",
    "    \n",
    "    def forward(self, articles, article_lengths):\n",
    "        # Embedding lookup\n",
    "        input = self.embed(articles)\n",
    "        # input to pack_padded_sequence can be of Txbx*\n",
    "        # where T is the length of longest sequence\n",
    "        # b is batch size\n",
    "        # batch is sorted in descending order of sequence lengths\n",
    "        #packed_input = pack_padded_sequence(input, list(article_lengths))\n",
    "        #packed_output, self.hidden = self.lstm(packed_input, self.hidden)\n",
    "        _, self.hidden = self.lstm(input, self.hidden)\n",
    "        \n",
    "        #output = self.linear_transform(self.hidden[0][hidden_layers - 1])\n",
    "        hidden = ((self.hidden[0][0] + self.hidden[0][1]), (self.hidden[1][0] + self.hidden[1][1]))\n",
    "        output = self.linear_transform(hidden[0])\n",
    "        \n",
    "        # Final hidden state\n",
    "        return hidden, output\n",
    "    \n",
    "encoder = Encoder(batch_size)\n",
    "encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embed): Embedding(10000, 128)\n",
       "  (lstm_cell): LSTMCell(128, 512)\n",
       "  (linear_transform): Linear(in_features=512, out_features=10000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # Lookup table that stores word embeddings\n",
    "        self.embed = nn.Embedding(vocab_size, num_dims).cuda()\n",
    "        self.embed.weight.data.copy_(torch.from_numpy(embeddings))\n",
    "        self.embed.weight.requires_grad = False\n",
    "    \n",
    "        self.hidden = None\n",
    "        self.lstm_cell = nn.LSTMCell(num_dims, hidden_size).cuda()\n",
    "\n",
    "        # Linear transformation \n",
    "        self.linear_transform = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input is a LongTensor of size batch_size\n",
    "        input = self.embed(input) \n",
    "\n",
    "        self.hidden = self.lstm_cell(input, self.hidden)\n",
    "\n",
    "        # output has shape (batch_size, vocab_size)\n",
    "        output = self.linear_transform(self.hidden[0])\n",
    "        return output\n",
    "    \n",
    "decoder = Decoder()\n",
    "decoder.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, param in decoder.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 4.0 #3.0, 3.5\n",
    "\n",
    "# Filter parameters that do not require gradients\n",
    "encoder_parameters = filter(lambda p: p.requires_grad, encoder.parameters())\n",
    "decoder_parameters = filter(lambda p: p.requires_grad, decoder.parameters())\n",
    "# Optimizers\n",
    "encoder_optimizer = torch.optim.SGD(encoder_parameters, lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.SGD(decoder_parameters, lr=learning_rate)\n",
    "# Loss function\n",
    "# Way to accumulate loss on sequences with variable lengths in batches :\n",
    "# size_average: By default, the losses are averaged over observations for each minibatch.\n",
    "# However, if the field size_average is set to False, the losses are instead summed for each minibatch. \n",
    "# Ignored if reduce is False.\n",
    "# Set size_average to False and divide the loss by the number of non-padding tokens.\n",
    "# ignore_index: Specifies a target value that is ignored and does not contribute to the input gradient. \n",
    "# When size_average is True, the loss is averaged over non-ignored targets.\n",
    "# Set ignore_index to the padding value\n",
    "loss_function = nn.CrossEntropyLoss(size_average=False, ignore_index=0).cuda() # 0 is the index of <pad>###\n",
    "\n",
    "def train_model(batch):\n",
    "    loss = 0\n",
    "    # Clear optimizer gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Clear hidden state of LSTM\n",
    "    encoder.hidden = encoder.init_hidden(batch_size)\n",
    "    # articles, abstracts are LongTensor vairables of shape (max_sequence_length, batch_size)\n",
    "    # containig word indices from the respective vocabs\n",
    "    # lengths are LongTensor varibles of shape batch_size containing\n",
    "    # lengths of all the sequences in the batch\n",
    "    articles, article_lengths = batch.article\n",
    "    abstracts, abstract_lengths = batch.abstract\n",
    "    hiddenT, output = encoder(articles, article_lengths)\n",
    "    \n",
    "    decoder.hidden = hiddenT\n",
    "    #input = Variable(torch.cuda.LongTensor(batch_size).fill_(2)) # 2 is the index of <sos>\n",
    "    input = most_likely(output, batch_size)\n",
    "\n",
    "    # Looping over all the sequences\n",
    "    for t in range(torch.max(abstract_lengths)):\n",
    "        output = decoder(input)\n",
    "        input = most_likely(output, batch_size)\n",
    "        loss += loss_function(output, abstracts[t])\n",
    "        \n",
    "    loss = loss/torch.sum(abstract_lengths)\n",
    "    loss.backward()\n",
    "    \n",
    "    #nn.utils.clip_grad_norm(encoder.parameters(), 0.5)\n",
    "    #nn.utils.clip_grad_norm(decoder.parameters(), 0.5)\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    # Initialize hidden_list for next batch of inputs\n",
    "    decoder.hidden_list = []\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loss(df):\n",
    "    batch_size = 1\n",
    "    generator = BatchGenerator(batch_size, df)\n",
    "    loss = 0\n",
    "    step = 0\n",
    "    while True:\n",
    "        try:\n",
    "            batch = generator.get_batch()\n",
    "            step += 1\n",
    "        except StopIteration: break\n",
    "        loss += calc_loss(batch, batch_size)\n",
    "    loss = loss/step\n",
    "    return loss\n",
    "\n",
    "def calc_loss(batch, batch_size):\n",
    "    loss = 0\n",
    "    encoder.hidden = encoder.init_hidden(batch_size, volatile=True)\n",
    "    articles, article_lengths = batch.article\n",
    "    abstracts, abstract_lengths = batch.abstract\n",
    "    \n",
    "    articles.volatile = True\n",
    "    abstracts.volatile = True\n",
    "        \n",
    "    hiddenT, output = encoder(articles, article_lengths) ###\n",
    "    for layer in range(hidden_layers):\n",
    "        decoder.hidden_list.append((hiddenT[0][layer], hiddenT[1][layer])) \n",
    "    #input = Variable(torch.cuda.LongTensor(batch_size).fill_(2), volatile=True)\n",
    "    input = most_likely(output, batch_size)\n",
    "    \n",
    "    for t in range(torch.max(abstract_lengths)):\n",
    "        output = decoder(input)\n",
    "        input = most_likely(output, batch_size)\n",
    "        loss += loss_function(output, abstracts[t])\n",
    "    loss = loss/torch.sum(abstract_lengths)\n",
    "    decoder.hidden_list = []\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_likely(output, batch_size):\n",
    "    if batch_size > 1:\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        output = softmax(output)\n",
    "        _, next_input = torch.topk(output, 1, dim=1)\n",
    "    else: \n",
    "        softmax = nn.Softmax(dim=0)\n",
    "        output = softmax(output)\n",
    "        _, next_input = torch.topk(output, 1)\n",
    "    return next_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "learning rate: 1.500000\n",
      "\n",
      "Average minibatch loss at step 2: 9.184\n",
      "Average minibatch loss at step 4: 9.103\n",
      "Average minibatch loss at step 6: 9.002\n",
      "Average minibatch loss at step 8: 8.866\n",
      "Average minibatch loss at step 10: 8.606\n",
      "Average minibatch loss at step 12: 7.718\n",
      "Average minibatch loss at step 14: 7.916\n",
      "Average minibatch loss at step 16: 7.962\n",
      "Average minibatch loss at step 18: 8.134\n",
      "Average minibatch loss at step 20: 7.511\n",
      "Average minibatch loss at step 22: 7.275\n",
      "Average minibatch loss at step 24: 7.185\n",
      "Average minibatch loss at step 26: 7.203\n",
      "Average minibatch loss at step 28: 6.955\n",
      "Average minibatch loss at step 30: 7.650\n",
      "Average minibatch loss at step 32: 7.061\n",
      "Average minibatch loss at step 34: 6.961\n",
      "Average minibatch loss at step 36: 7.327\n",
      "Average minibatch loss at step 38: 6.891\n",
      "Average minibatch loss at step 40: 7.030\n",
      "Average minibatch loss at step 42: 7.131\n",
      "Average minibatch loss at step 44: 6.769\n",
      "Average minibatch loss at step 46: 6.752\n",
      "Average minibatch loss at step 48: 6.714\n",
      "Average minibatch loss at step 50: 7.197\n",
      "Average minibatch loss at step 52: 6.832\n",
      "Average minibatch loss at step 54: 6.909\n",
      "Average minibatch loss at step 56: 6.803\n",
      "Average minibatch loss at step 58: 7.007\n",
      "Average minibatch loss at step 60: 6.733\n",
      "Average minibatch loss at step 62: 6.802\n",
      "Average minibatch loss at step 64: 6.692\n",
      "Average minibatch loss at step 66: 6.760\n",
      "Average minibatch loss at step 68: 6.891\n",
      "Average minibatch loss at step 70: 6.727\n",
      "Average minibatch loss at step 72: 6.681\n",
      "Average minibatch loss at step 74: 8.041\n",
      "Average minibatch loss at step 76: 7.489\n",
      "Average minibatch loss at step 78: 7.066\n",
      "Average minibatch loss at step 80: 6.883\n",
      "Average minibatch loss at step 82: 7.134\n",
      "Average minibatch loss at step 84: 6.700\n",
      "Average minibatch loss at step 86: 6.935\n",
      "Average minibatch loss at step 88: 7.338\n",
      "Average minibatch loss at step 90: 6.914\n",
      "Average minibatch loss at step 92: 6.775\n",
      "Average minibatch loss at step 94: 6.500\n",
      "Average minibatch loss at step 96: 6.693\n",
      "Average minibatch loss at step 98: 6.579\n",
      "Average minibatch loss at step 100: 6.664\n",
      "Average minibatch loss at step 102: 6.561\n",
      "Average minibatch loss at step 104: 6.663\n",
      "Average minibatch loss at step 106: 6.703\n",
      "Average minibatch loss at step 108: 6.481\n",
      "Average minibatch loss at step 110: 6.506\n",
      "Average minibatch loss at step 112: 6.301\n",
      "Average minibatch loss at step 114: 6.819\n",
      "Average minibatch loss at step 116: 6.947\n",
      "Average minibatch loss at step 118: 6.519\n",
      "Average minibatch loss at step 120: 6.574\n",
      "Average minibatch loss at step 122: 6.442\n",
      "Average minibatch loss at step 124: 6.565\n",
      "Average minibatch loss at step 126: 6.523\n",
      "Average minibatch loss at step 128: 6.587\n",
      "Average minibatch loss at step 130: 6.541\n",
      "Average minibatch loss at step 132: 6.542\n",
      "Average minibatch loss at step 134: 6.706\n",
      "Average minibatch loss at step 136: 6.541\n",
      "Average minibatch loss at step 138: 6.621\n",
      "Average minibatch loss at step 140: 6.353\n",
      "Average minibatch loss at step 142: 6.230\n",
      "Average minibatch loss at step 144: 6.352\n",
      "Average minibatch loss at step 146: 6.418\n",
      "Average minibatch loss at step 148: 6.820\n",
      "Average minibatch loss at step 150: 6.657\n",
      "Average minibatch loss at step 152: 6.532\n",
      "Average minibatch loss at step 154: 6.314\n",
      "Average minibatch loss at step 156: 6.418\n",
      "Average minibatch loss at step 158: 6.509\n",
      "Average minibatch loss at step 160: 6.435\n",
      "Average minibatch loss at step 162: 6.360\n",
      "Average minibatch loss at step 164: 6.979\n",
      "Average minibatch loss at step 166: 6.697\n",
      "Average minibatch loss at step 168: 6.446\n",
      "Average minibatch loss at step 170: 6.474\n",
      "Average minibatch loss at step 172: 6.202\n",
      "Average minibatch loss at step 174: 6.272\n",
      "Average minibatch loss at step 176: 6.635\n",
      "Average minibatch loss at step 178: 6.475\n",
      "Average minibatch loss at step 180: 6.303\n",
      "Average minibatch loss at step 182: 6.319\n",
      "Average minibatch loss at step 184: 6.660\n",
      "Average minibatch loss at step 186: 6.487\n",
      "Average minibatch loss at step 188: 6.663\n",
      "Average minibatch loss at step 190: 6.199\n",
      "Average minibatch loss at step 192: 6.324\n",
      "Average minibatch loss at step 194: 6.529\n",
      "Average minibatch loss at step 196: 6.695\n",
      "Average minibatch loss at step 198: 6.363\n",
      "Average minibatch loss at step 200: 6.361\n",
      "Average minibatch loss at step 202: 6.422\n",
      "Average minibatch loss at step 204: 6.618\n",
      "Average minibatch loss at step 206: 6.190\n",
      "Average minibatch loss at step 208: 6.230\n",
      "Average minibatch loss at step 210: 6.740\n",
      "Average minibatch loss at step 212: 6.264\n",
      "Average minibatch loss at step 214: 6.247\n",
      "Average minibatch loss at step 216: 6.455\n",
      "Average minibatch loss at step 218: 6.449\n",
      "Average minibatch loss at step 220: 6.263\n",
      "Average minibatch loss at step 222: 6.135\n",
      "Average minibatch loss at step 224: 6.323\n",
      "Average minibatch loss at step 226: 6.595\n",
      "Average minibatch loss at step 228: 6.364\n",
      "Average minibatch loss at step 230: 6.275\n",
      "Average minibatch loss at step 232: 6.768\n",
      "Average minibatch loss at step 234: 6.445\n",
      "Average minibatch loss at step 236: 6.133\n",
      "Average minibatch loss at step 238: 6.142\n",
      "Average minibatch loss at step 240: 6.762\n",
      "Average minibatch loss at step 242: 6.322\n",
      "Average minibatch loss at step 244: 6.189\n",
      "Average minibatch loss at step 246: 6.198\n",
      "Average minibatch loss at step 248: 6.662\n",
      "Average minibatch loss at step 250: 6.224\n",
      "Average minibatch loss at step 252: 6.377\n",
      "Average minibatch loss at step 254: 6.151\n",
      "Average minibatch loss at step 256: 6.194\n",
      "Average minibatch loss at step 258: 6.443\n",
      "Average minibatch loss at step 260: 6.300\n",
      "Average minibatch loss at step 262: 6.184\n",
      "Average minibatch loss at step 264: 6.245\n",
      "Average minibatch loss at step 266: 6.616\n",
      "Average minibatch loss at step 268: 6.343\n",
      "Average minibatch loss at step 270: 6.148\n",
      "Average minibatch loss at step 272: 6.502\n",
      "Average minibatch loss at step 274: 6.168\n",
      "Average minibatch loss at step 276: 6.161\n",
      "Average minibatch loss at step 278: 6.347\n",
      "Average minibatch loss at step 280: 6.453\n",
      "Average minibatch loss at step 282: 6.120\n",
      "Average minibatch loss at step 284: 6.265\n",
      "Average minibatch loss at step 286: 6.104\n",
      "Average minibatch loss at step 288: 6.255\n",
      "Average minibatch loss at step 290: 6.241\n",
      "Average minibatch loss at step 292: 6.452\n",
      "Average minibatch loss at step 294: 6.159\n",
      "Average minibatch loss at step 296: 6.226\n",
      "Average minibatch loss at step 298: 6.452\n",
      "Average minibatch loss at step 300: 6.163\n",
      "Average minibatch loss at step 302: 6.051\n",
      "Average minibatch loss at step 304: 6.091\n",
      "Average minibatch loss at step 306: 6.602\n",
      "Average minibatch loss at step 308: 6.213\n",
      "Average minibatch loss at step 310: 6.233\n",
      "Average minibatch loss at step 312: 6.317\n",
      "Average minibatch loss at step 314: 6.117\n",
      "Average minibatch loss at step 316: 6.169\n",
      "Average minibatch loss at step 318: 6.399\n",
      "Average minibatch loss at step 320: 6.112\n",
      "Average minibatch loss at step 322: 6.170\n",
      "Average minibatch loss at step 324: 6.518\n",
      "Average minibatch loss at step 326: 6.125\n",
      "Average minibatch loss at step 328: 6.175\n",
      "Average minibatch loss at step 330: 6.396\n",
      "Average minibatch loss at step 332: 6.131\n",
      "Average minibatch loss at step 334: 5.987\n",
      "Average minibatch loss at step 336: 5.878\n",
      "Average minibatch loss at step 338: 6.157\n",
      "Average minibatch loss at step 340: 6.418\n",
      "Average minibatch loss at step 342: 6.131\n",
      "Average minibatch loss at step 344: 6.250\n",
      "Average minibatch loss at step 346: 6.065\n",
      "Average minibatch loss at step 348: 6.143\n",
      "Average minibatch loss at step 350: 6.094\n",
      "Average minibatch loss at step 352: 6.173\n",
      "Average minibatch loss at step 354: 6.283\n",
      "Average minibatch loss at step 356: 6.462\n",
      "Average minibatch loss at step 358: 6.154\n",
      "Average minibatch loss at step 360: 6.218\n",
      "Average minibatch loss at step 362: 6.236\n",
      "Average minibatch loss at step 364: 6.096\n",
      "Average minibatch loss at step 366: 6.028\n",
      "Average minibatch loss at step 368: 6.007\n",
      "Average minibatch loss at step 370: 6.880\n",
      "Average minibatch loss at step 372: 6.732\n",
      "Average minibatch loss at step 374: 6.189\n",
      "Average minibatch loss at step 376: 6.196\n",
      "Average minibatch loss at step 378: 5.998\n",
      "Average minibatch loss at step 380: 6.047\n",
      "Average minibatch loss at step 382: 5.991\n",
      "Average minibatch loss at step 384: 6.575\n",
      "Average minibatch loss at step 386: 6.188\n",
      "Average minibatch loss at step 388: 6.266\n",
      "Average minibatch loss at step 390: 6.203\n",
      "Average minibatch loss at step 392: 6.161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 394: 6.198\n",
      "Average minibatch loss at step 396: 6.131\n",
      "Average minibatch loss at step 398: 6.484\n",
      "Average minibatch loss at step 400: 5.879\n",
      "Average minibatch loss at step 402: 6.045\n",
      "Average minibatch loss at step 404: 6.131\n",
      "Average minibatch loss at step 406: 6.451\n",
      "Average minibatch loss at step 408: 6.183\n",
      "Average minibatch loss at step 410: 5.933\n",
      "Average minibatch loss at step 412: 6.102\n",
      "Average minibatch loss at step 414: 5.992\n",
      "Average minibatch loss at step 416: 6.304\n",
      "Average minibatch loss at step 418: 6.405\n",
      "Average minibatch loss at step 420: 6.198\n",
      "Average minibatch loss at step 422: 6.060\n",
      "Average minibatch loss at step 424: 6.112\n",
      "Average minibatch loss at step 426: 6.455\n",
      "Average minibatch loss at step 428: 5.939\n",
      "Average minibatch loss at step 430: 5.915\n",
      "Average minibatch loss at step 432: 6.390\n",
      "Average minibatch loss at step 434: 6.668\n",
      "Average minibatch loss at step 436: 6.144\n",
      "Average minibatch loss at step 438: 6.190\n",
      "Average minibatch loss at step 440: 6.116\n",
      "Average minibatch loss at step 442: 5.896\n",
      "Average minibatch loss at step 444: 6.243\n",
      "Average minibatch loss at step 446: 6.007\n",
      "Average minibatch loss at step 448: 6.093\n",
      "Average minibatch loss at step 450: 6.199\n",
      "Average minibatch loss at step 452: 6.249\n",
      "Average minibatch loss at step 454: 6.261\n",
      "Average minibatch loss at step 456: 6.146\n",
      "Average minibatch loss at step 458: 6.173\n",
      "Average minibatch loss at step 460: 6.033\n",
      "Average minibatch loss at step 462: 6.052\n",
      "Average minibatch loss at step 464: 5.983\n",
      "Average minibatch loss at step 466: 6.599\n",
      "Average minibatch loss at step 468: 6.191\n",
      "Average minibatch loss at step 470: 6.214\n",
      "Average minibatch loss at step 472: 6.106\n",
      "Average minibatch loss at step 474: 5.901\n",
      "Average minibatch loss at step 476: 6.019\n",
      "Average minibatch loss at step 478: 6.402\n",
      "Average minibatch loss at step 480: 6.033\n",
      "Average minibatch loss at step 482: 6.038\n",
      "Average minibatch loss at step 484: 6.165\n",
      "Average minibatch loss at step 486: 6.081\n",
      "Average minibatch loss at step 488: 6.359\n",
      "Average minibatch loss at step 490: 6.146\n",
      "Average minibatch loss at step 492: 5.973\n",
      "Average minibatch loss at step 494: 6.247\n",
      "Average minibatch loss at step 496: 5.784\n",
      "Average minibatch loss at step 498: 5.960\n",
      "Average minibatch loss at step 500: 6.311\n",
      "Average minibatch loss at step 502: 6.180\n",
      "Average minibatch loss at step 504: 6.149\n",
      "Average minibatch loss at step 506: 5.977\n",
      "Average minibatch loss at step 508: 6.160\n",
      "Average minibatch loss at step 510: 6.251\n",
      "Average minibatch loss at step 512: 5.922\n",
      "Average minibatch loss at step 514: 6.002\n",
      "Average minibatch loss at step 516: 6.151\n",
      "Average minibatch loss at step 518: 6.182\n",
      "Average minibatch loss at step 520: 6.124\n",
      "Average minibatch loss at step 522: 6.108\n",
      "Average minibatch loss at step 524: 5.896\n",
      "Average minibatch loss at step 526: 5.909\n",
      "Average minibatch loss at step 528: 6.149\n",
      "Average minibatch loss at step 530: 6.022\n",
      "Average minibatch loss at step 532: 6.041\n",
      "Average minibatch loss at step 534: 6.130\n",
      "Average minibatch loss at step 536: 6.110\n",
      "Average minibatch loss at step 538: 5.882\n",
      "Average minibatch loss at step 540: 6.013\n",
      "Average minibatch loss at step 542: 5.922\n",
      "Average minibatch loss at step 544: 5.968\n",
      "Average minibatch loss at step 546: 6.231\n",
      "Average minibatch loss at step 548: 6.482\n",
      "Average minibatch loss at step 550: 6.055\n",
      "Average minibatch loss at step 552: 6.060\n",
      "Average minibatch loss at step 554: 6.099\n",
      "Average minibatch loss at step 556: 5.921\n",
      "Average minibatch loss at step 558: 5.881\n",
      "Average minibatch loss at step 560: 5.816\n",
      "Average minibatch loss at step 562: 6.042\n",
      "Average minibatch loss at step 564: 5.979\n",
      "Average minibatch loss at step 566: 6.097\n",
      "Average minibatch loss at step 568: 6.039\n",
      "Average minibatch loss at step 570: 6.059\n",
      "Average minibatch loss at step 572: 6.244\n",
      "Average minibatch loss at step 574: 5.895\n",
      "Average minibatch loss at step 576: 5.875\n",
      "Average minibatch loss at step 578: 6.248\n",
      "Average minibatch loss at step 580: 6.081\n",
      "Average minibatch loss at step 582: 6.012\n",
      "Average minibatch loss at step 584: 6.242\n",
      "Average minibatch loss at step 586: 6.074\n",
      "Average minibatch loss at step 588: 5.842\n",
      "Average minibatch loss at step 590: 6.194\n",
      "Average minibatch loss at step 592: 5.826\n",
      "Average minibatch loss at step 594: 6.010\n",
      "Average minibatch loss at step 596: 5.963\n",
      "Average minibatch loss at step 598: 5.979\n",
      "Average minibatch loss at step 600: 6.070\n",
      "Average minibatch loss at step 602: 6.011\n",
      "Average minibatch loss at step 604: 6.278\n",
      "Average minibatch loss at step 606: 6.000\n",
      "Average minibatch loss at step 608: 5.903\n",
      "Average minibatch loss at step 610: 5.961\n",
      "Average minibatch loss at step 612: 6.083\n",
      "Average minibatch loss at step 614: 6.288\n",
      "Average minibatch loss at step 616: 6.023\n",
      "Average minibatch loss at step 618: 6.133\n",
      "Average minibatch loss at step 620: 5.856\n",
      "Average minibatch loss at step 622: 6.048\n",
      "Average minibatch loss at step 624: 5.826\n",
      "Average minibatch loss at step 626: 5.963\n",
      "Average minibatch loss at step 628: 6.294\n",
      "Average minibatch loss at step 630: 5.967\n",
      "Average minibatch loss at step 632: 6.094\n",
      "Average minibatch loss at step 634: 5.843\n",
      "Average minibatch loss at step 636: 5.935\n",
      "Average minibatch loss at step 638: 6.114\n",
      "Average minibatch loss at step 640: 5.848\n",
      "Average minibatch loss at step 642: 5.995\n",
      "Average minibatch loss at step 644: 6.263\n",
      "Average minibatch loss at step 646: 6.004\n",
      "Average minibatch loss at step 648: 6.010\n",
      "Average minibatch loss at step 650: 6.036\n",
      "Average minibatch loss at step 652: 5.894\n",
      "Average minibatch loss at step 654: 5.961\n",
      "Average minibatch loss at step 656: 5.828\n",
      "Average minibatch loss at step 658: 5.943\n",
      "Average minibatch loss at step 660: 6.150\n",
      "Average minibatch loss at step 662: 5.957\n",
      "Average minibatch loss at step 664: 6.006\n",
      "Average minibatch loss at step 666: 5.783\n",
      "Average minibatch loss at step 668: 6.055\n",
      "Average minibatch loss at step 670: 6.110\n",
      "Average minibatch loss at step 672: 5.813\n",
      "Average minibatch loss at step 674: 5.962\n",
      "Average minibatch loss at step 676: 6.186\n",
      "Average minibatch loss at step 678: 5.958\n",
      "Average minibatch loss at step 680: 5.998\n",
      "Average minibatch loss at step 682: 6.069\n",
      "Average minibatch loss at step 684: 5.820\n",
      "Average minibatch loss at step 686: 6.037\n",
      "Average minibatch loss at step 688: 5.887\n",
      "Average minibatch loss at step 690: 5.933\n",
      "Average minibatch loss at step 692: 5.942\n",
      "Average minibatch loss at step 694: 6.080\n",
      "Average minibatch loss at step 696: 6.089\n",
      "Average minibatch loss at step 698: 5.810\n",
      "Average minibatch loss at step 700: 5.894\n",
      "Average minibatch loss at step 702: 5.844\n",
      "Average minibatch loss at step 704: 5.812\n",
      "Average minibatch loss at step 706: 6.098\n",
      "Average minibatch loss at step 708: 6.148\n",
      "Average minibatch loss at step 710: 5.931\n",
      "Average minibatch loss at step 712: 6.049\n",
      "Average minibatch loss at step 714: 6.034\n",
      "Average minibatch loss at step 716: 5.820\n",
      "Average minibatch loss at step 718: 5.873\n",
      "Average minibatch loss at step 720: 5.813\n",
      "Average minibatch loss at step 722: 5.899\n",
      "Average minibatch loss at step 724: 5.910\n",
      "Average minibatch loss at step 726: 5.899\n",
      "Average minibatch loss at step 728: 6.033\n",
      "Average minibatch loss at step 730: 5.926\n",
      "Average minibatch loss at step 732: 5.897\n",
      "Average minibatch loss at step 734: 5.825\n",
      "Average minibatch loss at step 736: 5.879\n",
      "Average minibatch loss at step 738: 5.894\n",
      "Average minibatch loss at step 740: 6.050\n",
      "Average minibatch loss at step 742: 6.006\n",
      "Average minibatch loss at step 744: 5.967\n",
      "Average minibatch loss at step 746: 6.044\n",
      "Average minibatch loss at step 748: 5.862\n",
      "Average minibatch loss at step 750: 5.782\n",
      "Average minibatch loss at step 752: 5.727\n",
      "Average minibatch loss at step 754: 5.901\n",
      "Average minibatch loss at step 756: 5.940\n",
      "Average minibatch loss at step 758: 5.973\n",
      "Average minibatch loss at step 760: 6.059\n",
      "Average minibatch loss at step 762: 6.094\n",
      "Average minibatch loss at step 764: 5.934\n",
      "Average minibatch loss at step 766: 5.854\n",
      "Average minibatch loss at step 768: 5.741\n",
      "Average minibatch loss at step 770: 5.888\n",
      "Average minibatch loss at step 772: 6.043\n",
      "Average minibatch loss at step 774: 6.141\n",
      "Average minibatch loss at step 776: 5.955\n",
      "Average minibatch loss at step 778: 5.995\n",
      "Average minibatch loss at step 780: 5.771\n",
      "Average minibatch loss at step 782: 5.726\n",
      "Average minibatch loss at step 784: 5.664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 786: 6.077\n",
      "Average minibatch loss at step 788: 5.892\n",
      "Average minibatch loss at step 790: 5.876\n",
      "Average minibatch loss at step 792: 5.953\n",
      "Average minibatch loss at step 794: 5.811\n",
      "Average minibatch loss at step 796: 6.105\n",
      "Average minibatch loss at step 798: 5.823\n",
      "Average minibatch loss at step 800: 6.140\n",
      "Average minibatch loss at step 802: 6.014\n",
      "Average minibatch loss at step 804: 6.278\n",
      "Average minibatch loss at step 806: 5.878\n",
      "Average minibatch loss at step 808: 6.020\n",
      "Average minibatch loss at step 810: 6.209\n",
      "Average minibatch loss at step 812: 5.757\n",
      "Average minibatch loss at step 814: 5.873\n",
      "Average minibatch loss at step 816: 6.041\n",
      "Average minibatch loss at step 818: 5.853\n",
      "Average minibatch loss at step 820: 5.876\n",
      "Average minibatch loss at step 822: 5.918\n",
      "Average minibatch loss at step 824: 5.923\n",
      "Average minibatch loss at step 826: 5.864\n",
      "Average minibatch loss at step 828: 5.955\n",
      "Average minibatch loss at step 830: 5.866\n",
      "Average minibatch loss at step 832: 5.765\n",
      "Average minibatch loss at step 834: 5.873\n",
      "Average minibatch loss at step 836: 6.042\n",
      "Average minibatch loss at step 838: 5.964\n",
      "Average minibatch loss at step 840: 6.177\n",
      "Average minibatch loss at step 842: 5.989\n",
      "Average minibatch loss at step 844: 5.770\n",
      "Average minibatch loss at step 846: 5.939\n",
      "Average minibatch loss at step 848: 5.764\n",
      "Average minibatch loss at step 850: 5.947\n",
      "Average minibatch loss at step 852: 6.004\n",
      "Average minibatch loss at step 854: 5.897\n",
      "Average minibatch loss at step 856: 5.922\n",
      "Average minibatch loss at step 858: 5.794\n",
      "Average minibatch loss at step 860: 5.860\n",
      "Average minibatch loss at step 862: 5.751\n",
      "Average minibatch loss at step 864: 5.739\n",
      "Average minibatch loss at step 866: 5.883\n",
      "Average minibatch loss at step 868: 6.306\n",
      "Average minibatch loss at step 870: 5.986\n",
      "Average minibatch loss at step 872: 6.055\n",
      "Average minibatch loss at step 874: 6.008\n",
      "Average minibatch loss at step 876: 5.726\n",
      "Average minibatch loss at step 878: 5.733\n",
      "Average minibatch loss at step 880: 5.743\n",
      "Average minibatch loss at step 882: 6.009\n",
      "Average minibatch loss at step 884: 5.850\n",
      "Average minibatch loss at step 886: 5.879\n",
      "Average minibatch loss at step 888: 5.983\n",
      "Average minibatch loss at step 890: 5.919\n",
      "Average minibatch loss at step 892: 5.970\n",
      "Average minibatch loss at step 894: 5.848\n",
      "Average minibatch loss at step 896: 5.745\n",
      "Average minibatch loss at step 898: 5.918\n",
      "Average minibatch loss at step 900: 6.110\n",
      "Average minibatch loss at step 902: 6.014\n",
      "Average minibatch loss at step 904: 5.888\n",
      "Average minibatch loss at step 906: 5.981\n",
      "Average minibatch loss at step 908: 5.704\n",
      "Average minibatch loss at step 910: 5.711\n",
      "Average minibatch loss at step 912: 5.797\n",
      "Average minibatch loss at step 914: 5.989\n",
      "Average minibatch loss at step 916: 5.920\n",
      "Average minibatch loss at step 918: 5.894\n",
      "Average minibatch loss at step 920: 5.941\n",
      "Average minibatch loss at step 922: 5.810\n",
      "Average minibatch loss at step 924: 5.812\n",
      "Average minibatch loss at step 926: 5.691\n",
      "Average minibatch loss at step 928: 5.740\n",
      "Average minibatch loss at step 930: 5.869\n",
      "Average minibatch loss at step 932: 6.062\n",
      "Average minibatch loss at step 934: 5.888\n",
      "Average minibatch loss at step 936: 5.898\n",
      "Average minibatch loss at step 938: 5.995\n",
      "Average minibatch loss at step 940: 5.743\n",
      "Average minibatch loss at step 942: 5.744\n",
      "Average minibatch loss at step 944: 5.760\n",
      "Average minibatch loss at step 946: 5.874\n",
      "Average minibatch loss at step 948: 5.823\n",
      "Average minibatch loss at step 950: 5.907\n",
      "Average minibatch loss at step 952: 5.983\n",
      "Average minibatch loss at step 954: 5.865\n",
      "Average minibatch loss at step 956: 5.823\n",
      "Average minibatch loss at step 958: 5.699\n",
      "Average minibatch loss at step 960: 5.758\n",
      "Average minibatch loss at step 962: 6.102\n",
      "Average minibatch loss at step 964: 5.963\n",
      "Average minibatch loss at step 966: 5.833\n",
      "Average minibatch loss at step 968: 5.896\n",
      "Average minibatch loss at step 970: 5.947\n",
      "Average minibatch loss at step 972: 5.713\n",
      "Average minibatch loss at step 974: 5.813\n",
      "Average minibatch loss at step 976: 5.775\n",
      "Average minibatch loss at step 978: 5.867\n",
      "Average minibatch loss at step 980: 5.849\n",
      "Average minibatch loss at step 982: 5.909\n",
      "Average minibatch loss at step 984: 5.868\n",
      "Average minibatch loss at step 986: 5.656\n",
      "Average minibatch loss at step 988: 5.769\n",
      "Average minibatch loss at step 990: 5.646\n",
      "Average minibatch loss at step 992: 5.581\n",
      "Average minibatch loss at step 994: 5.772\n",
      "Average minibatch loss at step 996: 5.931\n",
      "Average minibatch loss at step 998: 5.871\n",
      "Average minibatch loss at step 1000: 6.162\n",
      "Average minibatch loss at step 1002: 6.258\n",
      "Average minibatch loss at step 1004: 5.712\n",
      "Average minibatch loss at step 1006: 5.884\n",
      "Average minibatch loss at step 1008: 5.978\n",
      "Average minibatch loss at step 1010: 5.840\n",
      "Average minibatch loss at step 1012: 5.797\n",
      "Average minibatch loss at step 1014: 5.791\n",
      "Average minibatch loss at step 1016: 5.844\n",
      "Average minibatch loss at step 1018: 5.662\n",
      "Average minibatch loss at step 1020: 5.768\n",
      "Average minibatch loss at step 1022: 5.694\n",
      "Average minibatch loss at step 1024: 5.673\n",
      "Average minibatch loss at step 1026: 5.774\n",
      "Average minibatch loss at step 1028: 5.899\n",
      "Average minibatch loss at step 1030: 5.805\n",
      "Average minibatch loss at step 1032: 5.808\n",
      "Average minibatch loss at step 1034: 5.920\n",
      "Average minibatch loss at step 1036: 5.634\n",
      "Average minibatch loss at step 1038: 5.796\n",
      "Average minibatch loss at step 1040: 5.564\n",
      "Average minibatch loss at step 1042: 5.835\n",
      "Average minibatch loss at step 1044: 5.903\n",
      "Average minibatch loss at step 1046: 5.834\n",
      "Average minibatch loss at step 1048: 5.913\n",
      "Average minibatch loss at step 1050: 5.671\n",
      "Average minibatch loss at step 1052: 5.784\n",
      "Average minibatch loss at step 1054: 5.719\n",
      "Average minibatch loss at step 1056: 6.098\n",
      "Average minibatch loss at step 1058: 5.907\n",
      "Average minibatch loss at step 1060: 5.976\n",
      "Average minibatch loss at step 1062: 5.809\n",
      "Average minibatch loss at step 1064: 5.825\n",
      "Average minibatch loss at step 1066: 5.899\n",
      "Average minibatch loss at step 1068: 5.660\n",
      "Average minibatch loss at step 1070: 5.650\n",
      "Average minibatch loss at step 1072: 5.595\n",
      "Average minibatch loss at step 1074: 5.762\n",
      "Average minibatch loss at step 1076: 5.795\n",
      "Average minibatch loss at step 1078: 5.781\n",
      "Average minibatch loss at step 1080: 5.841\n",
      "Average minibatch loss at step 1082: 5.670\n",
      "Average minibatch loss at step 1084: 5.745\n",
      "Average minibatch loss at step 1086: 5.652\n",
      "Average minibatch loss at step 1088: 5.578\n",
      "Average minibatch loss at step 1090: 5.778\n",
      "Average minibatch loss at step 1092: 5.938\n",
      "Average minibatch loss at step 1094: 5.826\n",
      "Average minibatch loss at step 1096: 5.847\n",
      "Average minibatch loss at step 1098: 6.184\n",
      "Average minibatch loss at step 1100: 5.923\n",
      "Average minibatch loss at step 1102: 5.679\n",
      "Average minibatch loss at step 1104: 5.691\n",
      "Average minibatch loss at step 1106: 5.786\n",
      "Average minibatch loss at step 1108: 5.768\n",
      "Average minibatch loss at step 1110: 5.830\n",
      "Average minibatch loss at step 1112: 5.936\n",
      "Average minibatch loss at step 1114: 5.696\n",
      "Average minibatch loss at step 1116: 5.775\n",
      "Average minibatch loss at step 1118: 5.702\n",
      "Average minibatch loss at step 1120: 5.636\n",
      "Average minibatch loss at step 1122: 5.764\n",
      "Average minibatch loss at step 1124: 5.880\n",
      "Average minibatch loss at step 1126: 5.772\n",
      "Average minibatch loss at step 1128: 5.835\n",
      "Average minibatch loss at step 1130: 5.863\n",
      "Average minibatch loss at step 1132: 5.608\n",
      "Average minibatch loss at step 1134: 5.616\n",
      "Average minibatch loss at step 1136: 5.784\n",
      "Average minibatch loss at step 1138: 5.776\n",
      "Average minibatch loss at step 1140: 5.769\n",
      "Average minibatch loss at step 1142: 5.946\n",
      "Average minibatch loss at step 1144: 5.805\n",
      "Average minibatch loss at step 1146: 5.611\n",
      "Average minibatch loss at step 1148: 5.705\n",
      "Average minibatch loss at step 1150: 5.603\n",
      "Average minibatch loss at step 1152: 5.593\n",
      "Average minibatch loss at step 1154: 5.734\n",
      "Average minibatch loss at step 1156: 5.854\n",
      "Average minibatch loss at step 1158: 5.745\n",
      "Average minibatch loss at step 1160: 5.764\n",
      "Average minibatch loss at step 1162: 5.855\n",
      "Average minibatch loss at step 1164: 5.608\n",
      "Average minibatch loss at step 1166: 5.615\n",
      "Average minibatch loss at step 1168: 5.647\n",
      "Average minibatch loss at step 1170: 5.711\n",
      "Average minibatch loss at step 1172: 5.746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 1174: 5.751\n",
      "Average minibatch loss at step 1176: 5.803\n",
      "Average minibatch loss at step 1178: 5.669\n",
      "Average minibatch loss at step 1180: 5.761\n",
      "Average minibatch loss at step 1182: 5.621\n",
      "Average minibatch loss at step 1184: 5.542\n",
      "Average minibatch loss at step 1186: 5.740\n",
      "Average minibatch loss at step 1188: 5.824\n",
      "Average minibatch loss at step 1190: 5.753\n",
      "Average minibatch loss at step 1192: 5.802\n",
      "Average minibatch loss at step 1194: 5.861\n",
      "Average minibatch loss at step 1196: 5.611\n",
      "Average minibatch loss at step 1198: 5.609\n",
      "Average minibatch loss at step 1200: 5.600\n",
      "Average minibatch loss at step 1202: 5.716\n",
      "Average minibatch loss at step 1204: 5.795\n",
      "Average minibatch loss at step 1206: 5.749\n",
      "Average minibatch loss at step 1208: 5.830\n",
      "Average minibatch loss at step 1210: 5.620\n",
      "Average minibatch loss at step 1212: 5.696\n",
      "Average minibatch loss at step 1214: 5.597\n",
      "Average minibatch loss at step 1216: 5.490\n",
      "Average minibatch loss at step 1218: 5.726\n",
      "Average minibatch loss at step 1220: 5.952\n",
      "Average minibatch loss at step 1222: 5.752\n",
      "Average minibatch loss at step 1224: 5.836\n",
      "Average minibatch loss at step 1226: 5.855\n",
      "Average minibatch loss at step 1228: 5.607\n",
      "Average minibatch loss at step 1230: 5.611\n",
      "Average minibatch loss at step 1232: 5.677\n",
      "Average minibatch loss at step 1234: 5.730\n",
      "Average minibatch loss at step 1236: 5.799\n",
      "Average minibatch loss at step 1238: 5.698\n",
      "Average minibatch loss at step 1240: 5.772\n",
      "Average minibatch loss at step 1242: 5.602\n",
      "Average minibatch loss at step 1244: 5.707\n",
      "Average minibatch loss at step 1246: 5.602\n",
      "Average minibatch loss at step 1248: 5.522\n",
      "Average minibatch loss at step 1250: 5.695\n",
      "Average minibatch loss at step 1252: 5.872\n",
      "Average minibatch loss at step 1254: 5.730\n",
      "Average minibatch loss at step 1256: 5.749\n",
      "Average minibatch loss at step 1258: 5.819\n",
      "Average minibatch loss at step 1260: 5.548\n",
      "Average minibatch loss at step 1262: 5.652\n",
      "Average minibatch loss at step 1264: 5.534\n",
      "Average minibatch loss at step 1266: 5.777\n",
      "Average minibatch loss at step 1268: 5.774\n",
      "Average minibatch loss at step 1270: 6.274\n",
      "Average minibatch loss at step 1272: 5.868\n",
      "Average minibatch loss at step 1274: 5.618\n",
      "Average minibatch loss at step 1276: 5.673\n",
      "Average minibatch loss at step 1278: 5.845\n",
      "Average minibatch loss at step 1280: 5.611\n",
      "Average minibatch loss at step 1282: 5.712\n",
      "Average minibatch loss at step 1284: 5.809\n",
      "Average minibatch loss at step 1286: 5.704\n",
      "Average minibatch loss at step 1288: 5.760\n",
      "Average minibatch loss at step 1290: 5.847\n",
      "Average minibatch loss at step 1292: 5.612\n",
      "Average minibatch loss at step 1294: 5.680\n",
      "Average minibatch loss at step 1296: 5.708\n",
      "Average minibatch loss at step 1298: 5.700\n",
      "Average minibatch loss at step 1300: 5.799\n",
      "Average minibatch loss at step 1302: 5.718\n",
      "Average minibatch loss at step 1304: 5.782\n",
      "Average minibatch loss at step 1306: 5.618\n",
      "Average minibatch loss at step 1308: 5.702\n",
      "Average minibatch loss at step 1310: 5.742\n",
      "Average minibatch loss at step 1312: 5.536\n",
      "Average minibatch loss at step 1314: 5.689\n",
      "Average minibatch loss at step 1316: 5.812\n",
      "Average minibatch loss at step 1318: 5.712\n",
      "Average minibatch loss at step 1320: 5.741\n",
      "Average minibatch loss at step 1322: 5.821\n",
      "Average minibatch loss at step 1324: 5.579\n",
      "Average minibatch loss at step 1326: 5.731\n",
      "Average minibatch loss at step 1328: 5.496\n",
      "Average minibatch loss at step 1330: 5.696\n",
      "Average minibatch loss at step 1332: 5.748\n",
      "Average minibatch loss at step 1334: 5.730\n",
      "Average minibatch loss at step 1336: 5.726\n",
      "Average minibatch loss at step 1338: 5.606\n",
      "Average minibatch loss at step 1340: 5.705\n",
      "Average minibatch loss at step 1342: 5.559\n",
      "Average minibatch loss at step 1344: 5.491\n",
      "Average minibatch loss at step 1346: 5.676\n",
      "Average minibatch loss at step 1348: 5.803\n",
      "Average minibatch loss at step 1350: 5.702\n",
      "Average minibatch loss at step 1352: 5.769\n",
      "Average minibatch loss at step 1354: 5.824\n",
      "Average minibatch loss at step 1356: 5.571\n",
      "Average minibatch loss at step 1358: 5.544\n",
      "Average minibatch loss at step 1360: 5.529\n",
      "Average minibatch loss at step 1362: 5.842\n",
      "Average minibatch loss at step 1364: 5.830\n",
      "Average minibatch loss at step 1366: 5.678\n",
      "Average minibatch loss at step 1368: 5.727\n",
      "Average minibatch loss at step 1370: 5.628\n",
      "Average minibatch loss at step 1372: 5.738\n",
      "Average minibatch loss at step 1374: 5.756\n",
      "Average minibatch loss at step 1376: 5.533\n",
      "Average minibatch loss at step 1378: 5.674\n",
      "Average minibatch loss at step 1380: 5.814\n",
      "Average minibatch loss at step 1382: 5.683\n",
      "Average minibatch loss at step 1384: 5.741\n",
      "Average minibatch loss at step 1386: 5.811\n",
      "Average minibatch loss at step 1388: 5.593\n",
      "Average minibatch loss at step 1390: 5.543\n",
      "Average minibatch loss at step 1392: 5.684\n",
      "Average minibatch loss at step 1394: 5.786\n",
      "Average minibatch loss at step 1396: 5.735\n",
      "Average minibatch loss at step 1398: 5.687\n",
      "Average minibatch loss at step 1400: 5.731\n",
      "Average minibatch loss at step 1402: 5.571\n",
      "Average minibatch loss at step 1404: 5.681\n",
      "Average minibatch loss at step 1406: 5.555\n",
      "Average minibatch loss at step 1408: 5.453\n",
      "Average minibatch loss at step 1410: 5.649\n",
      "Average minibatch loss at step 1412: 5.769\n",
      "Average minibatch loss at step 1414: 5.687\n",
      "Average minibatch loss at step 1416: 5.740\n",
      "Average minibatch loss at step 1418: 5.779\n",
      "Average minibatch loss at step 1420: 5.552\n",
      "Average minibatch loss at step 1422: 5.514\n",
      "Average minibatch loss at step 1424: 5.507\n",
      "Average minibatch loss at step 1426: 5.779\n",
      "Average minibatch loss at step 1428: 5.742\n",
      "Average minibatch loss at step 1430: 5.713\n",
      "Average minibatch loss at step 1432: 5.712\n",
      "Average minibatch loss at step 1434: 5.587\n",
      "Average minibatch loss at step 1436: 5.674\n",
      "Average minibatch loss at step 1438: 5.523\n",
      "Average minibatch loss at step 1440: 5.487\n",
      "Average minibatch loss at step 1442: 5.659\n",
      "Average minibatch loss at step 1444: 5.800\n",
      "Average minibatch loss at step 1446: 5.706\n",
      "Average minibatch loss at step 1448: 5.725\n",
      "Average minibatch loss at step 1450: 5.775\n",
      "Average minibatch loss at step 1452: 5.534\n",
      "Average minibatch loss at step 1454: 5.501\n",
      "Average minibatch loss at step 1456: 5.629\n",
      "Average minibatch loss at step 1458: 5.649\n",
      "Average minibatch loss at step 1460: 5.673\n",
      "Average minibatch loss at step 1462: 5.726\n",
      "Average minibatch loss at step 1464: 5.700\n",
      "Average minibatch loss at step 1466: 5.555\n",
      "Average minibatch loss at step 1468: 5.648\n",
      "Average minibatch loss at step 1470: 5.620\n",
      "Average minibatch loss at step 1472: 5.438\n",
      "Average minibatch loss at step 1474: 5.717\n",
      "Average minibatch loss at step 1476: 5.878\n",
      "Average minibatch loss at step 1478: 5.719\n",
      "Average minibatch loss at step 1480: 5.680\n",
      "Average minibatch loss at step 1482: 5.783\n",
      "Average minibatch loss at step 1484: 5.555\n",
      "Average minibatch loss at step 1486: 5.539\n",
      "Average minibatch loss at step 1488: 5.584\n",
      "Average minibatch loss at step 1490: 5.641\n",
      "Average minibatch loss at step 1492: 5.803\n",
      "Average minibatch loss at step 1494: 5.748\n",
      "Average minibatch loss at step 1496: 5.709\n",
      "Average minibatch loss at step 1498: 5.541\n",
      "Average minibatch loss at step 1500: 5.659\n",
      "Average minibatch loss at step 1502: 5.526\n",
      "Average minibatch loss at step 1504: 5.411\n",
      "Average minibatch loss at step 1506: 5.627\n",
      "Average minibatch loss at step 1508: 5.773\n",
      "Average minibatch loss at step 1510: 5.658\n",
      "Average minibatch loss at step 1512: 5.689\n",
      "Average minibatch loss at step 1514: 5.758\n",
      "Average minibatch loss at step 1516: 5.513\n",
      "Average minibatch loss at step 1518: 5.564\n",
      "Average minibatch loss at step 1520: 5.546\n",
      "Average minibatch loss at step 1522: 5.777\n",
      "Average minibatch loss at step 1524: 5.667\n",
      "Average minibatch loss at step 1526: 5.635\n",
      "Average minibatch loss at step 1528: 5.684\n",
      "Average minibatch loss at step 1530: 5.574\n",
      "Average minibatch loss at step 1532: 5.688\n",
      "Average minibatch loss at step 1534: 5.524\n",
      "Average minibatch loss at step 1536: 5.375\n",
      "Average minibatch loss at step 1538: 5.616\n",
      "Average minibatch loss at step 1540: 5.774\n",
      "Average minibatch loss at step 1542: 5.640\n",
      "Average minibatch loss at step 1544: 5.697\n",
      "Average minibatch loss at step 1546: 5.810\n",
      "Average minibatch loss at step 1548: 5.506\n",
      "Average minibatch loss at step 1550: 5.598\n",
      "Average minibatch loss at step 1552: 5.575\n",
      "Average minibatch loss at step 1554: 5.771\n",
      "Average minibatch loss at step 1556: 5.692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 1558: 5.702\n",
      "Average minibatch loss at step 1560: 5.707\n",
      "Average minibatch loss at step 1562: 5.676\n",
      "Average minibatch loss at step 1564: 5.641\n",
      "Average minibatch loss at step 1566: 5.567\n",
      "Average minibatch loss at step 1568: 5.417\n",
      "Average minibatch loss at step 1570: 5.665\n",
      "Average minibatch loss at step 1572: 5.843\n",
      "Average minibatch loss at step 1574: 5.628\n",
      "Average minibatch loss at step 1576: 5.632\n",
      "Average minibatch loss at step 1578: 5.723\n",
      "Average minibatch loss at step 1580: 5.499\n",
      "Average minibatch loss at step 1582: 5.565\n",
      "Average minibatch loss at step 1584: 5.626\n",
      "Average minibatch loss at step 1586: 5.649\n",
      "Average minibatch loss at step 1588: 5.698\n",
      "Average minibatch loss at step 1590: 5.796\n",
      "Average minibatch loss at step 1592: 5.677\n",
      "Average minibatch loss at step 1594: 5.519\n",
      "Average minibatch loss at step 1596: 5.638\n",
      "Average minibatch loss at step 1598: 5.618\n",
      "Average minibatch loss at step 1600: 5.419\n",
      "Average minibatch loss at step 1602: 5.640\n",
      "Average minibatch loss at step 1604: 5.885\n",
      "Average minibatch loss at step 1606: 5.648\n",
      "Average minibatch loss at step 1608: 5.638\n",
      "Average minibatch loss at step 1610: 5.724\n",
      "Average minibatch loss at step 1612: 5.494\n",
      "Average minibatch loss at step 1614: 5.546\n",
      "Average minibatch loss at step 1616: 5.544\n",
      "Average minibatch loss at step 1618: 5.587\n",
      "Average minibatch loss at step 1620: 5.698\n",
      "Average minibatch loss at step 1622: 5.627\n",
      "Average minibatch loss at step 1624: 5.649\n",
      "Average minibatch loss at step 1626: 5.538\n",
      "Average minibatch loss at step 1628: 5.625\n",
      "Average minibatch loss at step 1630: 5.530\n",
      "Average minibatch loss at step 1632: 5.419\n",
      "Average minibatch loss at step 1634: 5.617\n",
      "Average minibatch loss at step 1636: 5.755\n",
      "Average minibatch loss at step 1638: 5.664\n",
      "Average minibatch loss at step 1640: 5.688\n",
      "Average minibatch loss at step 1642: 5.726\n",
      "Average minibatch loss at step 1644: 5.506\n",
      "Average minibatch loss at step 1646: 5.478\n",
      "Average minibatch loss at step 1648: 5.517\n",
      "Average minibatch loss at step 1650: 5.611\n",
      "Average minibatch loss at step 1652: 5.635\n",
      "Average minibatch loss at step 1654: 5.670\n",
      "Average minibatch loss at step 1656: 5.657\n",
      "Average minibatch loss at step 1658: 5.512\n",
      "Average minibatch loss at step 1660: 5.600\n",
      "Average minibatch loss at step 1662: 5.492\n",
      "Average minibatch loss at step 1664: 5.358\n",
      "Average minibatch loss at step 1666: 5.604\n",
      "Average minibatch loss at step 1668: 5.802\n",
      "Average minibatch loss at step 1670: 5.617\n",
      "Average minibatch loss at step 1672: 5.653\n",
      "Average minibatch loss at step 1674: 5.748\n",
      "Average minibatch loss at step 1676: 5.488\n",
      "Average minibatch loss at step 1678: 5.649\n",
      "Average minibatch loss at step 1680: 5.439\n",
      "Average minibatch loss at step 1682: 5.587\n",
      "Average minibatch loss at step 1684: 5.643\n",
      "Average minibatch loss at step 1686: 5.670\n",
      "Average minibatch loss at step 1688: 5.627\n",
      "Average minibatch loss at step 1690: 5.473\n",
      "Average minibatch loss at step 1692: 5.616\n",
      "Average minibatch loss at step 1694: 5.478\n",
      "Average minibatch loss at step 1696: 5.324\n",
      "Average minibatch loss at step 1698: 5.592\n",
      "Average minibatch loss at step 1700: 5.818\n",
      "Average minibatch loss at step 1702: 5.716\n",
      "Average minibatch loss at step 1704: 5.637\n",
      "Average minibatch loss at step 1706: 5.700\n",
      "Average minibatch loss at step 1708: 5.450\n",
      "Average minibatch loss at step 1710: 5.443\n",
      "Average minibatch loss at step 1712: 5.533\n",
      "Average minibatch loss at step 1714: 5.551\n",
      "Average minibatch loss at step 1716: 5.727\n",
      "Average minibatch loss at step 1718: 5.591\n",
      "Average minibatch loss at step 1720: 5.657\n",
      "Average minibatch loss at step 1722: 5.566\n",
      "Average minibatch loss at step 1724: 5.591\n",
      "Average minibatch loss at step 1726: 5.511\n",
      "Average minibatch loss at step 1728: 5.456\n",
      "Average minibatch loss at step 1730: 5.622\n",
      "Average minibatch loss at step 1732: 5.707\n",
      "Average minibatch loss at step 1734: 5.633\n",
      "Average minibatch loss at step 1736: 5.635\n",
      "Average minibatch loss at step 1738: 5.660\n",
      "Average minibatch loss at step 1740: 5.452\n",
      "Average minibatch loss at step 1742: 5.583\n",
      "Average minibatch loss at step 1744: 5.428\n",
      "Average minibatch loss at step 1746: 5.577\n",
      "Average minibatch loss at step 1748: 5.664\n",
      "Average minibatch loss at step 1750: 5.679\n",
      "Average minibatch loss at step 1752: 5.623\n",
      "Average minibatch loss at step 1754: 5.504\n",
      "Average minibatch loss at step 1756: 5.611\n",
      "Average minibatch loss at step 1758: 5.575\n",
      "Average minibatch loss at step 1760: 5.372\n",
      "Average minibatch loss at step 1762: 5.639\n",
      "Average minibatch loss at step 1764: 5.695\n",
      "Average minibatch loss at step 1766: 5.604\n",
      "Average minibatch loss at step 1768: 5.695\n",
      "Average minibatch loss at step 1770: 5.688\n",
      "Average minibatch loss at step 1772: 5.482\n",
      "Average minibatch loss at step 1774: 5.588\n",
      "Average minibatch loss at step 1776: 5.393\n",
      "Average minibatch loss at step 1778: 5.690\n",
      "Average minibatch loss at step 1780: 5.676\n",
      "Average minibatch loss at step 1782: 5.530\n",
      "Average minibatch loss at step 1784: 5.615\n",
      "Average minibatch loss at step 1786: 5.473\n",
      "Average minibatch loss at step 1788: 5.597\n",
      "Average minibatch loss at step 1790: 5.456\n",
      "Average minibatch loss at step 1792: 5.300\n",
      "Average minibatch loss at step 1794: 5.549\n",
      "Average minibatch loss at step 1796: 5.724\n",
      "Average minibatch loss at step 1798: 5.595\n",
      "Average minibatch loss at step 1800: 5.619\n",
      "Average minibatch loss at step 1802: 5.675\n",
      "Average minibatch loss at step 1804: 5.452\n",
      "Average minibatch loss at step 1806: 5.553\n",
      "Average minibatch loss at step 1808: 5.434\n",
      "Average minibatch loss at step 1810: 5.596\n",
      "Average minibatch loss at step 1812: 5.700\n",
      "Average minibatch loss at step 1814: 5.588\n",
      "Average minibatch loss at step 1816: 5.591\n",
      "Average minibatch loss at step 1818: 5.460\n",
      "Average minibatch loss at step 1820: 5.568\n",
      "Average minibatch loss at step 1822: 5.455\n",
      "Average minibatch loss at step 1824: 5.277\n",
      "Average minibatch loss at step 1826: 5.559\n",
      "Average minibatch loss at step 1828: 5.720\n",
      "Average minibatch loss at step 1830: 5.611\n",
      "Average minibatch loss at step 1832: 5.616\n",
      "Average minibatch loss at step 1834: 5.662\n",
      "Average minibatch loss at step 1836: 5.430\n",
      "Average minibatch loss at step 1838: 5.481\n",
      "Average minibatch loss at step 1840: 5.458\n",
      "Average minibatch loss at step 1842: 5.566\n",
      "Average minibatch loss at step 1844: 5.643\n",
      "Average minibatch loss at step 1846: 5.570\n",
      "Average minibatch loss at step 1848: 5.648\n",
      "Average minibatch loss at step 1850: 5.595\n",
      "Average minibatch loss at step 1852: 5.621\n",
      "Average minibatch loss at step 1854: 5.483\n",
      "Average minibatch loss at step 1856: 5.328\n",
      "Average minibatch loss at step 1858: 5.534\n",
      "Average minibatch loss at step 1860: 5.716\n",
      "Average minibatch loss at step 1862: 5.573\n",
      "Average minibatch loss at step 1864: 5.623\n",
      "Average minibatch loss at step 1866: 5.662\n",
      "Average minibatch loss at step 1868: 5.443\n",
      "Average minibatch loss at step 1870: 5.418\n",
      "Average minibatch loss at step 1872: 5.441\n",
      "Average minibatch loss at step 1874: 5.561\n",
      "Average minibatch loss at step 1876: 5.584\n",
      "Average minibatch loss at step 1878: 5.637\n",
      "Average minibatch loss at step 1880: 5.586\n",
      "Average minibatch loss at step 1882: 5.454\n",
      "Average minibatch loss at step 1884: 5.567\n",
      "Average minibatch loss at step 1886: 5.434\n",
      "Average minibatch loss at step 1888: 5.278\n",
      "Average minibatch loss at step 1890: 5.528\n",
      "Average minibatch loss at step 1892: 5.672\n",
      "Average minibatch loss at step 1894: 5.595\n",
      "Average minibatch loss at step 1896: 5.635\n",
      "Average minibatch loss at step 1898: 5.608\n",
      "Average minibatch loss at step 1900: 5.395\n",
      "Average minibatch loss at step 1902: 5.461\n",
      "Average minibatch loss at step 1904: 5.429\n",
      "Average minibatch loss at step 1906: 5.591\n",
      "Average minibatch loss at step 1908: 5.591\n",
      "Average minibatch loss at step 1910: 5.511\n",
      "Average minibatch loss at step 1912: 5.594\n",
      "Average minibatch loss at step 1914: 5.484\n",
      "Average minibatch loss at step 1916: 5.532\n",
      "Average minibatch loss at step 1918: 5.422\n",
      "Average minibatch loss at step 1920: 5.330\n",
      "Average minibatch loss at step 1922: 5.557\n",
      "Average minibatch loss at step 1924: 5.686\n",
      "Average minibatch loss at step 1926: 5.582\n",
      "Average minibatch loss at step 1928: 5.638\n",
      "Average minibatch loss at step 1930: 5.600\n",
      "Average minibatch loss at step 1932: 5.396\n",
      "Average minibatch loss at step 1934: 5.422\n",
      "Average minibatch loss at step 1936: 5.435\n",
      "Average minibatch loss at step 1938: 5.551\n",
      "Average minibatch loss at step 1940: 5.556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 1942: 5.518\n",
      "Average minibatch loss at step 1944: 5.548\n",
      "Average minibatch loss at step 1946: 5.461\n",
      "Average minibatch loss at step 1948: 5.553\n",
      "Average minibatch loss at step 1950: 5.464\n",
      "Average minibatch loss at step 1952: 5.385\n",
      "Average minibatch loss at step 1954: 5.527\n",
      "Average minibatch loss at step 1956: 5.688\n",
      "Average minibatch loss at step 1958: 5.582\n",
      "Average minibatch loss at step 1960: 5.596\n",
      "Average minibatch loss at step 1962: 5.606\n",
      "Average minibatch loss at step 1964: 5.400\n",
      "Average minibatch loss at step 1966: 5.480\n",
      "Average minibatch loss at step 1968: 5.355\n",
      "Average minibatch loss at step 1970: 5.573\n",
      "Average minibatch loss at step 1972: 5.556\n",
      "Average minibatch loss at step 1974: 5.592\n",
      "Average minibatch loss at step 1976: 5.539\n",
      "Average minibatch loss at step 1978: 5.471\n",
      "Average minibatch loss at step 1980: 5.540\n",
      "Average minibatch loss at step 1982: 5.418\n",
      "Average minibatch loss at step 1984: 5.270\n",
      "Average minibatch loss at step 1986: 5.488\n",
      "Average minibatch loss at step 1988: 5.639\n",
      "Average minibatch loss at step 1990: 5.573\n",
      "Average minibatch loss at step 1992: 5.611\n",
      "Average minibatch loss at step 1994: 5.590\n",
      "Average minibatch loss at step 1996: 5.377\n",
      "Average minibatch loss at step 1998: 5.411\n",
      "Average minibatch loss at step 2000: 5.441\n",
      "Average minibatch loss at step 2002: 5.497\n",
      "Average minibatch loss at step 2004: 5.581\n",
      "Average minibatch loss at step 2006: 5.642\n",
      "Average minibatch loss at step 2008: 5.562\n",
      "Average minibatch loss at step 2010: 5.417\n",
      "Average minibatch loss at step 2012: 5.509\n",
      "Average minibatch loss at step 2014: 5.421\n",
      "Average minibatch loss at step 2016: 5.339\n",
      "Average minibatch loss at step 2018: 5.538\n",
      "Average minibatch loss at step 2020: 5.708\n",
      "Average minibatch loss at step 2022: 5.547\n",
      "Average minibatch loss at step 2024: 5.551\n",
      "Average minibatch loss at step 2026: 5.567\n",
      "Average minibatch loss at step 2028: 5.373\n",
      "Average minibatch loss at step 2030: 5.443\n",
      "Average minibatch loss at step 2032: 5.506\n",
      "Average minibatch loss at step 2034: 5.506\n",
      "Average minibatch loss at step 2036: 5.559\n",
      "Average minibatch loss at step 2038: 5.523\n",
      "Average minibatch loss at step 2040: 5.523\n",
      "Average minibatch loss at step 2042: 5.394\n",
      "Average minibatch loss at step 2044: 5.476\n",
      "Average minibatch loss at step 2046: 5.462\n",
      "Average minibatch loss at step 2048: 5.302\n",
      "Average minibatch loss at step 2050: 5.533\n",
      "Average minibatch loss at step 2052: 5.655\n",
      "Average minibatch loss at step 2054: 5.542\n",
      "Average minibatch loss at step 2056: 5.567\n",
      "Average minibatch loss at step 2058: 5.596\n",
      "Average minibatch loss at step 2060: 5.373\n",
      "Average minibatch loss at step 2062: 5.414\n",
      "Average minibatch loss at step 2064: 5.350\n",
      "Average minibatch loss at step 2066: 5.443\n",
      "Average minibatch loss at step 2068: 5.550\n",
      "Average minibatch loss at step 2070: 5.538\n",
      "Average minibatch loss at step 2072: 5.548\n",
      "Average minibatch loss at step 2074: 5.408\n",
      "Average minibatch loss at step 2076: 5.527\n",
      "Average minibatch loss at step 2078: 5.470\n",
      "Average minibatch loss at step 2080: 5.413\n",
      "Average minibatch loss at step 2082: 5.478\n",
      "Average minibatch loss at step 2084: 5.606\n",
      "Average minibatch loss at step 2086: 5.554\n",
      "Average minibatch loss at step 2088: 5.571\n",
      "Average minibatch loss at step 2090: 5.582\n",
      "Average minibatch loss at step 2092: 5.496\n",
      "Average minibatch loss at step 2094: 5.420\n",
      "Average minibatch loss at step 2096: 5.347\n",
      "Average minibatch loss at step 2098: 5.592\n",
      "Average minibatch loss at step 2100: 5.546\n",
      "Average minibatch loss at step 2102: 5.543\n",
      "Average minibatch loss at step 2104: 5.533\n",
      "Average minibatch loss at step 2106: 5.391\n",
      "Average minibatch loss at step 2108: 5.447\n",
      "Average minibatch loss at step 2110: 5.453\n",
      "Average minibatch loss at step 2112: 5.289\n",
      "Average minibatch loss at step 2114: 5.496\n",
      "Average minibatch loss at step 2116: 5.647\n",
      "Average minibatch loss at step 2118: 5.524\n",
      "Average minibatch loss at step 2120: 5.586\n",
      "Average minibatch loss at step 2122: 5.555\n",
      "Average minibatch loss at step 2124: 5.415\n",
      "Average minibatch loss at step 2126: 5.493\n",
      "Average minibatch loss at step 2128: 5.310\n",
      "Average minibatch loss at step 2130: 5.447\n",
      "Average minibatch loss at step 2132: 5.623\n",
      "Average minibatch loss at step 2134: 5.491\n",
      "Average minibatch loss at step 2136: 5.512\n",
      "Average minibatch loss at step 2138: 5.370\n",
      "Average minibatch loss at step 2140: 5.448\n",
      "Average minibatch loss at step 2142: 5.381\n",
      "Average minibatch loss at step 2144: 5.231\n",
      "Average minibatch loss at step 2146: 5.469\n",
      "Average minibatch loss at step 2148: 5.621\n",
      "Average minibatch loss at step 2150: 5.519\n",
      "Average minibatch loss at step 2152: 5.527\n",
      "Average minibatch loss at step 2154: 5.560\n",
      "Average minibatch loss at step 2156: 5.358\n",
      "Average minibatch loss at step 2158: 5.429\n",
      "Average minibatch loss at step 2160: 5.405\n",
      "Average minibatch loss at step 2162: 5.466\n",
      "Average minibatch loss at step 2164: 5.630\n",
      "Average minibatch loss at step 2166: 5.445\n",
      "Average minibatch loss at step 2168: 5.513\n",
      "Average minibatch loss at step 2170: 5.341\n",
      "Average minibatch loss at step 2172: 5.428\n",
      "Average minibatch loss at step 2174: 5.423\n",
      "Average minibatch loss at step 2176: 5.240\n",
      "Average minibatch loss at step 2178: 5.479\n",
      "Average minibatch loss at step 2180: 5.596\n",
      "Average minibatch loss at step 2182: 5.497\n",
      "Average minibatch loss at step 2184: 5.498\n",
      "Average minibatch loss at step 2186: 5.504\n",
      "Average minibatch loss at step 2188: 5.323\n",
      "Average minibatch loss at step 2190: 5.380\n",
      "Average minibatch loss at step 2192: 5.539\n",
      "Average minibatch loss at step 2194: 5.422\n",
      "Average minibatch loss at step 2196: 5.470\n",
      "Average minibatch loss at step 2198: 5.466\n",
      "Average minibatch loss at step 2200: 5.499\n",
      "Average minibatch loss at step 2202: 5.337\n",
      "Average minibatch loss at step 2204: 5.449\n",
      "Average minibatch loss at step 2206: 5.399\n",
      "Average minibatch loss at step 2208: 5.236\n",
      "Average minibatch loss at step 2210: 5.588\n",
      "Average minibatch loss at step 2212: 5.661\n",
      "Average minibatch loss at step 2214: 5.499\n",
      "Average minibatch loss at step 2216: 5.493\n",
      "Average minibatch loss at step 2218: 5.529\n",
      "Average minibatch loss at step 2220: 5.347\n",
      "Average minibatch loss at step 2222: 5.369\n",
      "Average minibatch loss at step 2224: 5.327\n",
      "Average minibatch loss at step 2226: 5.411\n",
      "Average minibatch loss at step 2228: 5.490\n",
      "Average minibatch loss at step 2230: 5.450\n",
      "Average minibatch loss at step 2232: 5.482\n",
      "Average minibatch loss at step 2234: 5.329\n",
      "Average minibatch loss at step 2236: 5.462\n",
      "Average minibatch loss at step 2238: 5.408\n",
      "Average minibatch loss at step 2240: 5.206\n",
      "Average minibatch loss at step 2242: 5.434\n",
      "Average minibatch loss at step 2244: 5.573\n",
      "Average minibatch loss at step 2246: 5.479\n",
      "Average minibatch loss at step 2248: 5.458\n",
      "Average minibatch loss at step 2250: 5.497\n",
      "Average minibatch loss at step 2252: 5.333\n",
      "Average minibatch loss at step 2254: 5.354\n",
      "Average minibatch loss at step 2256: 5.326\n",
      "Average minibatch loss at step 2258: 5.359\n",
      "Average minibatch loss at step 2260: 5.530\n",
      "Average minibatch loss at step 2262: 5.468\n",
      "Average minibatch loss at step 2264: 5.484\n",
      "Average minibatch loss at step 2266: 5.312\n",
      "Average minibatch loss at step 2268: 5.380\n",
      "Average minibatch loss at step 2270: 5.375\n",
      "Average minibatch loss at step 2272: 5.181\n",
      "Average minibatch loss at step 2274: 5.428\n",
      "Average minibatch loss at step 2276: 5.617\n",
      "Average minibatch loss at step 2278: 5.496\n",
      "Average minibatch loss at step 2280: 5.443\n",
      "Average minibatch loss at step 2282: 5.600\n",
      "Average minibatch loss at step 2284: 5.299\n",
      "Average minibatch loss at step 2286: 5.327\n",
      "Average minibatch loss at step 2288: 5.266\n",
      "Average minibatch loss at step 2290: 5.408\n",
      "Average minibatch loss at step 2292: 5.536\n",
      "Average minibatch loss at step 2294: 5.464\n",
      "Average minibatch loss at step 2296: 5.451\n",
      "Average minibatch loss at step 2298: 5.322\n",
      "Average minibatch loss at step 2300: 5.400\n",
      "Average minibatch loss at step 2302: 5.397\n",
      "Average minibatch loss at step 2304: 5.154\n",
      "Average minibatch loss at step 2306: 5.397\n",
      "Average minibatch loss at step 2308: 5.554\n",
      "Average minibatch loss at step 2310: 5.468\n",
      "Average minibatch loss at step 2312: 5.448\n",
      "Average minibatch loss at step 2314: 5.476\n",
      "Average minibatch loss at step 2316: 5.327\n",
      "Average minibatch loss at step 2318: 5.412\n",
      "Average minibatch loss at step 2320: 5.281\n",
      "Average minibatch loss at step 2322: 5.403\n",
      "Average minibatch loss at step 2324: 5.451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 2326: 5.416\n",
      "Average minibatch loss at step 2328: 5.450\n",
      "Average minibatch loss at step 2330: 5.316\n",
      "Average minibatch loss at step 2332: 5.403\n",
      "Average minibatch loss at step 2334: 5.357\n",
      "Average minibatch loss at step 2336: 5.194\n",
      "Average minibatch loss at step 2338: 5.486\n",
      "Average minibatch loss at step 2340: 5.633\n",
      "Average minibatch loss at step 2342: 5.446\n",
      "Average minibatch loss at step 2344: 5.435\n",
      "Average minibatch loss at step 2346: 5.497\n",
      "Average minibatch loss at step 2348: 5.314\n",
      "Average minibatch loss at step 2350: 5.289\n",
      "Average minibatch loss at step 2352: 5.232\n",
      "Average minibatch loss at step 2354: 5.313\n",
      "Average minibatch loss at step 2356: 5.396\n",
      "Average minibatch loss at step 2358: 5.458\n",
      "Average minibatch loss at step 2360: 5.445\n",
      "Average minibatch loss at step 2362: 5.491\n",
      "Average minibatch loss at step 2364: 5.381\n",
      "Average minibatch loss at step 2366: 5.317\n",
      "Average minibatch loss at step 2368: 5.137\n",
      "Average minibatch loss at step 2370: 5.360\n",
      "Average minibatch loss at step 2372: 5.551\n",
      "Average minibatch loss at step 2374: 5.436\n",
      "Average minibatch loss at step 2376: 5.413\n",
      "Average minibatch loss at step 2378: 5.513\n",
      "Average minibatch loss at step 2380: 5.291\n",
      "Average minibatch loss at step 2382: 5.271\n",
      "Average minibatch loss at step 2384: 5.266\n",
      "Average minibatch loss at step 2386: 5.405\n",
      "Average minibatch loss at step 2388: 5.437\n",
      "Average minibatch loss at step 2390: 5.404\n",
      "Average minibatch loss at step 2392: 5.403\n",
      "Average minibatch loss at step 2394: 5.248\n",
      "Average minibatch loss at step 2396: 5.351\n",
      "Average minibatch loss at step 2398: 5.350\n",
      "Average minibatch loss at step 2400: 5.135\n",
      "Average minibatch loss at step 2402: 5.393\n",
      "Average minibatch loss at step 2404: 5.533\n",
      "Average minibatch loss at step 2406: 5.411\n",
      "Average minibatch loss at step 2408: 5.405\n",
      "Average minibatch loss at step 2410: 5.504\n",
      "Average minibatch loss at step 2412: 5.289\n",
      "Average minibatch loss at step 2414: 5.463\n",
      "Average minibatch loss at step 2416: 5.277\n",
      "Average minibatch loss at step 2418: 5.362\n",
      "Average minibatch loss at step 2420: 5.460\n",
      "Average minibatch loss at step 2422: 5.441\n",
      "Average minibatch loss at step 2424: 5.435\n",
      "Average minibatch loss at step 2426: 5.467\n",
      "Average minibatch loss at step 2428: 5.361\n",
      "Average minibatch loss at step 2430: 5.305\n",
      "Average minibatch loss at step 2432: 5.084\n",
      "Average minibatch loss at step 2434: 5.338\n",
      "Average minibatch loss at step 2436: 5.527\n",
      "Average minibatch loss at step 2438: 5.395\n",
      "Average minibatch loss at step 2440: 5.372\n",
      "Average minibatch loss at step 2442: 5.471\n",
      "Average minibatch loss at step 2444: 5.250\n",
      "Average minibatch loss at step 2446: 5.326\n",
      "Average minibatch loss at step 2448: 5.187\n",
      "Average minibatch loss at step 2450: 5.318\n",
      "Average minibatch loss at step 2452: 5.421\n",
      "Average minibatch loss at step 2454: 5.420\n",
      "Average minibatch loss at step 2456: 5.386\n",
      "Average minibatch loss at step 2458: 5.262\n",
      "Average minibatch loss at step 2460: 5.364\n",
      "Average minibatch loss at step 2462: 5.288\n",
      "Average minibatch loss at step 2464: 5.078\n",
      "Average minibatch loss at step 2466: 5.322\n",
      "Average minibatch loss at step 2468: 5.525\n",
      "Average minibatch loss at step 2470: 5.405\n",
      "Average minibatch loss at step 2472: 5.416\n",
      "Average minibatch loss at step 2474: 5.562\n",
      "Average minibatch loss at step 2476: 5.259\n",
      "Average minibatch loss at step 2478: 5.274\n",
      "Average minibatch loss at step 2480: 5.211\n",
      "Average minibatch loss at step 2482: 5.307\n",
      "Average minibatch loss at step 2484: 5.412\n",
      "Average minibatch loss at step 2486: 5.404\n",
      "Average minibatch loss at step 2488: 5.374\n",
      "Average minibatch loss at step 2490: 5.215\n",
      "Average minibatch loss at step 2492: 5.350\n",
      "Average minibatch loss at step 2494: 5.283\n",
      "Average minibatch loss at step 2496: 5.066\n",
      "Average minibatch loss at step 2498: 5.286\n",
      "Average minibatch loss at step 2500: 5.537\n",
      "Average minibatch loss at step 2502: 5.408\n",
      "Average minibatch loss at step 2504: 5.367\n",
      "Average minibatch loss at step 2506: 5.430\n",
      "Average minibatch loss at step 2508: 5.239\n",
      "Average minibatch loss at step 2510: 5.246\n",
      "Average minibatch loss at step 2512: 5.165\n",
      "Average minibatch loss at step 2514: 5.333\n",
      "Average minibatch loss at step 2516: 5.444\n",
      "Average minibatch loss at step 2518: 5.335\n",
      "Average minibatch loss at step 2520: 5.394\n",
      "Average minibatch loss at step 2522: 5.325\n",
      "Average minibatch loss at step 2524: 5.293\n",
      "Average minibatch loss at step 2526: 5.246\n",
      "Average minibatch loss at step 2528: 5.022\n",
      "Average minibatch loss at step 2530: 5.294\n",
      "Average minibatch loss at step 2532: 5.544\n",
      "Average minibatch loss at step 2534: 5.391\n",
      "Average minibatch loss at step 2536: 5.397\n",
      "Average minibatch loss at step 2538: 5.417\n",
      "Average minibatch loss at step 2540: 5.209\n",
      "Average minibatch loss at step 2542: 5.258\n",
      "Average minibatch loss at step 2544: 5.163\n",
      "Average minibatch loss at step 2546: 5.290\n",
      "Average minibatch loss at step 2548: 5.366\n",
      "Average minibatch loss at step 2550: 5.341\n",
      "Average minibatch loss at step 2552: 5.343\n",
      "Average minibatch loss at step 2554: 5.228\n",
      "Average minibatch loss at step 2556: 5.290\n",
      "Average minibatch loss at step 2558: 5.261\n",
      "Average minibatch loss at step 2560: 5.122\n",
      "Average minibatch loss at step 2562: 5.272\n",
      "Average minibatch loss at step 2564: 5.489\n",
      "Average minibatch loss at step 2566: 5.359\n",
      "Average minibatch loss at step 2568: 5.351\n",
      "Average minibatch loss at step 2570: 5.451\n",
      "Average minibatch loss at step 2572: 5.223\n",
      "Average minibatch loss at step 2574: 5.198\n",
      "Average minibatch loss at step 2576: 5.140\n",
      "Average minibatch loss at step 2578: 5.310\n",
      "Average minibatch loss at step 2580: 5.327\n",
      "Average minibatch loss at step 2582: 5.328\n",
      "Average minibatch loss at step 2584: 5.318\n",
      "Average minibatch loss at step 2586: 5.190\n",
      "Average minibatch loss at step 2588: 5.285\n",
      "Average minibatch loss at step 2590: 5.247\n",
      "Average minibatch loss at step 2592: 5.034\n",
      "Average minibatch loss at step 2594: 5.239\n",
      "Average minibatch loss at step 2596: 5.464\n",
      "Average minibatch loss at step 2598: 5.343\n",
      "Average minibatch loss at step 2600: 5.335\n",
      "Average minibatch loss at step 2602: 5.400\n",
      "Average minibatch loss at step 2604: 5.190\n",
      "Average minibatch loss at step 2606: 5.237\n",
      "Average minibatch loss at step 2608: 5.124\n",
      "Average minibatch loss at step 2610: 5.214\n",
      "Average minibatch loss at step 2612: 5.360\n",
      "Average minibatch loss at step 2614: 5.371\n",
      "Average minibatch loss at step 2616: 5.361\n",
      "Average minibatch loss at step 2618: 5.185\n",
      "Average minibatch loss at step 2620: 5.262\n",
      "Average minibatch loss at step 2622: 5.291\n",
      "Average minibatch loss at step 2624: 5.133\n",
      "Average minibatch loss at step 2626: 5.302\n",
      "Average minibatch loss at step 2628: 5.478\n",
      "Average minibatch loss at step 2630: 5.367\n",
      "Average minibatch loss at step 2632: 5.328\n",
      "Average minibatch loss at step 2634: 5.408\n",
      "Average minibatch loss at step 2636: 5.172\n",
      "Average minibatch loss at step 2638: 5.216\n",
      "Average minibatch loss at step 2640: 5.106\n",
      "Average minibatch loss at step 2642: 5.308\n",
      "Average minibatch loss at step 2644: 5.316\n",
      "Average minibatch loss at step 2646: 5.317\n",
      "Average minibatch loss at step 2648: 5.343\n",
      "Average minibatch loss at step 2650: 5.168\n",
      "Average minibatch loss at step 2652: 5.247\n",
      "Average minibatch loss at step 2654: 5.219\n",
      "Average minibatch loss at step 2656: 5.033\n",
      "Average minibatch loss at step 2658: 5.234\n",
      "Average minibatch loss at step 2660: 5.460\n",
      "Average minibatch loss at step 2662: 5.306\n",
      "Average minibatch loss at step 2664: 5.341\n",
      "Average minibatch loss at step 2666: 5.368\n",
      "Average minibatch loss at step 2668: 5.188\n",
      "Average minibatch loss at step 2670: 5.168\n",
      "Average minibatch loss at step 2672: 5.180\n",
      "Average minibatch loss at step 2674: 5.261\n",
      "Average minibatch loss at step 2676: 5.293\n",
      "Average minibatch loss at step 2678: 5.305\n",
      "Average minibatch loss at step 2680: 5.271\n",
      "Average minibatch loss at step 2682: 5.149\n",
      "Average minibatch loss at step 2684: 5.223\n",
      "Average minibatch loss at step 2686: 5.205\n",
      "Average minibatch loss at step 2688: 5.022\n",
      "Average minibatch loss at step 2690: 5.221\n",
      "Average minibatch loss at step 2692: 5.451\n",
      "Average minibatch loss at step 2694: 5.296\n",
      "Average minibatch loss at step 2696: 5.299\n",
      "Average minibatch loss at step 2698: 5.377\n",
      "Average minibatch loss at step 2700: 5.183\n",
      "Average minibatch loss at step 2702: 5.215\n",
      "Average minibatch loss at step 2704: 5.228\n",
      "Average minibatch loss at step 2706: 5.225\n",
      "Average minibatch loss at step 2708: 5.276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 2710: 5.280\n",
      "Average minibatch loss at step 2712: 5.259\n",
      "Average minibatch loss at step 2714: 5.160\n",
      "Average minibatch loss at step 2716: 5.222\n",
      "Average minibatch loss at step 2718: 5.174\n",
      "Average minibatch loss at step 2720: 4.979\n",
      "Average minibatch loss at step 2722: 5.192\n",
      "Average minibatch loss at step 2724: 5.414\n",
      "Average minibatch loss at step 2726: 5.300\n",
      "Average minibatch loss at step 2728: 5.278\n",
      "Average minibatch loss at step 2730: 5.415\n",
      "Average minibatch loss at step 2732: 5.154\n",
      "Average minibatch loss at step 2734: 5.183\n",
      "Average minibatch loss at step 2736: 5.117\n",
      "Average minibatch loss at step 2738: 5.253\n",
      "Average minibatch loss at step 2740: 5.305\n",
      "Average minibatch loss at step 2742: 5.248\n",
      "Average minibatch loss at step 2744: 5.257\n",
      "Average minibatch loss at step 2746: 5.155\n",
      "Average minibatch loss at step 2748: 5.205\n",
      "Average minibatch loss at step 2750: 5.165\n",
      "Average minibatch loss at step 2752: 4.968\n",
      "Average minibatch loss at step 2754: 5.166\n",
      "Average minibatch loss at step 2756: 5.386\n",
      "Average minibatch loss at step 2758: 5.268\n",
      "Average minibatch loss at step 2760: 5.256\n",
      "Average minibatch loss at step 2762: 5.310\n",
      "Average minibatch loss at step 2764: 5.191\n",
      "Average minibatch loss at step 2766: 5.180\n",
      "Average minibatch loss at step 2768: 5.123\n",
      "Average minibatch loss at step 2770: 5.198\n",
      "Average minibatch loss at step 2772: 5.335\n",
      "Average minibatch loss at step 2774: 5.204\n",
      "Average minibatch loss at step 2776: 5.271\n",
      "Average minibatch loss at step 2778: 5.150\n",
      "Average minibatch loss at step 2780: 5.206\n",
      "Average minibatch loss at step 2782: 5.209\n",
      "Average minibatch loss at step 2784: 4.966\n",
      "Average minibatch loss at step 2786: 5.157\n",
      "Average minibatch loss at step 2788: 5.410\n",
      "Average minibatch loss at step 2790: 5.268\n",
      "Average minibatch loss at step 2792: 5.295\n",
      "Average minibatch loss at step 2794: 5.295\n",
      "Average minibatch loss at step 2796: 5.153\n",
      "Average minibatch loss at step 2798: 5.150\n",
      "Average minibatch loss at step 2800: 5.113\n",
      "Average minibatch loss at step 2802: 5.151\n",
      "Average minibatch loss at step 2804: 5.272\n",
      "Average minibatch loss at step 2806: 5.225\n",
      "Average minibatch loss at step 2808: 5.245\n",
      "Average minibatch loss at step 2810: 5.106\n",
      "Average minibatch loss at step 2812: 5.187\n",
      "Average minibatch loss at step 2814: 5.165\n",
      "Average minibatch loss at step 2816: 4.964\n",
      "Average minibatch loss at step 2818: 5.181\n",
      "Average minibatch loss at step 2820: 5.408\n",
      "Average minibatch loss at step 2822: 5.257\n",
      "Average minibatch loss at step 2824: 5.278\n",
      "Average minibatch loss at step 2826: 5.359\n",
      "Average minibatch loss at step 2828: 5.134\n",
      "Average minibatch loss at step 2830: 5.164\n",
      "Average minibatch loss at step 2832: 5.131\n",
      "Average minibatch loss at step 2834: 5.319\n",
      "Average minibatch loss at step 2836: 5.294\n",
      "Average minibatch loss at step 2838: 5.325\n",
      "Average minibatch loss at step 2840: 5.249\n",
      "Average minibatch loss at step 2842: 5.090\n",
      "Average minibatch loss at step 2844: 5.186\n",
      "Average minibatch loss at step 2846: 5.176\n",
      "Average minibatch loss at step 2848: 5.004\n",
      "Average minibatch loss at step 2850: 5.190\n",
      "Average minibatch loss at step 2852: 5.390\n",
      "Average minibatch loss at step 2854: 5.247\n",
      "Average minibatch loss at step 2856: 5.233\n",
      "Average minibatch loss at step 2858: 5.294\n",
      "Average minibatch loss at step 2860: 5.073\n",
      "Average minibatch loss at step 2862: 5.092\n",
      "Average minibatch loss at step 2864: 5.048\n",
      "Average minibatch loss at step 2866: 5.275\n",
      "Average minibatch loss at step 2868: 5.306\n",
      "Average minibatch loss at step 2870: 5.219\n",
      "Average minibatch loss at step 2872: 5.219\n",
      "Average minibatch loss at step 2874: 5.077\n",
      "Average minibatch loss at step 2876: 5.151\n",
      "Average minibatch loss at step 2878: 5.139\n",
      "Average minibatch loss at step 2880: 4.946\n",
      "Average minibatch loss at step 2882: 5.131\n",
      "Average minibatch loss at step 2884: 5.331\n",
      "Average minibatch loss at step 2886: 5.242\n",
      "Average minibatch loss at step 2888: 5.210\n",
      "Average minibatch loss at step 2890: 5.315\n",
      "Average minibatch loss at step 2892: 5.079\n",
      "Average minibatch loss at step 2894: 5.126\n",
      "Average minibatch loss at step 2896: 5.049\n",
      "Average minibatch loss at step 2898: 5.100\n",
      "Average minibatch loss at step 2900: 5.194\n",
      "Average minibatch loss at step 2902: 5.217\n",
      "Average minibatch loss at step 2904: 5.189\n",
      "Average minibatch loss at step 2906: 5.050\n",
      "Average minibatch loss at step 2908: 5.135\n",
      "Average minibatch loss at step 2910: 5.134\n",
      "Average minibatch loss at step 2912: 4.869\n",
      "Average minibatch loss at step 2914: 5.128\n",
      "Average minibatch loss at step 2916: 5.327\n",
      "Average minibatch loss at step 2918: 5.201\n",
      "Average minibatch loss at step 2920: 5.264\n",
      "Average minibatch loss at step 2922: 5.268\n",
      "Average minibatch loss at step 2924: 5.124\n",
      "Average minibatch loss at step 2926: 5.054\n",
      "Average minibatch loss at step 2928: 5.083\n",
      "Average minibatch loss at step 2930: 5.119\n",
      "Average minibatch loss at step 2932: 5.236\n",
      "Average minibatch loss at step 2934: 5.214\n",
      "Average minibatch loss at step 2936: 5.164\n",
      "Average minibatch loss at step 2938: 5.058\n",
      "Average minibatch loss at step 2940: 5.133\n",
      "Average minibatch loss at step 2942: 5.134\n",
      "Average minibatch loss at step 2944: 4.922\n",
      "Average minibatch loss at step 2946: 5.081\n",
      "Average minibatch loss at step 2948: 5.368\n",
      "Average minibatch loss at step 2950: 5.194\n",
      "Average minibatch loss at step 2952: 5.226\n",
      "Average minibatch loss at step 2954: 5.243\n",
      "Average minibatch loss at step 2956: 5.066\n",
      "Average minibatch loss at step 2958: 5.074\n",
      "Average minibatch loss at step 2960: 5.076\n",
      "Average minibatch loss at step 2962: 5.097\n",
      "Average minibatch loss at step 2964: 5.156\n",
      "Average minibatch loss at step 2966: 5.185\n",
      "Average minibatch loss at step 2968: 5.157\n",
      "Average minibatch loss at step 2970: 5.025\n",
      "Average minibatch loss at step 2972: 5.112\n",
      "Average minibatch loss at step 2974: 5.159\n",
      "Average minibatch loss at step 2976: 4.910\n",
      "Average minibatch loss at step 2978: 5.124\n",
      "Average minibatch loss at step 2980: 5.304\n",
      "Average minibatch loss at step 2982: 5.214\n",
      "Average minibatch loss at step 2984: 5.214\n",
      "Average minibatch loss at step 2986: 5.268\n",
      "Average minibatch loss at step 2988: 5.030\n",
      "Average minibatch loss at step 2990: 5.072\n",
      "Average minibatch loss at step 2992: 5.025\n",
      "Average minibatch loss at step 2994: 5.099\n",
      "Average minibatch loss at step 2996: 5.168\n",
      "Average minibatch loss at step 2998: 5.116\n",
      "Average minibatch loss at step 3000: 5.188\n",
      "Average minibatch loss at step 3002: 5.030\n",
      "Average minibatch loss at step 3004: 5.102\n",
      "Average minibatch loss at step 3006: 5.099\n",
      "Average minibatch loss at step 3008: 4.825\n",
      "Average minibatch loss at step 3010: 5.049\n",
      "Average minibatch loss at step 3012: 5.373\n",
      "Average minibatch loss at step 3014: 5.147\n",
      "Average minibatch loss at step 3016: 5.200\n",
      "Average minibatch loss at step 3018: 5.223\n",
      "Average minibatch loss at step 3020: 5.097\n",
      "Average minibatch loss at step 3022: 5.010\n",
      "Average minibatch loss at step 3024: 5.039\n",
      "Average minibatch loss at step 3026: 5.029\n",
      "Average minibatch loss at step 3028: 5.156\n",
      "Average minibatch loss at step 3030: 5.167\n",
      "Average minibatch loss at step 3032: 5.104\n",
      "Average minibatch loss at step 3034: 5.017\n",
      "Average minibatch loss at step 3036: 5.128\n",
      "Average minibatch loss at step 3038: 5.077\n",
      "Average minibatch loss at step 3040: 4.866\n",
      "Average minibatch loss at step 3042: 5.023\n",
      "Average minibatch loss at step 3044: 5.274\n",
      "Average minibatch loss at step 3046: 5.129\n",
      "Average minibatch loss at step 3048: 5.121\n",
      "Average minibatch loss at step 3050: 5.179\n",
      "Average minibatch loss at step 3052: 4.992\n",
      "Average minibatch loss at step 3054: 4.960\n",
      "Average minibatch loss at step 3056: 4.987\n",
      "Average minibatch loss at step 3058: 5.023\n",
      "Average minibatch loss at step 3060: 5.145\n",
      "Average minibatch loss at step 3062: 5.098\n",
      "Average minibatch loss at step 3064: 5.109\n",
      "Average minibatch loss at step 3066: 4.999\n",
      "Average minibatch loss at step 3068: 5.065\n",
      "Average minibatch loss at step 3070: 5.038\n",
      "Average minibatch loss at step 3072: 4.760\n",
      "Average minibatch loss at step 3074: 5.036\n",
      "Average minibatch loss at step 3076: 5.243\n",
      "Average minibatch loss at step 3078: 5.171\n",
      "Average minibatch loss at step 3080: 5.125\n",
      "Average minibatch loss at step 3082: 5.150\n",
      "Average minibatch loss at step 3084: 4.961\n",
      "Average minibatch loss at step 3086: 4.993\n",
      "Average minibatch loss at step 3088: 4.980\n",
      "Average minibatch loss at step 3090: 5.013\n",
      "Average minibatch loss at step 3092: 5.102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 3094: 5.166\n",
      "Average minibatch loss at step 3096: 5.094\n",
      "Average minibatch loss at step 3098: 4.989\n",
      "Average minibatch loss at step 3100: 5.070\n",
      "Average minibatch loss at step 3102: 5.080\n",
      "Average minibatch loss at step 3104: 4.806\n",
      "Average minibatch loss at step 3106: 5.174\n",
      "Average minibatch loss at step 3108: 5.222\n",
      "Average minibatch loss at step 3110: 5.124\n",
      "Average minibatch loss at step 3112: 5.141\n",
      "Average minibatch loss at step 3114: 5.167\n",
      "Average minibatch loss at step 3116: 5.019\n",
      "Average minibatch loss at step 3118: 4.995\n",
      "Average minibatch loss at step 3120: 5.112\n",
      "Average minibatch loss at step 3122: 5.018\n",
      "Average minibatch loss at step 3124: 5.131\n",
      "Average minibatch loss at step 3126: 5.081\n",
      "Average minibatch loss at step 3128: 5.127\n",
      "Average minibatch loss at step 3130: 4.987\n",
      "Average minibatch loss at step 3132: 5.031\n",
      "Average minibatch loss at step 3134: 5.048\n",
      "Average minibatch loss at step 3136: 4.779\n",
      "Average minibatch loss at step 3138: 5.217\n",
      "Average minibatch loss at step 3140: 5.324\n",
      "Average minibatch loss at step 3142: 5.118\n",
      "Average minibatch loss at step 3144: 5.085\n",
      "Average minibatch loss at step 3146: 5.131\n",
      "Average minibatch loss at step 3148: 4.926\n",
      "Average minibatch loss at step 3150: 4.927\n",
      "Average minibatch loss at step 3152: 5.018\n",
      "Average minibatch loss at step 3154: 4.996\n",
      "Average minibatch loss at step 3156: 5.105\n",
      "Average minibatch loss at step 3158: 5.109\n",
      "Average minibatch loss at step 3160: 5.115\n",
      "Average minibatch loss at step 3162: 4.921\n",
      "Average minibatch loss at step 3164: 5.040\n",
      "Average minibatch loss at step 3166: 5.038\n",
      "Average minibatch loss at step 3168: 4.720\n",
      "Average minibatch loss at step 3170: 4.986\n",
      "Average minibatch loss at step 3172: 5.236\n",
      "Average minibatch loss at step 3174: 5.058\n",
      "Average minibatch loss at step 3176: 5.106\n",
      "Average minibatch loss at step 3178: 5.170\n",
      "Average minibatch loss at step 3180: 4.948\n",
      "Average minibatch loss at step 3182: 4.929\n",
      "Average minibatch loss at step 3184: 5.068\n",
      "Average minibatch loss at step 3186: 4.972\n",
      "Average minibatch loss at step 3188: 5.069\n",
      "Average minibatch loss at step 3190: 5.053\n",
      "Average minibatch loss at step 3192: 5.091\n",
      "Average minibatch loss at step 3194: 4.915\n",
      "Average minibatch loss at step 3196: 5.004\n",
      "Average minibatch loss at step 3198: 5.012\n",
      "Average minibatch loss at step 3200: 4.733\n",
      "Average minibatch loss at step 3202: 4.973\n",
      "Average minibatch loss at step 3204: 5.163\n",
      "Average minibatch loss at step 3206: 5.099\n",
      "Average minibatch loss at step 3208: 5.057\n",
      "Average minibatch loss at step 3210: 5.120\n",
      "Average minibatch loss at step 3212: 4.893\n",
      "Average minibatch loss at step 3214: 4.927\n",
      "Average minibatch loss at step 3216: 4.967\n",
      "Average minibatch loss at step 3218: 4.940\n",
      "Average minibatch loss at step 3220: 5.028\n",
      "Average minibatch loss at step 3222: 4.986\n",
      "Average minibatch loss at step 3224: 5.039\n",
      "Average minibatch loss at step 3226: 4.890\n",
      "Average minibatch loss at step 3228: 4.972\n",
      "Average minibatch loss at step 3230: 4.998\n",
      "Average minibatch loss at step 3232: 4.691\n",
      "Average minibatch loss at step 3234: 4.938\n",
      "Average minibatch loss at step 3236: 5.135\n",
      "Average minibatch loss at step 3238: 5.071\n",
      "Average minibatch loss at step 3240: 5.043\n",
      "Average minibatch loss at step 3242: 5.109\n",
      "Average minibatch loss at step 3244: 4.928\n",
      "Average minibatch loss at step 3246: 4.842\n",
      "Average minibatch loss at step 3248: 4.977\n",
      "Average minibatch loss at step 3250: 4.935\n",
      "Average minibatch loss at step 3252: 5.049\n",
      "Average minibatch loss at step 3254: 4.991\n",
      "Average minibatch loss at step 3256: 5.031\n",
      "Average minibatch loss at step 3258: 4.892\n",
      "Average minibatch loss at step 3260: 5.003\n",
      "Average minibatch loss at step 3262: 4.978\n",
      "Average minibatch loss at step 3264: 4.743\n",
      "Average minibatch loss at step 3266: 4.928\n",
      "Average minibatch loss at step 3268: 5.194\n",
      "Average minibatch loss at step 3270: 5.052\n",
      "Average minibatch loss at step 3272: 5.024\n",
      "Average minibatch loss at step 3274: 5.104\n",
      "Average minibatch loss at step 3276: 4.861\n",
      "Average minibatch loss at step 3278: 4.878\n",
      "Average minibatch loss at step 3280: 4.901\n",
      "Average minibatch loss at step 3282: 4.894\n",
      "Average minibatch loss at step 3284: 4.991\n",
      "Average minibatch loss at step 3286: 5.049\n",
      "Average minibatch loss at step 3288: 5.021\n",
      "Average minibatch loss at step 3290: 4.887\n",
      "Average minibatch loss at step 3292: 4.939\n",
      "Average minibatch loss at step 3294: 4.940\n",
      "Average minibatch loss at step 3296: 4.591\n",
      "Average minibatch loss at step 3298: 4.955\n",
      "Average minibatch loss at step 3300: 5.194\n",
      "Average minibatch loss at step 3302: 5.014\n",
      "Average minibatch loss at step 3304: 5.024\n",
      "Average minibatch loss at step 3306: 5.041\n",
      "Average minibatch loss at step 3308: 4.872\n",
      "Average minibatch loss at step 3310: 4.904\n",
      "Average minibatch loss at step 3312: 4.953\n",
      "Average minibatch loss at step 3314: 4.880\n",
      "Average minibatch loss at step 3316: 5.003\n",
      "Average minibatch loss at step 3318: 4.945\n",
      "Average minibatch loss at step 3320: 4.984\n",
      "Average minibatch loss at step 3322: 4.858\n",
      "Average minibatch loss at step 3324: 4.946\n",
      "Average minibatch loss at step 3326: 4.945\n",
      "Average minibatch loss at step 3328: 4.777\n",
      "Average minibatch loss at step 3330: 4.892\n",
      "Average minibatch loss at step 3332: 5.118\n",
      "Average minibatch loss at step 3334: 5.084\n",
      "Average minibatch loss at step 3336: 5.047\n",
      "Average minibatch loss at step 3338: 5.088\n",
      "Average minibatch loss at step 3340: 4.854\n",
      "Average minibatch loss at step 3342: 4.852\n",
      "Average minibatch loss at step 3344: 4.887\n",
      "Average minibatch loss at step 3346: 4.869\n",
      "Average minibatch loss at step 3348: 4.994\n",
      "Average minibatch loss at step 3350: 5.017\n",
      "Average minibatch loss at step 3352: 5.004\n",
      "Average minibatch loss at step 3354: 4.820\n",
      "Average minibatch loss at step 3356: 4.887\n",
      "Average minibatch loss at step 3358: 4.904\n",
      "Average minibatch loss at step 3360: 4.574\n",
      "Average minibatch loss at step 3362: 4.990\n",
      "Average minibatch loss at step 3364: 5.072\n",
      "Average minibatch loss at step 3366: 4.996\n",
      "Average minibatch loss at step 3368: 4.974\n",
      "Average minibatch loss at step 3370: 5.012\n",
      "Average minibatch loss at step 3372: 4.819\n",
      "Average minibatch loss at step 3374: 4.791\n",
      "Average minibatch loss at step 3376: 4.852\n",
      "Average minibatch loss at step 3378: 4.860\n",
      "Average minibatch loss at step 3380: 4.942\n",
      "Average minibatch loss at step 3382: 4.967\n",
      "Average minibatch loss at step 3384: 4.969\n",
      "Average minibatch loss at step 3386: 4.783\n",
      "Average minibatch loss at step 3388: 4.867\n",
      "Average minibatch loss at step 3390: 4.932\n",
      "Average minibatch loss at step 3392: 4.664\n",
      "Average minibatch loss at step 3394: 4.885\n",
      "Average minibatch loss at step 3396: 5.059\n",
      "Average minibatch loss at step 3398: 4.987\n",
      "Average minibatch loss at step 3400: 4.998\n",
      "Average minibatch loss at step 3402: 5.042\n",
      "Average minibatch loss at step 3404: 4.831\n",
      "Average minibatch loss at step 3406: 4.805\n",
      "Average minibatch loss at step 3408: 4.932\n",
      "Average minibatch loss at step 3410: 4.817\n",
      "Average minibatch loss at step 3412: 4.901\n",
      "Average minibatch loss at step 3414: 4.943\n",
      "Average minibatch loss at step 3416: 5.204\n",
      "Average minibatch loss at step 3418: 4.807\n",
      "Average minibatch loss at step 3420: 4.870\n",
      "Average minibatch loss at step 3422: 4.899\n",
      "Average minibatch loss at step 3424: 4.544\n",
      "Average minibatch loss at step 3426: 4.863\n",
      "Average minibatch loss at step 3428: 5.172\n",
      "Average minibatch loss at step 3430: 4.983\n",
      "Average minibatch loss at step 3432: 4.932\n",
      "Average minibatch loss at step 3434: 5.046\n",
      "Average minibatch loss at step 3436: 4.790\n",
      "Average minibatch loss at step 3438: 4.791\n",
      "Average minibatch loss at step 3440: 4.951\n",
      "Average minibatch loss at step 3442: 4.834\n",
      "Average minibatch loss at step 3444: 4.946\n",
      "Average minibatch loss at step 3446: 4.870\n",
      "Average minibatch loss at step 3448: 4.941\n",
      "Average minibatch loss at step 3450: 4.781\n",
      "Average minibatch loss at step 3452: 4.848\n",
      "Average minibatch loss at step 3454: 4.927\n",
      "Average minibatch loss at step 3456: 4.707\n",
      "Average minibatch loss at step 3458: 4.902\n",
      "Average minibatch loss at step 3460: 5.069\n",
      "Average minibatch loss at step 3462: 4.938\n",
      "Average minibatch loss at step 3464: 4.964\n",
      "Average minibatch loss at step 3466: 5.021\n",
      "Average minibatch loss at step 3468: 4.798\n",
      "Average minibatch loss at step 3470: 4.812\n",
      "Average minibatch loss at step 3472: 4.808\n",
      "Average minibatch loss at step 3474: 4.784\n",
      "Average minibatch loss at step 3476: 4.939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 3478: 4.851\n",
      "Average minibatch loss at step 3480: 4.880\n",
      "Average minibatch loss at step 3482: 4.744\n",
      "Average minibatch loss at step 3484: 4.840\n",
      "Average minibatch loss at step 3486: 4.871\n",
      "Average minibatch loss at step 3488: 4.503\n",
      "Average minibatch loss at step 3490: 4.956\n",
      "Average minibatch loss at step 3492: 5.012\n",
      "Average minibatch loss at step 3494: 4.976\n",
      "Average minibatch loss at step 3496: 4.955\n",
      "Average minibatch loss at step 3498: 4.932\n",
      "Average minibatch loss at step 3500: 4.764\n",
      "Average minibatch loss at step 3502: 4.741\n",
      "Average minibatch loss at step 3504: 4.813\n",
      "Average minibatch loss at step 3506: 4.736\n",
      "Average minibatch loss at step 3508: 4.831\n",
      "Average minibatch loss at step 3510: 4.845\n",
      "Average minibatch loss at step 3512: 4.951\n",
      "Average minibatch loss at step 3514: 4.708\n",
      "Average minibatch loss at step 3516: 4.771\n",
      "Average minibatch loss at step 3518: 4.837\n",
      "Average minibatch loss at step 3520: 4.514\n",
      "Average minibatch loss at step 3522: 4.943\n",
      "Average minibatch loss at step 3524: 4.971\n",
      "Average minibatch loss at step 3526: 4.868\n",
      "Average minibatch loss at step 3528: 4.933\n",
      "Average minibatch loss at step 3530: 4.918\n",
      "Average minibatch loss at step 3532: 4.805\n",
      "Average minibatch loss at step 3534: 4.749\n",
      "Average minibatch loss at step 3536: 4.834\n",
      "Average minibatch loss at step 3538: 4.748\n",
      "Average minibatch loss at step 3540: 4.827\n",
      "Average minibatch loss at step 3542: 4.835\n",
      "Average minibatch loss at step 3544: 4.938\n",
      "Average minibatch loss at step 3546: 4.706\n",
      "Average minibatch loss at step 3548: 4.767\n",
      "Average minibatch loss at step 3550: 4.832\n",
      "Average minibatch loss at step 3552: 4.374\n",
      "Average minibatch loss at step 3554: 4.806\n",
      "Average minibatch loss at step 3556: 4.999\n",
      "Average minibatch loss at step 3558: 4.825\n",
      "Average minibatch loss at step 3560: 4.907\n",
      "Average minibatch loss at step 3562: 4.924\n",
      "Average minibatch loss at step 3564: 4.712\n",
      "Average minibatch loss at step 3566: 4.655\n",
      "Average minibatch loss at step 3568: 4.829\n",
      "Average minibatch loss at step 3570: 4.739\n",
      "Average minibatch loss at step 3572: 4.817\n",
      "Average minibatch loss at step 3574: 4.822\n",
      "Average minibatch loss at step 3576: 4.866\n",
      "Average minibatch loss at step 3578: 4.702\n",
      "Average minibatch loss at step 3580: 4.733\n",
      "Average minibatch loss at step 3582: 4.825\n",
      "Average minibatch loss at step 3584: 4.391\n",
      "Average minibatch loss at step 3586: 4.824\n",
      "Average minibatch loss at step 3588: 5.101\n",
      "Average minibatch loss at step 3590: 4.833\n",
      "Average minibatch loss at step 3592: 4.883\n",
      "Average minibatch loss at step 3594: 4.918\n",
      "Average minibatch loss at step 3596: 4.714\n",
      "Average minibatch loss at step 3598: 4.635\n",
      "Average minibatch loss at step 3600: 4.785\n",
      "Average minibatch loss at step 3602: 4.694\n",
      "Average minibatch loss at step 3604: 4.797\n",
      "Average minibatch loss at step 3606: 4.788\n",
      "Average minibatch loss at step 3608: 4.902\n",
      "Average minibatch loss at step 3610: 4.681\n",
      "Average minibatch loss at step 3612: 4.728\n",
      "Average minibatch loss at step 3614: 4.820\n",
      "Average minibatch loss at step 3616: 4.475\n",
      "Average minibatch loss at step 3618: 4.946\n",
      "Average minibatch loss at step 3620: 4.931\n",
      "Average minibatch loss at step 3622: 4.860\n",
      "Average minibatch loss at step 3624: 4.811\n",
      "Average minibatch loss at step 3626: 4.848\n",
      "Average minibatch loss at step 3628: 4.712\n",
      "Average minibatch loss at step 3630: 4.641\n",
      "Average minibatch loss at step 3632: 4.726\n",
      "Average minibatch loss at step 3634: 4.698\n",
      "Average minibatch loss at step 3636: 4.823\n",
      "Average minibatch loss at step 3638: 4.772\n",
      "Average minibatch loss at step 3640: 4.776\n",
      "Average minibatch loss at step 3642: 4.643\n",
      "Average minibatch loss at step 3644: 4.715\n",
      "Average minibatch loss at step 3646: 4.803\n",
      "Average minibatch loss at step 3648: 4.484\n",
      "Average minibatch loss at step 3650: 4.851\n",
      "Average minibatch loss at step 3652: 4.953\n",
      "Average minibatch loss at step 3654: 4.772\n",
      "Average minibatch loss at step 3656: 4.801\n",
      "Average minibatch loss at step 3658: 4.821\n",
      "Average minibatch loss at step 3660: 4.658\n",
      "Average minibatch loss at step 3662: 4.627\n",
      "Average minibatch loss at step 3664: 4.732\n",
      "Average minibatch loss at step 3666: 4.660\n",
      "Average minibatch loss at step 3668: 4.769\n",
      "Average minibatch loss at step 3670: 4.743\n",
      "Average minibatch loss at step 3672: 4.936\n",
      "Average minibatch loss at step 3674: 4.635\n",
      "Average minibatch loss at step 3676: 4.670\n",
      "Average minibatch loss at step 3678: 4.753\n",
      "Average minibatch loss at step 3680: 4.261\n",
      "Average minibatch loss at step 3682: 4.732\n",
      "Average minibatch loss at step 3684: 4.868\n",
      "Average minibatch loss at step 3686: 4.768\n",
      "Average minibatch loss at step 3688: 4.757\n",
      "Average minibatch loss at step 3690: 4.807\n",
      "Average minibatch loss at step 3692: 4.614\n",
      "Average minibatch loss at step 3694: 4.618\n",
      "Average minibatch loss at step 3696: 4.672\n",
      "Average minibatch loss at step 3698: 4.580\n",
      "Average minibatch loss at step 3700: 4.769\n",
      "Average minibatch loss at step 3702: 4.701\n",
      "Average minibatch loss at step 3704: 4.829\n",
      "Average minibatch loss at step 3706: 4.623\n",
      "Average minibatch loss at step 3708: 4.678\n",
      "Average minibatch loss at step 3710: 4.776\n",
      "Average minibatch loss at step 3712: 4.291\n",
      "Average minibatch loss at step 3714: 4.740\n",
      "Average minibatch loss at step 3716: 4.926\n",
      "Average minibatch loss at step 3718: 4.781\n",
      "Average minibatch loss at step 3720: 4.783\n",
      "Average minibatch loss at step 3722: 4.923\n",
      "Average minibatch loss at step 3724: 4.616\n",
      "Average minibatch loss at step 3726: 4.572\n",
      "Average minibatch loss at step 3728: 4.684\n",
      "Average minibatch loss at step 3730: 4.579\n",
      "Average minibatch loss at step 3732: 4.680\n",
      "Average minibatch loss at step 3734: 4.710\n",
      "Average minibatch loss at step 3736: 4.850\n",
      "Average minibatch loss at step 3738: 4.657\n",
      "Average minibatch loss at step 3740: 4.637\n",
      "Average minibatch loss at step 3742: 4.765\n",
      "Average minibatch loss at step 3744: 4.210\n",
      "Average minibatch loss at step 3746: 4.807\n",
      "Average minibatch loss at step 3748: 4.837\n",
      "Average minibatch loss at step 3750: 4.723\n",
      "Average minibatch loss at step 3752: 4.720\n",
      "Average minibatch loss at step 3754: 4.773\n",
      "Average minibatch loss at step 3756: 4.669\n",
      "Average minibatch loss at step 3758: 4.563\n",
      "Average minibatch loss at step 3760: 4.649\n",
      "Average minibatch loss at step 3762: 4.579\n",
      "Average minibatch loss at step 3764: 4.747\n",
      "Average minibatch loss at step 3766: 4.740\n",
      "Average minibatch loss at step 3768: 4.810\n",
      "Average minibatch loss at step 3770: 4.583\n",
      "Average minibatch loss at step 3772: 4.591\n",
      "Average minibatch loss at step 3774: 4.690\n",
      "Average minibatch loss at step 3776: 4.157\n",
      "Average minibatch loss at step 3778: 4.842\n",
      "Average minibatch loss at step 3780: 4.938\n",
      "Average minibatch loss at step 3782: 4.721\n",
      "Average minibatch loss at step 3784: 4.713\n",
      "Average minibatch loss at step 3786: 4.758\n",
      "Average minibatch loss at step 3788: 4.571\n",
      "Average minibatch loss at step 3790: 4.493\n",
      "Average minibatch loss at step 3792: 4.650\n",
      "Average minibatch loss at step 3794: 4.603\n",
      "Average minibatch loss at step 3796: 4.734\n",
      "Average minibatch loss at step 3798: 4.656\n",
      "Average minibatch loss at step 3800: 4.673\n",
      "Average minibatch loss at step 3802: 4.553\n",
      "Average minibatch loss at step 3804: 4.607\n",
      "Average minibatch loss at step 3806: 4.680\n",
      "Average minibatch loss at step 3808: 4.229\n",
      "Average minibatch loss at step 3810: 4.753\n",
      "Average minibatch loss at step 3812: 4.848\n",
      "Average minibatch loss at step 3814: 4.658\n",
      "Average minibatch loss at step 3816: 4.661\n",
      "Average minibatch loss at step 3818: 4.726\n",
      "Average minibatch loss at step 3820: 4.518\n",
      "Average minibatch loss at step 3822: 4.522\n",
      "Average minibatch loss at step 3824: 4.714\n",
      "Average minibatch loss at step 3826: 4.580\n",
      "Average minibatch loss at step 3828: 4.717\n",
      "Average minibatch loss at step 3830: 4.665\n",
      "Average minibatch loss at step 3832: 4.711\n",
      "Average minibatch loss at step 3834: 4.584\n",
      "Average minibatch loss at step 3836: 4.603\n",
      "Average minibatch loss at step 3838: 4.666\n",
      "Average minibatch loss at step 3840: 4.147\n",
      "Average minibatch loss at step 3842: 4.676\n",
      "Average minibatch loss at step 3844: 4.787\n",
      "Average minibatch loss at step 3846: 4.639\n",
      "Average minibatch loss at step 3848: 4.689\n",
      "Average minibatch loss at step 3850: 4.707\n",
      "Average minibatch loss at step 3852: 4.516\n",
      "Average minibatch loss at step 3854: 4.503\n",
      "Average minibatch loss at step 3856: 4.585\n",
      "Average minibatch loss at step 3858: 4.805\n",
      "Average minibatch loss at step 3860: 4.665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 3862: 4.559\n",
      "Average minibatch loss at step 3864: 4.673\n",
      "Average minibatch loss at step 3866: 4.532\n",
      "Average minibatch loss at step 3868: 4.564\n",
      "Average minibatch loss at step 3870: 4.741\n",
      "Average minibatch loss at step 3872: 4.241\n",
      "Average minibatch loss at step 3874: 5.817\n",
      "Average minibatch loss at step 3876: 6.272\n",
      "Average minibatch loss at step 3878: 5.960\n",
      "Average minibatch loss at step 3880: 5.738\n",
      "Average minibatch loss at step 3882: 5.213\n",
      "Average minibatch loss at step 3884: 4.799\n",
      "Average minibatch loss at step 3886: 4.675\n",
      "Average minibatch loss at step 3888: 4.668\n",
      "Average minibatch loss at step 3890: 4.610\n",
      "Average minibatch loss at step 3892: 4.691\n",
      "Average minibatch loss at step 3894: 4.601\n",
      "Average minibatch loss at step 3896: 4.668\n",
      "Average minibatch loss at step 3898: 4.550\n",
      "Average minibatch loss at step 3900: 4.632\n",
      "Average minibatch loss at step 3902: 4.617\n",
      "Average minibatch loss at step 3904: 4.135\n",
      "Average minibatch loss at step 3906: 4.703\n",
      "Average minibatch loss at step 3908: 4.805\n",
      "Average minibatch loss at step 3910: 4.658\n",
      "Average minibatch loss at step 3912: 4.675\n",
      "Average minibatch loss at step 3914: 4.685\n",
      "Average minibatch loss at step 3916: 4.533\n",
      "Average minibatch loss at step 3918: 4.422\n",
      "Average minibatch loss at step 3920: 4.554\n",
      "Average minibatch loss at step 3922: 4.525\n",
      "Average minibatch loss at step 3924: 4.643\n",
      "Average minibatch loss at step 3926: 4.522\n",
      "Average minibatch loss at step 3928: 4.589\n",
      "Average minibatch loss at step 3930: 4.500\n",
      "Average minibatch loss at step 3932: 4.509\n",
      "Average minibatch loss at step 3934: 4.569\n",
      "Average minibatch loss at step 3936: 4.069\n",
      "Average minibatch loss at step 3938: 4.671\n",
      "Average minibatch loss at step 3940: 4.723\n",
      "Average minibatch loss at step 3942: 4.603\n",
      "Average minibatch loss at step 3944: 4.652\n",
      "Average minibatch loss at step 3946: 4.614\n",
      "Average minibatch loss at step 3948: 4.430\n",
      "Average minibatch loss at step 3950: 4.367\n",
      "Average minibatch loss at step 3952: 4.510\n",
      "Average minibatch loss at step 3954: 4.436\n",
      "Average minibatch loss at step 3956: 4.642\n",
      "Average minibatch loss at step 3958: 4.531\n",
      "Average minibatch loss at step 3960: 4.607\n",
      "Average minibatch loss at step 3962: 4.468\n",
      "Average minibatch loss at step 3964: 4.509\n",
      "Average minibatch loss at step 3966: 4.572\n",
      "Average minibatch loss at step 3968: 4.072\n",
      "Average minibatch loss at step 3970: 4.637\n",
      "Average minibatch loss at step 3972: 4.753\n",
      "Average minibatch loss at step 3974: 4.605\n",
      "Average minibatch loss at step 3976: 4.708\n",
      "Average minibatch loss at step 3978: 4.675\n",
      "Average minibatch loss at step 3980: 4.442\n",
      "Average minibatch loss at step 3982: 4.407\n",
      "Average minibatch loss at step 3984: 4.534\n",
      "Average minibatch loss at step 3986: 4.456\n",
      "Average minibatch loss at step 3988: 4.534\n",
      "Average minibatch loss at step 3990: 4.495\n",
      "Average minibatch loss at step 3992: 4.608\n",
      "Average minibatch loss at step 3994: 4.550\n",
      "Average minibatch loss at step 3996: 4.563\n",
      "Average minibatch loss at step 3998: 4.560\n",
      "Average minibatch loss at step 4000: 3.940\n",
      "Average minibatch loss at step 4002: 4.585\n",
      "Average minibatch loss at step 4004: 4.712\n",
      "Average minibatch loss at step 4006: 4.580\n",
      "Average minibatch loss at step 4008: 4.599\n",
      "Average minibatch loss at step 4010: 4.620\n",
      "Average minibatch loss at step 4012: 4.409\n",
      "Average minibatch loss at step 4014: 4.398\n",
      "Average minibatch loss at step 4016: 4.545\n",
      "Average minibatch loss at step 4018: 4.457\n",
      "Average minibatch loss at step 4020: 4.538\n",
      "Average minibatch loss at step 4022: 4.431\n",
      "Average minibatch loss at step 4024: 4.540\n",
      "Average minibatch loss at step 4026: 4.543\n",
      "Average minibatch loss at step 4028: 4.513\n",
      "Average minibatch loss at step 4030: 4.602\n",
      "Average minibatch loss at step 4032: 4.025\n",
      "Average minibatch loss at step 4034: 4.650\n",
      "Average minibatch loss at step 4036: 4.696\n",
      "Average minibatch loss at step 4038: 4.609\n",
      "Average minibatch loss at step 4040: 4.679\n",
      "Average minibatch loss at step 4042: 4.575\n",
      "Average minibatch loss at step 4044: 4.406\n",
      "Average minibatch loss at step 4046: 4.393\n",
      "Average minibatch loss at step 4048: 4.510\n",
      "Average minibatch loss at step 4050: 4.373\n",
      "Average minibatch loss at step 4052: 4.498\n",
      "Average minibatch loss at step 4054: 4.427\n",
      "Average minibatch loss at step 4056: 4.491\n",
      "Average minibatch loss at step 4058: 4.420\n",
      "Average minibatch loss at step 4060: 4.475\n",
      "Average minibatch loss at step 4062: 4.559\n",
      "Average minibatch loss at step 4064: 4.006\n",
      "Average minibatch loss at step 4066: 4.727\n",
      "Average minibatch loss at step 4068: 4.668\n",
      "Average minibatch loss at step 4070: 4.560\n",
      "Average minibatch loss at step 4072: 4.559\n",
      "Average minibatch loss at step 4074: 4.525\n",
      "Average minibatch loss at step 4076: 4.379\n",
      "Average minibatch loss at step 4078: 4.277\n",
      "Average minibatch loss at step 4080: 4.400\n",
      "Average minibatch loss at step 4082: 4.377\n",
      "Average minibatch loss at step 4084: 4.547\n",
      "Average minibatch loss at step 4086: 4.478\n",
      "Average minibatch loss at step 4088: 4.537\n",
      "Average minibatch loss at step 4090: 4.464\n",
      "Average minibatch loss at step 4092: 4.452\n",
      "Average minibatch loss at step 4094: 4.503\n",
      "Average minibatch loss at step 4096: 4.107\n",
      "Average minibatch loss at step 4098: 4.563\n",
      "Average minibatch loss at step 4100: 4.659\n",
      "Average minibatch loss at step 4102: 4.486\n",
      "Average minibatch loss at step 4104: 4.530\n",
      "Average minibatch loss at step 4106: 4.496\n",
      "Average minibatch loss at step 4108: 4.362\n",
      "Average minibatch loss at step 4110: 4.280\n",
      "Average minibatch loss at step 4112: 4.400\n",
      "Average minibatch loss at step 4114: 4.321\n",
      "Average minibatch loss at step 4116: 4.469\n",
      "Average minibatch loss at step 4118: 4.370\n",
      "Average minibatch loss at step 4120: 4.573\n",
      "Average minibatch loss at step 4122: 4.415\n",
      "Average minibatch loss at step 4124: 4.432\n",
      "Average minibatch loss at step 4126: 4.449\n",
      "Average minibatch loss at step 4128: 3.882\n",
      "Average minibatch loss at step 4130: 4.574\n",
      "Average minibatch loss at step 4132: 4.643\n",
      "Average minibatch loss at step 4134: 4.456\n",
      "Average minibatch loss at step 4136: 4.541\n",
      "Average minibatch loss at step 4138: 4.523\n",
      "Average minibatch loss at step 4140: 4.336\n",
      "Average minibatch loss at step 4142: 4.247\n",
      "Average minibatch loss at step 4144: 4.501\n",
      "Average minibatch loss at step 4146: 4.455\n",
      "Average minibatch loss at step 4148: 4.468\n",
      "Average minibatch loss at step 4150: 4.371\n",
      "Average minibatch loss at step 4152: 4.421\n",
      "Average minibatch loss at step 4154: 4.351\n",
      "Average minibatch loss at step 4156: 4.364\n",
      "Average minibatch loss at step 4158: 4.561\n",
      "Average minibatch loss at step 4160: 3.950\n",
      "Average minibatch loss at step 4162: 4.505\n",
      "Average minibatch loss at step 4164: 4.574\n",
      "Average minibatch loss at step 4166: 4.473\n",
      "Average minibatch loss at step 4168: 4.558\n",
      "Average minibatch loss at step 4170: 4.535\n",
      "Average minibatch loss at step 4172: 4.288\n",
      "Average minibatch loss at step 4174: 4.369\n",
      "Average minibatch loss at step 4176: 4.563\n",
      "Average minibatch loss at step 4178: 4.311\n",
      "Average minibatch loss at step 4180: 4.415\n",
      "Average minibatch loss at step 4182: 4.328\n",
      "Average minibatch loss at step 4184: 4.394\n",
      "Average minibatch loss at step 4186: 4.355\n",
      "Average minibatch loss at step 4188: 4.365\n",
      "Average minibatch loss at step 4190: 4.388\n",
      "Average minibatch loss at step 4192: 3.919\n",
      "Average minibatch loss at step 4194: 4.531\n",
      "Average minibatch loss at step 4196: 4.639\n",
      "Average minibatch loss at step 4198: 4.415\n",
      "Average minibatch loss at step 4200: 4.535\n",
      "Average minibatch loss at step 4202: 4.437\n",
      "Average minibatch loss at step 4204: 4.352\n",
      "Average minibatch loss at step 4206: 4.213\n",
      "Average minibatch loss at step 4208: 4.402\n",
      "Average minibatch loss at step 4210: 4.313\n",
      "Average minibatch loss at step 4212: 4.488\n",
      "Average minibatch loss at step 4214: 4.331\n",
      "Average minibatch loss at step 4216: 4.427\n",
      "Average minibatch loss at step 4218: 4.338\n",
      "Average minibatch loss at step 4220: 4.380\n",
      "Average minibatch loss at step 4222: 4.413\n",
      "Average minibatch loss at step 4224: 3.844\n",
      "Average minibatch loss at step 4226: 4.440\n",
      "Average minibatch loss at step 4228: 4.533\n",
      "Average minibatch loss at step 4230: 4.445\n",
      "Average minibatch loss at step 4232: 4.431\n",
      "Average minibatch loss at step 4234: 4.429\n",
      "Average minibatch loss at step 4236: 4.230\n",
      "Average minibatch loss at step 4238: 4.184\n",
      "Average minibatch loss at step 4240: 4.358\n",
      "Average minibatch loss at step 4242: 4.445\n",
      "Average minibatch loss at step 4244: 4.422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 4246: 4.415\n",
      "Average minibatch loss at step 4248: 4.384\n",
      "Average minibatch loss at step 4250: 4.285\n",
      "Average minibatch loss at step 4252: 4.335\n",
      "Average minibatch loss at step 4254: 4.370\n",
      "Average minibatch loss at step 4256: 3.702\n",
      "Average minibatch loss at step 4258: 4.422\n",
      "Average minibatch loss at step 4260: 4.498\n",
      "Average minibatch loss at step 4262: 4.368\n",
      "Average minibatch loss at step 4264: 4.400\n",
      "Average minibatch loss at step 4266: 4.379\n",
      "Average minibatch loss at step 4268: 4.177\n",
      "Average minibatch loss at step 4270: 4.155\n",
      "Average minibatch loss at step 4272: 4.407\n",
      "Average minibatch loss at step 4274: 4.319\n",
      "Average minibatch loss at step 4276: 4.355\n",
      "Average minibatch loss at step 4278: 4.309\n",
      "Average minibatch loss at step 4280: 4.397\n",
      "Average minibatch loss at step 4282: 4.311\n",
      "Average minibatch loss at step 4284: 4.295\n",
      "Average minibatch loss at step 4286: 4.342\n",
      "Average minibatch loss at step 4288: 3.749\n",
      "Average minibatch loss at step 4290: 4.486\n",
      "Average minibatch loss at step 4292: 4.516\n",
      "Average minibatch loss at step 4294: 4.337\n",
      "Average minibatch loss at step 4296: 4.456\n",
      "Average minibatch loss at step 4298: 4.429\n",
      "Average minibatch loss at step 4300: 4.249\n",
      "Average minibatch loss at step 4302: 4.136\n",
      "Average minibatch loss at step 4304: 4.364\n",
      "Average minibatch loss at step 4306: 4.230\n",
      "Average minibatch loss at step 4308: 4.343\n",
      "Average minibatch loss at step 4310: 4.259\n",
      "Average minibatch loss at step 4312: 4.365\n",
      "Average minibatch loss at step 4314: 4.313\n",
      "Average minibatch loss at step 4316: 4.256\n",
      "Average minibatch loss at step 4318: 4.322\n",
      "Average minibatch loss at step 4320: 3.610\n",
      "Average minibatch loss at step 4322: 4.393\n",
      "Average minibatch loss at step 4324: 4.422\n",
      "Average minibatch loss at step 4326: 4.307\n",
      "Average minibatch loss at step 4328: 4.422\n",
      "Average minibatch loss at step 4330: 4.333\n",
      "Average minibatch loss at step 4332: 4.214\n",
      "Average minibatch loss at step 4334: 4.083\n",
      "Average minibatch loss at step 4336: 4.241\n",
      "Average minibatch loss at step 4338: 4.144\n",
      "Average minibatch loss at step 4340: 4.264\n",
      "Average minibatch loss at step 4342: 4.286\n",
      "Average minibatch loss at step 4344: 4.416\n",
      "Average minibatch loss at step 4346: 4.260\n",
      "Average minibatch loss at step 4348: 4.332\n",
      "Average minibatch loss at step 4350: 4.365\n",
      "Average minibatch loss at step 4352: 3.674\n",
      "Average minibatch loss at step 4354: 4.402\n",
      "Average minibatch loss at step 4356: 4.456\n",
      "Average minibatch loss at step 4358: 4.357\n",
      "Average minibatch loss at step 4360: 4.358\n",
      "Average minibatch loss at step 4362: 4.300\n",
      "Average minibatch loss at step 4364: 4.121\n",
      "Average minibatch loss at step 4366: 4.246\n",
      "Average minibatch loss at step 4368: 4.302\n",
      "Average minibatch loss at step 4370: 4.167\n",
      "Average minibatch loss at step 4372: 4.227\n",
      "Average minibatch loss at step 4374: 4.157\n",
      "Average minibatch loss at step 4376: 4.326\n",
      "Average minibatch loss at step 4378: 4.247\n",
      "Average minibatch loss at step 4380: 4.253\n",
      "Average minibatch loss at step 4382: 4.304\n",
      "Average minibatch loss at step 4384: 3.597\n",
      "Average minibatch loss at step 4386: 4.334\n",
      "Average minibatch loss at step 4388: 4.509\n",
      "Average minibatch loss at step 4390: 4.256\n",
      "Average minibatch loss at step 4392: 4.385\n",
      "Average minibatch loss at step 4394: 4.329\n",
      "Average minibatch loss at step 4396: 4.099\n",
      "Average minibatch loss at step 4398: 3.997\n",
      "Average minibatch loss at step 4400: 4.342\n",
      "Average minibatch loss at step 4402: 4.266\n",
      "Average minibatch loss at step 4404: 4.253\n",
      "Average minibatch loss at step 4406: 4.274\n",
      "Average minibatch loss at step 4408: 4.244\n",
      "Average minibatch loss at step 4410: 4.185\n",
      "Average minibatch loss at step 4412: 4.294\n",
      "Average minibatch loss at step 4414: 4.273\n",
      "Average minibatch loss at step 4416: 3.626\n",
      "Average minibatch loss at step 4418: 4.293\n",
      "Average minibatch loss at step 4420: 4.399\n",
      "Average minibatch loss at step 4422: 4.206\n",
      "Average minibatch loss at step 4424: 4.328\n",
      "Average minibatch loss at step 4426: 4.244\n",
      "Average minibatch loss at step 4428: 4.066\n",
      "Average minibatch loss at step 4430: 4.053\n",
      "Average minibatch loss at step 4432: 4.269\n",
      "Average minibatch loss at step 4434: 4.105\n",
      "Average minibatch loss at step 4436: 4.210\n",
      "Average minibatch loss at step 4438: 4.144\n",
      "Average minibatch loss at step 4440: 4.289\n",
      "Average minibatch loss at step 4442: 4.256\n",
      "Average minibatch loss at step 4444: 4.201\n",
      "Average minibatch loss at step 4446: 4.219\n",
      "Average minibatch loss at step 4448: 3.655\n",
      "Average minibatch loss at step 4450: 4.355\n",
      "Average minibatch loss at step 4452: 4.444\n",
      "Average minibatch loss at step 4454: 4.211\n",
      "Average minibatch loss at step 4456: 4.321\n",
      "Average minibatch loss at step 4458: 4.241\n",
      "Average minibatch loss at step 4460: 4.090\n",
      "Average minibatch loss at step 4462: 4.137\n",
      "Average minibatch loss at step 4464: 4.179\n",
      "Average minibatch loss at step 4466: 4.219\n",
      "Average minibatch loss at step 4468: 4.149\n",
      "Average minibatch loss at step 4470: 4.230\n",
      "Average minibatch loss at step 4472: 4.295\n",
      "Average minibatch loss at step 4474: 4.359\n",
      "Average minibatch loss at step 4476: 4.237\n",
      "Average minibatch loss at step 4478: 4.310\n",
      "Average minibatch loss at step 4480: 3.756\n",
      "Average minibatch loss at step 4482: 4.405\n",
      "Average minibatch loss at step 4484: 4.464\n",
      "Average minibatch loss at step 4486: 4.243\n",
      "Average minibatch loss at step 4488: 4.311\n",
      "Average minibatch loss at step 4490: 4.217\n",
      "Average minibatch loss at step 4492: 4.016\n",
      "Average minibatch loss at step 4494: 3.985\n",
      "Average minibatch loss at step 4496: 4.240\n",
      "Average minibatch loss at step 4498: 4.101\n",
      "Average minibatch loss at step 4500: 4.231\n",
      "Average minibatch loss at step 4502: 4.130\n",
      "Average minibatch loss at step 4504: 4.161\n",
      "Average minibatch loss at step 4506: 4.175\n",
      "Average minibatch loss at step 4508: 4.155\n",
      "Average minibatch loss at step 4510: 4.170\n",
      "Average minibatch loss at step 4512: 3.484\n",
      "Average minibatch loss at step 4514: 4.221\n",
      "Average minibatch loss at step 4516: 4.332\n",
      "Average minibatch loss at step 4518: 4.156\n",
      "Average minibatch loss at step 4520: 4.406\n",
      "Average minibatch loss at step 4522: 4.179\n",
      "Average minibatch loss at step 4524: 4.019\n",
      "Average minibatch loss at step 4526: 4.053\n",
      "Average minibatch loss at step 4528: 4.108\n",
      "Average minibatch loss at step 4530: 4.085\n",
      "Average minibatch loss at step 4532: 4.177\n",
      "Average minibatch loss at step 4534: 4.103\n",
      "Average minibatch loss at step 4536: 4.176\n",
      "Average minibatch loss at step 4538: 4.190\n",
      "Average minibatch loss at step 4540: 4.095\n",
      "Average minibatch loss at step 4542: 4.159\n",
      "Average minibatch loss at step 4544: 3.430\n",
      "Average minibatch loss at step 4546: 4.169\n",
      "Average minibatch loss at step 4548: 4.283\n",
      "Average minibatch loss at step 4550: 4.122\n",
      "Average minibatch loss at step 4552: 4.226\n",
      "Average minibatch loss at step 4554: 4.180\n",
      "Average minibatch loss at step 4556: 4.100\n",
      "Average minibatch loss at step 4558: 3.994\n",
      "Average minibatch loss at step 4560: 4.171\n",
      "Average minibatch loss at step 4562: 4.051\n",
      "Average minibatch loss at step 4564: 4.070\n",
      "Average minibatch loss at step 4566: 4.018\n",
      "Average minibatch loss at step 4568: 4.227\n",
      "Average minibatch loss at step 4570: 4.170\n",
      "Average minibatch loss at step 4572: 4.109\n",
      "Average minibatch loss at step 4574: 4.301\n",
      "Average minibatch loss at step 4576: 3.647\n",
      "Average minibatch loss at step 4578: 4.266\n",
      "Average minibatch loss at step 4580: 4.339\n",
      "Average minibatch loss at step 4582: 4.115\n",
      "Average minibatch loss at step 4584: 4.241\n",
      "Average minibatch loss at step 4586: 4.140\n",
      "Average minibatch loss at step 4588: 3.966\n",
      "Average minibatch loss at step 4590: 4.003\n",
      "Average minibatch loss at step 4592: 4.237\n",
      "Average minibatch loss at step 4594: 4.005\n",
      "Average minibatch loss at step 4596: 4.071\n",
      "Average minibatch loss at step 4598: 4.060\n",
      "Average minibatch loss at step 4600: 4.200\n",
      "Average minibatch loss at step 4602: 4.093\n",
      "Average minibatch loss at step 4604: 4.047\n",
      "Average minibatch loss at step 4606: 4.118\n",
      "Average minibatch loss at step 4608: 3.320\n",
      "Average minibatch loss at step 4610: 4.139\n",
      "Average minibatch loss at step 4612: 4.219\n",
      "Average minibatch loss at step 4614: 4.087\n",
      "Average minibatch loss at step 4616: 4.261\n",
      "Average minibatch loss at step 4618: 4.165\n",
      "Average minibatch loss at step 4620: 4.002\n",
      "Average minibatch loss at step 4622: 3.964\n",
      "Average minibatch loss at step 4624: 4.126\n",
      "Average minibatch loss at step 4626: 4.007\n",
      "Average minibatch loss at step 4628: 4.090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 4630: 3.946\n",
      "Average minibatch loss at step 4632: 4.047\n",
      "Average minibatch loss at step 4634: 4.029\n",
      "Average minibatch loss at step 4636: 3.984\n",
      "Average minibatch loss at step 4638: 4.144\n",
      "Average minibatch loss at step 4640: 3.285\n",
      "Average minibatch loss at step 4642: 4.211\n",
      "Average minibatch loss at step 4644: 4.450\n",
      "Average minibatch loss at step 4646: 4.157\n",
      "Average minibatch loss at step 4648: 4.192\n",
      "Average minibatch loss at step 4650: 4.089\n",
      "Average minibatch loss at step 4652: 3.999\n",
      "Average minibatch loss at step 4654: 4.030\n",
      "Average minibatch loss at step 4656: 4.447\n",
      "Average minibatch loss at step 4658: 4.034\n",
      "Average minibatch loss at step 4660: 4.073\n",
      "Average minibatch loss at step 4662: 3.975\n",
      "Average minibatch loss at step 4664: 4.064\n",
      "Average minibatch loss at step 4666: 4.092\n",
      "Average minibatch loss at step 4668: 3.988\n",
      "Average minibatch loss at step 4670: 4.147\n",
      "Average minibatch loss at step 4672: 3.367\n",
      "Average minibatch loss at step 4674: 4.171\n",
      "Average minibatch loss at step 4676: 4.178\n",
      "Average minibatch loss at step 4678: 4.022\n",
      "Average minibatch loss at step 4680: 4.136\n",
      "Average minibatch loss at step 4682: 4.089\n",
      "Average minibatch loss at step 4684: 4.045\n",
      "Average minibatch loss at step 4686: 3.889\n",
      "Average minibatch loss at step 4688: 4.062\n",
      "Average minibatch loss at step 4690: 4.020\n",
      "Average minibatch loss at step 4692: 4.001\n",
      "Average minibatch loss at step 4694: 4.036\n",
      "Average minibatch loss at step 4696: 4.063\n",
      "Average minibatch loss at step 4698: 4.053\n",
      "Average minibatch loss at step 4700: 4.023\n",
      "Average minibatch loss at step 4702: 4.218\n",
      "Average minibatch loss at step 4704: 3.393\n",
      "Average minibatch loss at step 4706: 4.136\n",
      "Average minibatch loss at step 4708: 4.138\n",
      "Average minibatch loss at step 4710: 3.975\n",
      "Average minibatch loss at step 4712: 4.063\n",
      "Average minibatch loss at step 4714: 4.024\n",
      "Average minibatch loss at step 4716: 3.915\n",
      "Average minibatch loss at step 4718: 3.961\n",
      "Average minibatch loss at step 4720: 4.136\n",
      "Average minibatch loss at step 4722: 3.926\n",
      "Average minibatch loss at step 4724: 4.180\n",
      "Average minibatch loss at step 4726: 4.085\n",
      "Average minibatch loss at step 4728: 4.043\n",
      "Average minibatch loss at step 4730: 4.052\n",
      "Average minibatch loss at step 4732: 3.901\n",
      "Average minibatch loss at step 4734: 4.017\n",
      "Average minibatch loss at step 4736: 3.311\n",
      "Average minibatch loss at step 4738: 4.038\n",
      "Average minibatch loss at step 4740: 4.118\n",
      "Average minibatch loss at step 4742: 3.934\n",
      "Average minibatch loss at step 4744: 4.224\n",
      "Average minibatch loss at step 4746: 3.990\n",
      "Average minibatch loss at step 4748: 3.877\n",
      "Average minibatch loss at step 4750: 3.921\n",
      "Average minibatch loss at step 4752: 4.010\n",
      "Average minibatch loss at step 4754: 3.936\n",
      "Average minibatch loss at step 4756: 3.947\n",
      "Average minibatch loss at step 4758: 3.854\n",
      "Average minibatch loss at step 4760: 3.934\n",
      "Average minibatch loss at step 4762: 3.974\n",
      "Average minibatch loss at step 4764: 3.878\n",
      "Average minibatch loss at step 4766: 3.962\n",
      "Average minibatch loss at step 4768: 3.503\n",
      "Average minibatch loss at step 4770: 4.110\n",
      "Average minibatch loss at step 4772: 4.192\n",
      "Average minibatch loss at step 4774: 4.077\n",
      "Average minibatch loss at step 4776: 4.194\n",
      "Average minibatch loss at step 4778: 7.546\n",
      "Average minibatch loss at step 4780: 7.242\n",
      "Average minibatch loss at step 4782: 7.527\n",
      "Average minibatch loss at step 4784: 6.107\n",
      "Average minibatch loss at step 4786: 4.945\n",
      "Average minibatch loss at step 4788: 4.723\n",
      "Average minibatch loss at step 4790: 4.298\n",
      "Average minibatch loss at step 4792: 4.336\n",
      "Average minibatch loss at step 4794: 4.240\n",
      "Average minibatch loss at step 4796: 4.119\n",
      "Average minibatch loss at step 4798: 4.268\n",
      "Average minibatch loss at step 4800: 3.513\n",
      "Average minibatch loss at step 4802: 4.298\n",
      "Average minibatch loss at step 4804: 4.350\n",
      "Average minibatch loss at step 4806: 4.107\n",
      "Average minibatch loss at step 4808: 4.119\n",
      "Average minibatch loss at step 4810: 4.118\n",
      "Average minibatch loss at step 4812: 3.979\n",
      "Average minibatch loss at step 4814: 4.036\n",
      "Average minibatch loss at step 4816: 4.165\n",
      "Average minibatch loss at step 4818: 3.910\n",
      "Average minibatch loss at step 4820: 3.945\n",
      "Average minibatch loss at step 4822: 3.882\n",
      "Average minibatch loss at step 4824: 3.944\n",
      "Average minibatch loss at step 4826: 4.009\n",
      "Average minibatch loss at step 4828: 3.899\n",
      "Average minibatch loss at step 4830: 4.108\n",
      "Average minibatch loss at step 4832: 3.194\n",
      "Average minibatch loss at step 4834: 4.046\n",
      "Average minibatch loss at step 4836: 4.193\n",
      "Average minibatch loss at step 4838: 3.955\n",
      "Average minibatch loss at step 4840: 4.122\n",
      "Average minibatch loss at step 4842: 4.043\n",
      "Average minibatch loss at step 4844: 3.934\n",
      "Average minibatch loss at step 4846: 3.913\n",
      "Average minibatch loss at step 4848: 3.995\n",
      "Average minibatch loss at step 4850: 3.852\n",
      "Average minibatch loss at step 4852: 3.909\n",
      "Average minibatch loss at step 4854: 3.805\n",
      "Average minibatch loss at step 4856: 3.864\n",
      "Average minibatch loss at step 4858: 3.878\n",
      "Average minibatch loss at step 4860: 3.847\n",
      "Average minibatch loss at step 4862: 3.996\n",
      "Average minibatch loss at step 4864: 3.302\n",
      "Average minibatch loss at step 4866: 3.982\n",
      "Average minibatch loss at step 4868: 4.067\n",
      "Average minibatch loss at step 4870: 3.874\n",
      "Average minibatch loss at step 4872: 4.084\n",
      "Average minibatch loss at step 4874: 3.952\n",
      "Average minibatch loss at step 4876: 3.857\n",
      "Average minibatch loss at step 4878: 3.809\n",
      "Average minibatch loss at step 4880: 3.929\n",
      "Average minibatch loss at step 4882: 3.809\n",
      "Average minibatch loss at step 4884: 3.824\n",
      "Average minibatch loss at step 4886: 3.717\n",
      "Average minibatch loss at step 4888: 3.963\n",
      "Average minibatch loss at step 4890: 3.892\n",
      "Average minibatch loss at step 4892: 3.866\n",
      "Average minibatch loss at step 4894: 4.195\n",
      "Average minibatch loss at step 4896: 3.021\n",
      "Average minibatch loss at step 4898: 3.975\n",
      "Average minibatch loss at step 4900: 4.171\n",
      "Average minibatch loss at step 4902: 3.925\n",
      "Average minibatch loss at step 4904: 3.979\n",
      "Average minibatch loss at step 4906: 3.891\n",
      "Average minibatch loss at step 4908: 3.781\n",
      "Average minibatch loss at step 4910: 3.765\n",
      "Average minibatch loss at step 4912: 3.963\n",
      "Average minibatch loss at step 4914: 3.766\n",
      "Average minibatch loss at step 4916: 3.880\n",
      "Average minibatch loss at step 4918: 3.865\n",
      "Average minibatch loss at step 4920: 3.846\n",
      "Average minibatch loss at step 4922: 3.873\n",
      "Average minibatch loss at step 4924: 3.926\n",
      "Average minibatch loss at step 4926: 3.900\n",
      "Average minibatch loss at step 4928: 3.147\n",
      "Average minibatch loss at step 4930: 4.028\n",
      "Average minibatch loss at step 4932: 4.140\n",
      "Average minibatch loss at step 4934: 3.807\n",
      "Average minibatch loss at step 4936: 3.961\n",
      "Average minibatch loss at step 4938: 3.848\n",
      "Average minibatch loss at step 4940: 3.865\n",
      "Average minibatch loss at step 4942: 3.757\n",
      "Average minibatch loss at step 4944: 3.848\n",
      "Average minibatch loss at step 4946: 3.851\n",
      "Average minibatch loss at step 4948: 3.768\n",
      "Average minibatch loss at step 4950: 3.780\n",
      "Average minibatch loss at step 4952: 3.925\n",
      "Average minibatch loss at step 4954: 3.897\n",
      "Average minibatch loss at step 4956: 3.774\n",
      "Average minibatch loss at step 4958: 3.824\n",
      "Average minibatch loss at step 4960: 3.128\n",
      "Average minibatch loss at step 4962: 3.909\n",
      "Average minibatch loss at step 4964: 3.953\n",
      "Average minibatch loss at step 4966: 3.788\n",
      "Average minibatch loss at step 4968: 3.911\n",
      "Average minibatch loss at step 4970: 3.813\n",
      "Average minibatch loss at step 4972: 3.803\n",
      "Average minibatch loss at step 4974: 3.734\n",
      "Average minibatch loss at step 4976: 3.955\n",
      "Average minibatch loss at step 4978: 3.715\n",
      "Average minibatch loss at step 4980: 3.739\n",
      "Average minibatch loss at step 4982: 3.700\n",
      "Average minibatch loss at step 4984: 3.764\n",
      "Average minibatch loss at step 4986: 3.798\n",
      "Average minibatch loss at step 4988: 3.708\n",
      "Average minibatch loss at step 4990: 3.886\n",
      "Average minibatch loss at step 4992: 3.008\n",
      "Average minibatch loss at step 4994: 3.806\n",
      "Average minibatch loss at step 4996: 3.983\n",
      "Average minibatch loss at step 4998: 3.764\n",
      "Average minibatch loss at step 5000: 3.971\n",
      "Average minibatch loss at step 5002: 3.825\n",
      "Average minibatch loss at step 5004: 3.765\n",
      "Average minibatch loss at step 5006: 3.687\n",
      "Average minibatch loss at step 5008: 3.780\n",
      "Average minibatch loss at step 5010: 3.764\n",
      "Average minibatch loss at step 5012: 3.793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 5014: 3.656\n",
      "Average minibatch loss at step 5016: 3.743\n",
      "Average minibatch loss at step 5018: 3.813\n",
      "Average minibatch loss at step 5020: 3.708\n",
      "Average minibatch loss at step 5022: 3.767\n",
      "Average minibatch loss at step 5024: 2.941\n",
      "Average minibatch loss at step 5026: 3.879\n",
      "Average minibatch loss at step 5028: 4.057\n",
      "Average minibatch loss at step 5030: 3.777\n",
      "Average minibatch loss at step 5032: 3.941\n",
      "Average minibatch loss at step 5034: 3.777\n",
      "Average minibatch loss at step 5036: 3.706\n",
      "Average minibatch loss at step 5038: 3.619\n",
      "Average minibatch loss at step 5040: 3.915\n",
      "Average minibatch loss at step 5042: 3.765\n",
      "Average minibatch loss at step 5044: 3.970\n",
      "Average minibatch loss at step 5046: 3.639\n",
      "Average minibatch loss at step 5048: 3.850\n",
      "Average minibatch loss at step 5050: 3.807\n",
      "Average minibatch loss at step 5052: 3.679\n",
      "Average minibatch loss at step 5054: 4.063\n",
      "Average minibatch loss at step 5056: 3.046\n",
      "Average minibatch loss at step 5058: 3.931\n",
      "Average minibatch loss at step 5060: 4.041\n",
      "Average minibatch loss at step 5062: 3.770\n",
      "Average minibatch loss at step 5064: 3.831\n",
      "Average minibatch loss at step 5066: 3.739\n",
      "Average minibatch loss at step 5068: 3.644\n",
      "Average minibatch loss at step 5070: 3.624\n",
      "Average minibatch loss at step 5072: 3.793\n",
      "Average minibatch loss at step 5074: 3.635\n",
      "Average minibatch loss at step 5076: 3.662\n",
      "Average minibatch loss at step 5078: 3.591\n",
      "Average minibatch loss at step 5080: 3.719\n",
      "Average minibatch loss at step 5082: 3.857\n",
      "Average minibatch loss at step 5084: 3.764\n",
      "Average minibatch loss at step 5086: 3.765\n",
      "Average minibatch loss at step 5088: 2.895\n",
      "Average minibatch loss at step 5090: 3.712\n",
      "Average minibatch loss at step 5092: 3.821\n",
      "Average minibatch loss at step 5094: 3.714\n",
      "Average minibatch loss at step 5096: 3.846\n",
      "Average minibatch loss at step 5098: 3.746\n",
      "Average minibatch loss at step 5100: 3.659\n",
      "Average minibatch loss at step 5102: 3.577\n",
      "Average minibatch loss at step 5104: 3.684\n",
      "Average minibatch loss at step 5106: 3.596\n",
      "Average minibatch loss at step 5108: 3.678\n",
      "Average minibatch loss at step 5110: 3.547\n",
      "Average minibatch loss at step 5112: 3.625\n",
      "Average minibatch loss at step 5114: 3.744\n",
      "Average minibatch loss at step 5116: 3.749\n",
      "Average minibatch loss at step 5118: 3.937\n",
      "Average minibatch loss at step 5120: 2.846\n",
      "Average minibatch loss at step 5122: 3.825\n",
      "Average minibatch loss at step 5124: 3.828\n",
      "Average minibatch loss at step 5126: 3.665\n",
      "Average minibatch loss at step 5128: 3.792\n",
      "Average minibatch loss at step 5130: 3.733\n",
      "Average minibatch loss at step 5132: 3.585\n",
      "Average minibatch loss at step 5134: 3.578\n",
      "Average minibatch loss at step 5136: 3.721\n",
      "Average minibatch loss at step 5138: 3.771\n",
      "Average minibatch loss at step 5140: 3.608\n",
      "Average minibatch loss at step 5142: 3.584\n",
      "Average minibatch loss at step 5144: 3.753\n",
      "Average minibatch loss at step 5146: 3.779\n",
      "Average minibatch loss at step 5148: 3.745\n",
      "Average minibatch loss at step 5150: 3.778\n",
      "Average minibatch loss at step 5152: 2.802\n",
      "Average minibatch loss at step 5154: 3.701\n",
      "Average minibatch loss at step 5156: 3.894\n",
      "Average minibatch loss at step 5158: 3.763\n",
      "Average minibatch loss at step 5160: 3.901\n",
      "Average minibatch loss at step 5162: 3.776\n",
      "Average minibatch loss at step 5164: 3.688\n",
      "Average minibatch loss at step 5166: 3.652\n",
      "Average minibatch loss at step 5168: 3.675\n",
      "Average minibatch loss at step 5170: 3.654\n",
      "Average minibatch loss at step 5172: 3.665\n",
      "Average minibatch loss at step 5174: 3.540\n",
      "Average minibatch loss at step 5176: 3.623\n",
      "Average minibatch loss at step 5178: 3.694\n",
      "Average minibatch loss at step 5180: 3.578\n",
      "Average minibatch loss at step 5182: 3.744\n",
      "Average minibatch loss at step 5184: 3.028\n",
      "Average minibatch loss at step 5186: 3.653\n",
      "Average minibatch loss at step 5188: 3.829\n",
      "Average minibatch loss at step 5190: 3.676\n",
      "Average minibatch loss at step 5192: 3.751\n",
      "Average minibatch loss at step 5194: 3.691\n",
      "Average minibatch loss at step 5196: 3.608\n",
      "Average minibatch loss at step 5198: 3.573\n",
      "Average minibatch loss at step 5200: 3.867\n",
      "Average minibatch loss at step 5202: 3.558\n",
      "Average minibatch loss at step 5204: 3.626\n",
      "Average minibatch loss at step 5206: 3.536\n",
      "Average minibatch loss at step 5208: 3.606\n",
      "Average minibatch loss at step 5210: 3.684\n",
      "Average minibatch loss at step 5212: 3.579\n",
      "Average minibatch loss at step 5214: 3.756\n",
      "Average minibatch loss at step 5216: 2.709\n",
      "Average minibatch loss at step 5218: 3.723\n",
      "Average minibatch loss at step 5220: 3.808\n",
      "Average minibatch loss at step 5222: 3.638\n",
      "Average minibatch loss at step 5224: 3.671\n",
      "Average minibatch loss at step 5226: 3.582\n",
      "Average minibatch loss at step 5228: 3.573\n",
      "Average minibatch loss at step 5230: 3.577\n",
      "Average minibatch loss at step 5232: 3.672\n",
      "Average minibatch loss at step 5234: 3.533\n",
      "Average minibatch loss at step 5236: 3.503\n",
      "Average minibatch loss at step 5238: 3.410\n",
      "Average minibatch loss at step 5240: 3.547\n",
      "Average minibatch loss at step 5242: 3.589\n",
      "Average minibatch loss at step 5244: 3.527\n",
      "Average minibatch loss at step 5246: 3.625\n",
      "Average minibatch loss at step 5248: 2.801\n",
      "Average minibatch loss at step 5250: 3.565\n",
      "Average minibatch loss at step 5252: 3.767\n",
      "Average minibatch loss at step 5254: 3.640\n",
      "Average minibatch loss at step 5256: 3.701\n",
      "Average minibatch loss at step 5258: 3.518\n",
      "Average minibatch loss at step 5260: 3.435\n",
      "Average minibatch loss at step 5262: 3.441\n",
      "Average minibatch loss at step 5264: 3.569\n",
      "Average minibatch loss at step 5266: 3.444\n",
      "Average minibatch loss at step 5268: 3.476\n",
      "Average minibatch loss at step 5270: 3.378\n",
      "Average minibatch loss at step 5272: 3.532\n",
      "Average minibatch loss at step 5274: 3.539\n",
      "Average minibatch loss at step 5276: 3.546\n",
      "Average minibatch loss at step 5278: 3.643\n",
      "Average minibatch loss at step 5280: 2.617\n",
      "Average minibatch loss at step 5282: 3.505\n",
      "Average minibatch loss at step 5284: 3.795\n",
      "Average minibatch loss at step 5286: 3.577\n",
      "Average minibatch loss at step 5288: 3.666\n",
      "Average minibatch loss at step 5290: 3.561\n",
      "Average minibatch loss at step 5292: 3.459\n",
      "Average minibatch loss at step 5294: 3.546\n",
      "Average minibatch loss at step 5296: 3.578\n",
      "Average minibatch loss at step 5298: 3.412\n",
      "Average minibatch loss at step 5300: 3.421\n",
      "Average minibatch loss at step 5302: 3.362\n",
      "Average minibatch loss at step 5304: 3.513\n",
      "Average minibatch loss at step 5306: 3.494\n",
      "Average minibatch loss at step 5308: 3.640\n",
      "Average minibatch loss at step 5310: 3.811\n",
      "Average minibatch loss at step 5312: 2.652\n",
      "Average minibatch loss at step 5314: 3.517\n",
      "Average minibatch loss at step 5316: 3.698\n",
      "Average minibatch loss at step 5318: 3.576\n",
      "Average minibatch loss at step 5320: 3.756\n",
      "Average minibatch loss at step 5322: 3.521\n",
      "Average minibatch loss at step 5324: 3.492\n",
      "Average minibatch loss at step 5326: 3.590\n",
      "Average minibatch loss at step 5328: 3.647\n",
      "Average minibatch loss at step 5330: 3.375\n",
      "Average minibatch loss at step 5332: 3.503\n",
      "Average minibatch loss at step 5334: 3.413\n",
      "Average minibatch loss at step 5336: 3.511\n",
      "Average minibatch loss at step 5338: 3.502\n",
      "Average minibatch loss at step 5340: 3.448\n",
      "Average minibatch loss at step 5342: 3.608\n",
      "Average minibatch loss at step 5344: 2.595\n",
      "Average minibatch loss at step 5346: 3.524\n",
      "Average minibatch loss at step 5348: 3.721\n",
      "Average minibatch loss at step 5350: 3.408\n",
      "Average minibatch loss at step 5352: 3.539\n",
      "Average minibatch loss at step 5354: 3.518\n",
      "Average minibatch loss at step 5356: 3.431\n",
      "Average minibatch loss at step 5358: 3.509\n",
      "Average minibatch loss at step 5360: 3.609\n",
      "Average minibatch loss at step 5362: 3.515\n",
      "Average minibatch loss at step 5364: 3.463\n",
      "Average minibatch loss at step 5366: 3.323\n",
      "Average minibatch loss at step 5368: 3.396\n",
      "Average minibatch loss at step 5370: 3.528\n",
      "Average minibatch loss at step 5372: 3.394\n",
      "Average minibatch loss at step 5374: 3.509\n",
      "Average minibatch loss at step 5376: 2.666\n",
      "Average minibatch loss at step 5378: 3.528\n",
      "Average minibatch loss at step 5380: 3.575\n",
      "Average minibatch loss at step 5382: 3.480\n",
      "Average minibatch loss at step 5384: 3.658\n",
      "Average minibatch loss at step 5386: 3.442\n",
      "Average minibatch loss at step 5388: 3.362\n",
      "Average minibatch loss at step 5390: 3.324\n",
      "Average minibatch loss at step 5392: 3.544\n",
      "Average minibatch loss at step 5394: 3.381\n",
      "Average minibatch loss at step 5396: 3.552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 5398: 3.268\n",
      "Average minibatch loss at step 5400: 3.504\n",
      "Average minibatch loss at step 5402: 3.754\n",
      "Average minibatch loss at step 5404: 3.566\n",
      "Average minibatch loss at step 5406: 3.552\n",
      "Average minibatch loss at step 5408: 2.537\n",
      "Average minibatch loss at step 5410: 3.395\n",
      "Average minibatch loss at step 5412: 3.671\n",
      "Average minibatch loss at step 5414: 3.429\n",
      "Average minibatch loss at step 5416: 3.521\n",
      "Average minibatch loss at step 5418: 3.381\n",
      "Average minibatch loss at step 5420: 3.316\n",
      "Average minibatch loss at step 5422: 3.382\n",
      "Average minibatch loss at step 5424: 3.440\n",
      "Average minibatch loss at step 5426: 3.402\n",
      "Average minibatch loss at step 5428: 3.368\n",
      "Average minibatch loss at step 5430: 3.208\n",
      "Average minibatch loss at step 5432: 3.353\n",
      "Average minibatch loss at step 5434: 3.458\n",
      "Average minibatch loss at step 5436: 3.377\n",
      "Average minibatch loss at step 5438: 3.471\n",
      "Average minibatch loss at step 5440: 2.536\n",
      "Average minibatch loss at step 5442: 3.407\n",
      "Average minibatch loss at step 5444: 3.602\n",
      "Average minibatch loss at step 5446: 3.427\n",
      "Average minibatch loss at step 5448: 3.494\n",
      "Average minibatch loss at step 5450: 3.359\n",
      "Average minibatch loss at step 5452: 3.214\n",
      "Average minibatch loss at step 5454: 3.307\n",
      "Average minibatch loss at step 5456: 3.507\n",
      "Average minibatch loss at step 5458: 3.324\n",
      "Average minibatch loss at step 5460: 3.284\n",
      "Average minibatch loss at step 5462: 3.201\n",
      "Average minibatch loss at step 5464: 3.347\n",
      "Average minibatch loss at step 5466: 3.507\n",
      "Average minibatch loss at step 5468: 3.320\n",
      "Average minibatch loss at step 5470: 3.450\n",
      "Average minibatch loss at step 5472: 2.487\n",
      "Average minibatch loss at step 5474: 3.356\n",
      "Average minibatch loss at step 5476: 3.507\n",
      "Average minibatch loss at step 5478: 3.388\n",
      "Average minibatch loss at step 5480: 3.602\n",
      "Average minibatch loss at step 5482: 3.440\n",
      "Average minibatch loss at step 5484: 3.304\n",
      "Average minibatch loss at step 5486: 3.322\n",
      "Average minibatch loss at step 5488: 3.544\n",
      "Average minibatch loss at step 5490: 3.280\n",
      "Average minibatch loss at step 5492: 3.392\n",
      "Average minibatch loss at step 5494: 3.261\n",
      "Average minibatch loss at step 5496: 3.366\n",
      "Average minibatch loss at step 5498: 3.376\n",
      "Average minibatch loss at step 5500: 3.426\n",
      "Average minibatch loss at step 5502: 3.433\n",
      "Average minibatch loss at step 5504: 2.361\n",
      "Average minibatch loss at step 5506: 3.275\n",
      "Average minibatch loss at step 5508: 3.497\n",
      "Average minibatch loss at step 5510: 3.436\n",
      "Average minibatch loss at step 5512: 3.595\n",
      "Average minibatch loss at step 5514: 3.444\n",
      "Average minibatch loss at step 5516: 3.359\n",
      "Average minibatch loss at step 5518: 3.491\n",
      "Average minibatch loss at step 5520: 3.501\n",
      "Average minibatch loss at step 5522: 3.369\n",
      "Average minibatch loss at step 5524: 3.218\n",
      "Average minibatch loss at step 5526: 3.119\n",
      "Average minibatch loss at step 5528: 3.345\n",
      "Average minibatch loss at step 5530: 3.408\n",
      "Average minibatch loss at step 5532: 3.333\n",
      "Average minibatch loss at step 5534: 3.544\n",
      "Average minibatch loss at step 5536: 2.423\n",
      "Average minibatch loss at step 5538: 3.277\n",
      "Average minibatch loss at step 5540: 3.528\n",
      "Average minibatch loss at step 5542: 3.305\n",
      "Average minibatch loss at step 5544: 3.555\n",
      "Average minibatch loss at step 5546: 3.258\n",
      "Average minibatch loss at step 5548: 3.201\n",
      "Average minibatch loss at step 5550: 3.245\n",
      "Average minibatch loss at step 5552: 3.315\n",
      "Average minibatch loss at step 5554: 3.163\n",
      "Average minibatch loss at step 5556: 3.323\n",
      "Average minibatch loss at step 5558: 3.149\n",
      "Average minibatch loss at step 5560: 3.320\n",
      "Average minibatch loss at step 5562: 3.339\n",
      "Average minibatch loss at step 5564: 3.341\n",
      "Average minibatch loss at step 5566: 3.424\n",
      "Average minibatch loss at step 5568: 2.631\n",
      "Average minibatch loss at step 5570: 3.415\n",
      "Average minibatch loss at step 5572: 3.438\n",
      "Average minibatch loss at step 5574: 3.345\n",
      "Average minibatch loss at step 5576: 3.427\n",
      "Average minibatch loss at step 5578: 3.284\n",
      "Average minibatch loss at step 5580: 3.233\n",
      "Average minibatch loss at step 5582: 3.220\n",
      "Average minibatch loss at step 5584: 3.282\n",
      "Average minibatch loss at step 5586: 3.261\n",
      "Average minibatch loss at step 5588: 3.346\n",
      "Average minibatch loss at step 5590: 3.160\n",
      "Average minibatch loss at step 5592: 3.382\n",
      "Average minibatch loss at step 5594: 3.317\n",
      "Average minibatch loss at step 5596: 3.329\n",
      "Average minibatch loss at step 5598: 3.409\n",
      "Average minibatch loss at step 5600: 2.321\n",
      "Average minibatch loss at step 5602: 3.167\n",
      "Average minibatch loss at step 5604: 3.416\n",
      "Average minibatch loss at step 5606: 3.310\n",
      "Average minibatch loss at step 5608: 3.345\n",
      "Average minibatch loss at step 5610: 3.407\n",
      "Average minibatch loss at step 5612: 3.250\n",
      "Average minibatch loss at step 5614: 3.190\n",
      "Average minibatch loss at step 5616: 3.334\n",
      "Average minibatch loss at step 5618: 3.310\n",
      "Average minibatch loss at step 5620: 3.186\n",
      "Average minibatch loss at step 5622: 3.096\n",
      "Average minibatch loss at step 5624: 3.189\n",
      "Average minibatch loss at step 5626: 3.365\n",
      "Average minibatch loss at step 5628: 3.301\n",
      "Average minibatch loss at step 5630: 3.260\n",
      "Average minibatch loss at step 5632: 2.207\n",
      "Average minibatch loss at step 5634: 3.101\n",
      "Average minibatch loss at step 5636: 3.372\n",
      "Average minibatch loss at step 5638: 3.288\n",
      "Average minibatch loss at step 5640: 3.523\n",
      "Average minibatch loss at step 5642: 3.182\n",
      "Average minibatch loss at step 5644: 3.048\n",
      "Average minibatch loss at step 5646: 3.184\n",
      "Average minibatch loss at step 5648: 3.279\n",
      "Average minibatch loss at step 5650: 3.168\n",
      "Average minibatch loss at step 5652: 3.257\n",
      "Average minibatch loss at step 5654: 3.066\n",
      "Average minibatch loss at step 5656: 3.215\n",
      "Average minibatch loss at step 5658: 3.286\n",
      "Average minibatch loss at step 5660: 3.278\n",
      "Average minibatch loss at step 5662: 3.281\n",
      "Average minibatch loss at step 5664: 2.156\n",
      "Average minibatch loss at step 5666: 3.096\n",
      "Average minibatch loss at step 5668: 3.359\n",
      "Average minibatch loss at step 5670: 3.243\n",
      "Average minibatch loss at step 5672: 3.287\n",
      "Average minibatch loss at step 5674: 3.091\n",
      "Average minibatch loss at step 5676: 3.205\n",
      "Average minibatch loss at step 5678: 3.407\n",
      "Average minibatch loss at step 5680: 3.328\n",
      "Average minibatch loss at step 5682: 3.323\n",
      "Average minibatch loss at step 5684: 3.169\n",
      "Average minibatch loss at step 5686: 3.020\n",
      "Average minibatch loss at step 5688: 3.283\n",
      "Average minibatch loss at step 5690: 3.438\n",
      "Average minibatch loss at step 5692: 3.392\n",
      "Average minibatch loss at step 5694: 3.345\n",
      "Average minibatch loss at step 5696: 2.077\n",
      "Average minibatch loss at step 5698: 3.118\n",
      "Average minibatch loss at step 5700: 3.338\n",
      "Average minibatch loss at step 5702: 3.321\n",
      "Average minibatch loss at step 5704: 3.368\n",
      "Average minibatch loss at step 5706: 3.154\n",
      "Average minibatch loss at step 5708: 3.082\n",
      "Average minibatch loss at step 5710: 3.064\n",
      "Average minibatch loss at step 5712: 3.149\n",
      "Average minibatch loss at step 5714: 3.137\n",
      "Average minibatch loss at step 5716: 3.077\n",
      "Average minibatch loss at step 5718: 2.951\n",
      "Average minibatch loss at step 5720: 3.259\n",
      "Average minibatch loss at step 5722: 3.406\n",
      "Average minibatch loss at step 5724: 3.137\n",
      "Average minibatch loss at step 5726: 3.286\n",
      "Average minibatch loss at step 5728: 2.114\n",
      "Average minibatch loss at step 5730: 3.107\n",
      "Average minibatch loss at step 5732: 3.253\n",
      "Average minibatch loss at step 5734: 3.119\n",
      "Average minibatch loss at step 5736: 3.374\n",
      "Average minibatch loss at step 5738: 3.151\n",
      "Average minibatch loss at step 5740: 3.080\n",
      "Average minibatch loss at step 5742: 3.086\n",
      "Average minibatch loss at step 5744: 3.215\n",
      "Average minibatch loss at step 5746: 3.123\n",
      "Average minibatch loss at step 5748: 3.100\n",
      "Average minibatch loss at step 5750: 2.834\n",
      "Average minibatch loss at step 5752: 3.059\n",
      "Average minibatch loss at step 5754: 3.097\n",
      "Average minibatch loss at step 5756: 3.100\n",
      "Average minibatch loss at step 5758: 3.266\n",
      "Average minibatch loss at step 5760: 1.960\n",
      "Average minibatch loss at step 5762: 3.009\n",
      "Average minibatch loss at step 5764: 3.150\n",
      "Average minibatch loss at step 5766: 3.035\n",
      "Average minibatch loss at step 5768: 3.284\n",
      "Average minibatch loss at step 5770: 3.077\n",
      "Average minibatch loss at step 5772: 2.968\n",
      "Average minibatch loss at step 5774: 2.878\n",
      "Average minibatch loss at step 5776: 3.103\n",
      "Average minibatch loss at step 5778: 3.031\n",
      "Average minibatch loss at step 5780: 2.987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 5782: 2.776\n",
      "Average minibatch loss at step 5784: 2.900\n",
      "Average minibatch loss at step 5786: 3.088\n",
      "Average minibatch loss at step 5788: 3.047\n",
      "Average minibatch loss at step 5790: 3.124\n",
      "Average minibatch loss at step 5792: 2.099\n",
      "Average minibatch loss at step 5794: 3.003\n",
      "Average minibatch loss at step 5796: 3.302\n",
      "Average minibatch loss at step 5798: 2.995\n",
      "Average minibatch loss at step 5800: 3.103\n",
      "Average minibatch loss at step 5802: 2.946\n",
      "Average minibatch loss at step 5804: 2.970\n",
      "Average minibatch loss at step 5806: 2.963\n",
      "Average minibatch loss at step 5808: 3.013\n",
      "Average minibatch loss at step 5810: 2.929\n",
      "Average minibatch loss at step 5812: 2.911\n",
      "Average minibatch loss at step 5814: 2.802\n",
      "Average minibatch loss at step 5816: 2.907\n",
      "Average minibatch loss at step 5818: 3.074\n",
      "Average minibatch loss at step 5820: 3.047\n",
      "Average minibatch loss at step 5822: 3.240\n",
      "Average minibatch loss at step 5824: 1.978\n",
      "Average minibatch loss at step 5826: 2.946\n",
      "Average minibatch loss at step 5828: 3.270\n",
      "Average minibatch loss at step 5830: 3.015\n",
      "Average minibatch loss at step 5832: 3.197\n",
      "Average minibatch loss at step 5834: 3.025\n",
      "Average minibatch loss at step 5836: 2.968\n",
      "Average minibatch loss at step 5838: 3.062\n",
      "Average minibatch loss at step 5840: 3.149\n",
      "Average minibatch loss at step 5842: 3.019\n",
      "Average minibatch loss at step 5844: 2.956\n",
      "Average minibatch loss at step 5846: 2.777\n",
      "Average minibatch loss at step 5848: 2.856\n",
      "Average minibatch loss at step 5850: 3.006\n",
      "Average minibatch loss at step 5852: 3.050\n",
      "Average minibatch loss at step 5854: 3.346\n",
      "Average minibatch loss at step 5856: 1.900\n",
      "Average minibatch loss at step 5858: 2.878\n",
      "Average minibatch loss at step 5860: 3.180\n",
      "Average minibatch loss at step 5862: 3.103\n",
      "Average minibatch loss at step 5864: 3.248\n",
      "Average minibatch loss at step 5866: 2.931\n",
      "Average minibatch loss at step 5868: 2.963\n",
      "Average minibatch loss at step 5870: 3.004\n",
      "Average minibatch loss at step 5872: 3.172\n",
      "Average minibatch loss at step 5874: 2.897\n",
      "Average minibatch loss at step 5876: 2.960\n",
      "Average minibatch loss at step 5878: 2.906\n",
      "Average minibatch loss at step 5880: 2.973\n",
      "Average minibatch loss at step 5882: 2.971\n",
      "Average minibatch loss at step 5884: 2.946\n",
      "Average minibatch loss at step 5886: 3.032\n",
      "Average minibatch loss at step 5888: 1.782\n",
      "Average minibatch loss at step 5890: 2.794\n",
      "Average minibatch loss at step 5892: 3.080\n",
      "Average minibatch loss at step 5894: 2.865\n",
      "Average minibatch loss at step 5896: 3.071\n",
      "Average minibatch loss at step 5898: 2.938\n",
      "Average minibatch loss at step 5900: 2.929\n",
      "Average minibatch loss at step 5902: 2.932\n",
      "Average minibatch loss at step 5904: 3.262\n",
      "Average minibatch loss at step 5906: 2.848\n",
      "Average minibatch loss at step 5908: 2.816\n",
      "Average minibatch loss at step 5910: 2.696\n",
      "Average minibatch loss at step 5912: 2.865\n",
      "Average minibatch loss at step 5914: 3.028\n",
      "Average minibatch loss at step 5916: 3.226\n",
      "Average minibatch loss at step 5918: 3.007\n",
      "Average minibatch loss at step 5920: 1.728\n",
      "Average minibatch loss at step 5922: 2.812\n",
      "Average minibatch loss at step 5924: 3.168\n",
      "Average minibatch loss at step 5926: 3.065\n",
      "Average minibatch loss at step 5928: 3.165\n",
      "Average minibatch loss at step 5930: 2.900\n",
      "Average minibatch loss at step 5932: 2.772\n",
      "Average minibatch loss at step 5934: 2.936\n",
      "Average minibatch loss at step 5936: 2.961\n",
      "Average minibatch loss at step 5938: 2.841\n",
      "Average minibatch loss at step 5940: 2.834\n",
      "Average minibatch loss at step 5942: 2.658\n",
      "Average minibatch loss at step 5944: 2.842\n",
      "Average minibatch loss at step 5946: 2.909\n",
      "Average minibatch loss at step 5948: 3.023\n",
      "Average minibatch loss at step 5950: 3.046\n",
      "Average minibatch loss at step 5952: 1.860\n",
      "Average minibatch loss at step 5954: 2.731\n",
      "Average minibatch loss at step 5956: 3.022\n",
      "Average minibatch loss at step 5958: 2.967\n",
      "Average minibatch loss at step 5960: 3.122\n",
      "Average minibatch loss at step 5962: 2.805\n",
      "Average minibatch loss at step 5964: 2.791\n",
      "Average minibatch loss at step 5966: 2.727\n",
      "Average minibatch loss at step 5968: 2.895\n",
      "Average minibatch loss at step 5970: 2.803\n",
      "Average minibatch loss at step 5972: 2.797\n",
      "Average minibatch loss at step 5974: 2.663\n",
      "Average minibatch loss at step 5976: 2.885\n",
      "Average minibatch loss at step 5978: 2.897\n",
      "Average minibatch loss at step 5980: 2.840\n",
      "Average minibatch loss at step 5982: 2.914\n",
      "Average minibatch loss at step 5984: 1.788\n",
      "Average minibatch loss at step 5986: 2.761\n",
      "Average minibatch loss at step 5988: 2.938\n",
      "Average minibatch loss at step 5990: 3.409\n",
      "Average minibatch loss at step 5992: 3.062\n",
      "Average minibatch loss at step 5994: 2.801\n",
      "Average minibatch loss at step 5996: 2.694\n",
      "Average minibatch loss at step 5998: 2.748\n",
      "Average minibatch loss at step 6000: 2.902\n",
      "Average minibatch loss at step 6002: 2.917\n",
      "Average minibatch loss at step 6004: 2.726\n",
      "Average minibatch loss at step 6006: 2.637\n",
      "Average minibatch loss at step 6008: 2.855\n",
      "Average minibatch loss at step 6010: 3.008\n",
      "Average minibatch loss at step 6012: 2.810\n",
      "Average minibatch loss at step 6014: 2.914\n",
      "Average minibatch loss at step 6016: 1.693\n",
      "Average minibatch loss at step 6018: 2.716\n",
      "Average minibatch loss at step 6020: 2.991\n",
      "Average minibatch loss at step 6022: 2.981\n",
      "Average minibatch loss at step 6024: 2.949\n",
      "Average minibatch loss at step 6026: 2.730\n",
      "Average minibatch loss at step 6028: 2.607\n",
      "Average minibatch loss at step 6030: 2.653\n",
      "Average minibatch loss at step 6032: 2.808\n",
      "Average minibatch loss at step 6034: 2.765\n",
      "Average minibatch loss at step 6036: 3.085\n",
      "Average minibatch loss at step 6038: 2.911\n",
      "Average minibatch loss at step 6040: 2.972\n",
      "Average minibatch loss at step 6042: 2.929\n",
      "Average minibatch loss at step 6044: 2.892\n",
      "Average minibatch loss at step 6046: 3.093\n",
      "Average minibatch loss at step 6048: 1.866\n",
      "Average minibatch loss at step 6050: 2.819\n",
      "Average minibatch loss at step 6052: 2.978\n",
      "Average minibatch loss at step 6054: 2.963\n",
      "Average minibatch loss at step 6056: 3.021\n",
      "Average minibatch loss at step 6058: 2.730\n",
      "Average minibatch loss at step 6060: 2.730\n",
      "Average minibatch loss at step 6062: 3.095\n",
      "Average minibatch loss at step 6064: 3.008\n",
      "Average minibatch loss at step 6066: 2.667\n",
      "Average minibatch loss at step 6068: 2.729\n",
      "Average minibatch loss at step 6070: 2.496\n",
      "Average minibatch loss at step 6072: 2.717\n",
      "Average minibatch loss at step 6074: 2.927\n",
      "Average minibatch loss at step 6076: 2.875\n",
      "Average minibatch loss at step 6078: 2.892\n",
      "Average minibatch loss at step 6080: 1.831\n",
      "Average minibatch loss at step 6082: 2.637\n",
      "Average minibatch loss at step 6084: 2.835\n",
      "Average minibatch loss at step 6086: 2.847\n",
      "Average minibatch loss at step 6088: 2.835\n",
      "Average minibatch loss at step 6090: 2.775\n",
      "Average minibatch loss at step 6092: 2.660\n",
      "Average minibatch loss at step 6094: 2.712\n",
      "Average minibatch loss at step 6096: 2.931\n",
      "Average minibatch loss at step 6098: 2.919\n",
      "Average minibatch loss at step 6100: 2.830\n",
      "Average minibatch loss at step 6102: 2.635\n",
      "Average minibatch loss at step 6104: 2.592\n",
      "Average minibatch loss at step 6106: 2.702\n",
      "Average minibatch loss at step 6108: 2.677\n",
      "Average minibatch loss at step 6110: 2.758\n",
      "Average minibatch loss at step 6112: 1.636\n",
      "Average minibatch loss at step 6114: 2.474\n",
      "Average minibatch loss at step 6116: 2.930\n",
      "Average minibatch loss at step 6118: 2.754\n",
      "Average minibatch loss at step 6120: 2.766\n",
      "Average minibatch loss at step 6122: 2.615\n",
      "Average minibatch loss at step 6124: 2.524\n",
      "Average minibatch loss at step 6126: 2.722\n",
      "Average minibatch loss at step 6128: 2.798\n",
      "Average minibatch loss at step 6130: 2.618\n",
      "Average minibatch loss at step 6132: 2.530\n",
      "Average minibatch loss at step 6134: 2.421\n",
      "Average minibatch loss at step 6136: 2.620\n",
      "Average minibatch loss at step 6138: 2.851\n",
      "Average minibatch loss at step 6140: 2.603\n",
      "Average minibatch loss at step 6142: 2.689\n",
      "Average minibatch loss at step 6144: 1.408\n",
      "Average minibatch loss at step 6146: 2.500\n",
      "Average minibatch loss at step 6148: 2.778\n",
      "Average minibatch loss at step 6150: 2.835\n",
      "Average minibatch loss at step 6152: 2.952\n",
      "Average minibatch loss at step 6154: 2.795\n",
      "Average minibatch loss at step 6156: 2.608\n",
      "Average minibatch loss at step 6158: 2.749\n",
      "Average minibatch loss at step 6160: 2.688\n",
      "Average minibatch loss at step 6162: 2.694\n",
      "Average minibatch loss at step 6164: 2.486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 6166: 2.342\n",
      "Average minibatch loss at step 6168: 2.597\n",
      "Average minibatch loss at step 6170: 2.763\n",
      "Average minibatch loss at step 6172: 2.622\n",
      "Average minibatch loss at step 6174: 2.733\n",
      "Average minibatch loss at step 6176: 1.457\n",
      "Average minibatch loss at step 6178: 2.451\n",
      "Average minibatch loss at step 6180: 2.690\n",
      "Average minibatch loss at step 6182: 2.597\n",
      "Average minibatch loss at step 6184: 2.790\n",
      "Average minibatch loss at step 6186: 2.512\n",
      "Average minibatch loss at step 6188: 2.507\n",
      "Average minibatch loss at step 6190: 2.526\n",
      "Average minibatch loss at step 6192: 2.599\n",
      "Average minibatch loss at step 6194: 2.553\n",
      "Average minibatch loss at step 6196: 2.461\n",
      "Average minibatch loss at step 6198: 2.333\n",
      "Average minibatch loss at step 6200: 2.508\n",
      "Average minibatch loss at step 6202: 2.575\n",
      "Average minibatch loss at step 6204: 2.524\n",
      "Average minibatch loss at step 6206: 2.597\n",
      "Average minibatch loss at step 6208: 1.417\n",
      "Average minibatch loss at step 6210: 2.344\n",
      "Average minibatch loss at step 6212: 2.751\n",
      "Average minibatch loss at step 6214: 2.615\n",
      "Average minibatch loss at step 6216: 2.724\n",
      "Average minibatch loss at step 6218: 2.591\n",
      "Average minibatch loss at step 6220: 2.661\n",
      "Average minibatch loss at step 6222: 2.650\n",
      "Average minibatch loss at step 6224: 2.543\n",
      "Average minibatch loss at step 6226: 2.565\n",
      "Average minibatch loss at step 6228: 2.377\n",
      "Average minibatch loss at step 6230: 2.479\n",
      "Average minibatch loss at step 6232: 2.699\n",
      "Average minibatch loss at step 6234: 2.821\n",
      "Average minibatch loss at step 6236: 2.687\n",
      "Average minibatch loss at step 6238: 2.791\n",
      "Average minibatch loss at step 6240: 2.056\n",
      "Average minibatch loss at step 6242: 2.647\n",
      "Average minibatch loss at step 6244: 2.931\n",
      "Average minibatch loss at step 6246: 2.809\n",
      "Average minibatch loss at step 6248: 2.790\n",
      "Average minibatch loss at step 6250: 2.521\n",
      "Average minibatch loss at step 6252: 2.422\n",
      "Average minibatch loss at step 6254: 2.350\n",
      "Average minibatch loss at step 6256: 2.459\n",
      "Average minibatch loss at step 6258: 2.549\n",
      "Average minibatch loss at step 6260: 2.300\n",
      "Average minibatch loss at step 6262: 2.152\n",
      "Average minibatch loss at step 6264: 2.363\n",
      "Average minibatch loss at step 6266: 2.711\n",
      "Average minibatch loss at step 6268: 2.779\n",
      "Average minibatch loss at step 6270: 2.689\n",
      "Average minibatch loss at step 6272: 1.412\n",
      "Average minibatch loss at step 6274: 2.296\n",
      "Average minibatch loss at step 6276: 2.561\n",
      "Average minibatch loss at step 6278: 2.471\n",
      "Average minibatch loss at step 6280: 2.717\n",
      "Average minibatch loss at step 6282: 2.750\n",
      "Average minibatch loss at step 6284: 2.404\n",
      "Average minibatch loss at step 6286: 2.410\n",
      "Average minibatch loss at step 6288: 2.448\n",
      "Average minibatch loss at step 6290: 2.505\n",
      "Average minibatch loss at step 6292: 2.289\n",
      "Average minibatch loss at step 6294: 2.196\n",
      "Average minibatch loss at step 6296: 2.324\n",
      "Average minibatch loss at step 6298: 2.521\n",
      "Average minibatch loss at step 6300: 2.488\n",
      "Average minibatch loss at step 6302: 2.751\n",
      "Average minibatch loss at step 6304: 1.397\n",
      "Average minibatch loss at step 6306: 2.223\n",
      "Average minibatch loss at step 6308: 2.466\n",
      "Average minibatch loss at step 6310: 2.383\n",
      "Average minibatch loss at step 6312: 2.617\n",
      "Average minibatch loss at step 6314: 2.348\n",
      "Average minibatch loss at step 6316: 2.441\n",
      "Average minibatch loss at step 6318: 2.313\n",
      "Average minibatch loss at step 6320: 2.338\n",
      "Average minibatch loss at step 6322: 2.317\n",
      "Average minibatch loss at step 6324: 2.366\n",
      "Average minibatch loss at step 6326: 2.261\n",
      "Average minibatch loss at step 6328: 2.298\n",
      "Average minibatch loss at step 6330: 2.608\n",
      "Average minibatch loss at step 6332: 2.556\n",
      "Average minibatch loss at step 6334: 2.591\n",
      "Average minibatch loss at step 6336: 1.345\n",
      "Average minibatch loss at step 6338: 2.193\n",
      "Average minibatch loss at step 6340: 2.529\n",
      "Average minibatch loss at step 6342: 2.561\n",
      "Average minibatch loss at step 6344: 2.563\n",
      "Average minibatch loss at step 6346: 2.298\n",
      "Average minibatch loss at step 6348: 2.342\n",
      "Average minibatch loss at step 6350: 2.362\n",
      "Average minibatch loss at step 6352: 2.317\n",
      "Average minibatch loss at step 6354: 2.298\n",
      "Average minibatch loss at step 6356: 2.195\n",
      "Average minibatch loss at step 6358: 2.174\n",
      "Average minibatch loss at step 6360: 2.446\n",
      "Average minibatch loss at step 6362: 2.599\n",
      "Average minibatch loss at step 6364: 2.558\n",
      "Average minibatch loss at step 6366: 2.699\n",
      "Average minibatch loss at step 6368: 1.299\n",
      "Average minibatch loss at step 6370: 2.137\n",
      "Average minibatch loss at step 6372: 2.506\n",
      "Average minibatch loss at step 6374: 2.422\n",
      "Average minibatch loss at step 6376: 2.572\n",
      "Average minibatch loss at step 6378: 2.342\n",
      "Average minibatch loss at step 6380: 2.292\n",
      "Average minibatch loss at step 6382: 2.408\n",
      "Average minibatch loss at step 6384: 2.410\n",
      "Average minibatch loss at step 6386: 2.288\n",
      "Average minibatch loss at step 6388: 2.146\n",
      "Average minibatch loss at step 6390: 2.085\n",
      "Average minibatch loss at step 6392: 2.208\n",
      "Average minibatch loss at step 6394: 2.515\n",
      "Average minibatch loss at step 6396: 2.460\n",
      "Average minibatch loss at step 6398: 2.494\n",
      "Average minibatch loss at step 6400: 1.327\n",
      "Average minibatch loss at step 6402: 2.102\n",
      "Average minibatch loss at step 6404: 2.420\n",
      "Average minibatch loss at step 6406: 2.431\n",
      "Average minibatch loss at step 6408: 2.618\n",
      "Average minibatch loss at step 6410: 2.444\n",
      "Average minibatch loss at step 6412: 2.348\n",
      "Average minibatch loss at step 6414: 2.379\n",
      "Average minibatch loss at step 6416: 2.428\n",
      "Average minibatch loss at step 6418: 2.518\n",
      "Average minibatch loss at step 6420: 2.505\n",
      "Average minibatch loss at step 6422: 2.227\n",
      "Average minibatch loss at step 6424: 2.330\n",
      "Average minibatch loss at step 6426: 2.396\n",
      "Average minibatch loss at step 6428: 2.301\n",
      "Average minibatch loss at step 6430: 2.459\n",
      "Average minibatch loss at step 6432: 1.179\n",
      "Average minibatch loss at step 6434: 2.079\n",
      "Average minibatch loss at step 6436: 2.373\n",
      "Average minibatch loss at step 6438: 2.317\n",
      "Average minibatch loss at step 6440: 2.521\n",
      "Average minibatch loss at step 6442: 2.146\n",
      "Average minibatch loss at step 6444: 2.101\n",
      "Average minibatch loss at step 6446: 2.137\n",
      "Average minibatch loss at step 6448: 2.523\n",
      "Average minibatch loss at step 6450: 2.539\n",
      "Average minibatch loss at step 6452: 2.187\n",
      "Average minibatch loss at step 6454: 2.175\n",
      "Average minibatch loss at step 6456: 2.331\n",
      "Average minibatch loss at step 6458: 2.607\n",
      "Average minibatch loss at step 6460: 2.607\n",
      "Average minibatch loss at step 6462: 2.469\n",
      "Average minibatch loss at step 6464: 1.092\n",
      "Average minibatch loss at step 6466: 2.054\n",
      "Average minibatch loss at step 6468: 2.331\n",
      "Average minibatch loss at step 6470: 2.251\n",
      "Average minibatch loss at step 6472: 2.427\n",
      "Average minibatch loss at step 6474: 2.263\n",
      "Average minibatch loss at step 6476: 2.518\n",
      "Average minibatch loss at step 6478: 2.171\n",
      "Average minibatch loss at step 6480: 2.346\n",
      "Average minibatch loss at step 6482: 2.288\n",
      "Average minibatch loss at step 6484: 2.027\n",
      "Average minibatch loss at step 6486: 1.907\n",
      "Average minibatch loss at step 6488: 2.100\n",
      "Average minibatch loss at step 6490: 2.458\n",
      "Average minibatch loss at step 6492: 2.198\n",
      "Average minibatch loss at step 6494: 2.332\n",
      "Average minibatch loss at step 6496: 1.120\n",
      "Average minibatch loss at step 6498: 1.964\n",
      "Average minibatch loss at step 6500: 2.321\n",
      "Average minibatch loss at step 6502: 2.257\n",
      "Average minibatch loss at step 6504: 2.319\n",
      "Average minibatch loss at step 6506: 2.200\n",
      "Average minibatch loss at step 6508: 2.221\n",
      "Average minibatch loss at step 6510: 2.110\n",
      "Average minibatch loss at step 6512: 2.217\n",
      "Average minibatch loss at step 6514: 2.167\n",
      "Average minibatch loss at step 6516: 2.044\n",
      "Average minibatch loss at step 6518: 1.875\n",
      "Average minibatch loss at step 6520: 2.006\n",
      "Average minibatch loss at step 6522: 2.174\n",
      "Average minibatch loss at step 6524: 2.095\n",
      "Average minibatch loss at step 6526: 2.343\n",
      "Average minibatch loss at step 6528: 1.214\n",
      "Average minibatch loss at step 6530: 1.893\n",
      "Average minibatch loss at step 6532: 2.223\n",
      "Average minibatch loss at step 6534: 2.279\n",
      "Average minibatch loss at step 6536: 2.322\n",
      "Average minibatch loss at step 6538: 2.005\n",
      "Average minibatch loss at step 6540: 1.936\n",
      "Average minibatch loss at step 6542: 1.887\n",
      "Average minibatch loss at step 6544: 2.120\n",
      "Average minibatch loss at step 6546: 2.177\n",
      "Average minibatch loss at step 6548: 2.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 6550: 1.901\n",
      "Average minibatch loss at step 6552: 2.053\n",
      "Average minibatch loss at step 6554: 2.224\n",
      "Average minibatch loss at step 6556: 2.042\n",
      "Average minibatch loss at step 6558: 2.290\n",
      "Average minibatch loss at step 6560: 1.035\n",
      "Average minibatch loss at step 6562: 1.814\n",
      "Average minibatch loss at step 6564: 2.046\n",
      "Average minibatch loss at step 6566: 2.041\n",
      "Average minibatch loss at step 6568: 2.192\n",
      "Average minibatch loss at step 6570: 1.999\n",
      "Average minibatch loss at step 6572: 1.997\n",
      "Average minibatch loss at step 6574: 1.867\n",
      "Average minibatch loss at step 6576: 2.000\n",
      "Average minibatch loss at step 6578: 2.020\n",
      "Average minibatch loss at step 6580: 1.828\n",
      "Average minibatch loss at step 6582: 1.780\n",
      "Average minibatch loss at step 6584: 1.925\n",
      "Average minibatch loss at step 6586: 2.101\n",
      "Average minibatch loss at step 6588: 2.010\n",
      "Average minibatch loss at step 6590: 2.162\n",
      "Average minibatch loss at step 6592: 1.058\n",
      "Average minibatch loss at step 6594: 1.772\n",
      "Average minibatch loss at step 6596: 2.135\n",
      "Average minibatch loss at step 6598: 2.172\n",
      "Average minibatch loss at step 6600: 2.423\n",
      "Average minibatch loss at step 6602: 2.112\n",
      "Average minibatch loss at step 6604: 1.972\n",
      "Average minibatch loss at step 6606: 1.890\n",
      "Average minibatch loss at step 6608: 1.920\n",
      "Average minibatch loss at step 6610: 1.924\n",
      "Average minibatch loss at step 6612: 1.795\n",
      "Average minibatch loss at step 6614: 1.780\n",
      "Average minibatch loss at step 6616: 1.887\n",
      "Average minibatch loss at step 6618: 2.000\n",
      "Average minibatch loss at step 6620: 2.031\n",
      "Average minibatch loss at step 6622: 2.155\n",
      "Average minibatch loss at step 6624: 0.951\n",
      "Average minibatch loss at step 6626: 1.792\n",
      "Average minibatch loss at step 6628: 2.164\n",
      "Average minibatch loss at step 6630: 2.593\n",
      "Average minibatch loss at step 6632: 2.571\n",
      "Average minibatch loss at step 6634: 2.402\n",
      "Average minibatch loss at step 6636: 2.455\n",
      "Average minibatch loss at step 6638: 2.226\n",
      "Average minibatch loss at step 6640: 2.229\n",
      "Average minibatch loss at step 6642: 2.185\n",
      "Average minibatch loss at step 6644: 1.813\n",
      "Average minibatch loss at step 6646: 1.707\n",
      "Average minibatch loss at step 6648: 2.050\n",
      "Average minibatch loss at step 6650: 2.282\n",
      "Average minibatch loss at step 6652: 2.230\n",
      "Average minibatch loss at step 6654: 2.272\n",
      "Average minibatch loss at step 6656: 1.254\n",
      "Average minibatch loss at step 6658: 1.860\n",
      "Average minibatch loss at step 6660: 2.226\n",
      "Average minibatch loss at step 6662: 2.115\n",
      "Average minibatch loss at step 6664: 2.201\n",
      "Average minibatch loss at step 6666: 1.957\n",
      "Average minibatch loss at step 6668: 1.885\n",
      "Average minibatch loss at step 6670: 1.906\n",
      "Average minibatch loss at step 6672: 1.921\n",
      "Average minibatch loss at step 6674: 1.931\n",
      "Average minibatch loss at step 6676: 1.850\n",
      "Average minibatch loss at step 6678: 1.723\n",
      "Average minibatch loss at step 6680: 1.904\n",
      "Average minibatch loss at step 6682: 2.109\n",
      "Average minibatch loss at step 6684: 1.998\n",
      "Average minibatch loss at step 6686: 2.133\n",
      "Average minibatch loss at step 6688: 0.902\n",
      "Average minibatch loss at step 6690: 1.626\n",
      "Average minibatch loss at step 6692: 1.898\n",
      "Average minibatch loss at step 6694: 2.031\n",
      "Average minibatch loss at step 6696: 2.223\n",
      "Average minibatch loss at step 6698: 1.962\n",
      "Average minibatch loss at step 6700: 1.890\n",
      "Average minibatch loss at step 6702: 1.707\n",
      "Average minibatch loss at step 6704: 1.862\n",
      "Average minibatch loss at step 6706: 1.878\n",
      "Average minibatch loss at step 6708: 1.740\n",
      "Average minibatch loss at step 6710: 1.656\n",
      "Average minibatch loss at step 6712: 1.767\n",
      "Average minibatch loss at step 6714: 1.966\n",
      "Average minibatch loss at step 6716: 1.950\n",
      "Average minibatch loss at step 6718: 1.956\n",
      "Average minibatch loss at step 6720: 0.805\n",
      "Average minibatch loss at step 6722: 1.591\n",
      "Average minibatch loss at step 6724: 1.883\n",
      "Average minibatch loss at step 6726: 1.927\n",
      "Average minibatch loss at step 6728: 1.993\n",
      "Average minibatch loss at step 6730: 1.816\n",
      "Average minibatch loss at step 6732: 1.869\n",
      "Average minibatch loss at step 6734: 1.768\n",
      "Average minibatch loss at step 6736: 1.909\n",
      "Average minibatch loss at step 6738: 1.892\n",
      "Average minibatch loss at step 6740: 1.574\n",
      "Average minibatch loss at step 6742: 1.540\n",
      "Average minibatch loss at step 6744: 1.918\n",
      "Average minibatch loss at step 6746: 2.158\n",
      "Average minibatch loss at step 6748: 1.900\n",
      "Average minibatch loss at step 6750: 1.936\n",
      "Average minibatch loss at step 6752: 0.843\n",
      "Average minibatch loss at step 6754: 1.534\n",
      "Average minibatch loss at step 6756: 1.800\n",
      "Average minibatch loss at step 6758: 1.839\n",
      "Average minibatch loss at step 6760: 2.215\n",
      "Average minibatch loss at step 6762: 1.914\n",
      "Average minibatch loss at step 6764: 1.768\n",
      "Average minibatch loss at step 6766: 1.861\n",
      "Average minibatch loss at step 6768: 1.860\n",
      "Average minibatch loss at step 6770: 2.025\n",
      "Average minibatch loss at step 6772: 1.966\n",
      "Average minibatch loss at step 6774: 1.878\n",
      "Average minibatch loss at step 6776: 2.058\n",
      "Average minibatch loss at step 6778: 1.990\n",
      "Average minibatch loss at step 6780: 1.957\n",
      "Average minibatch loss at step 6782: 1.943\n",
      "Average minibatch loss at step 6784: 0.843\n",
      "Average minibatch loss at step 6786: 1.542\n",
      "Average minibatch loss at step 6788: 1.805\n",
      "Average minibatch loss at step 6790: 1.878\n",
      "Average minibatch loss at step 6792: 2.063\n",
      "Average minibatch loss at step 6794: 1.922\n",
      "Average minibatch loss at step 6796: 1.709\n",
      "Average minibatch loss at step 6798: 1.710\n",
      "Average minibatch loss at step 6800: 1.911\n",
      "Average minibatch loss at step 6802: 1.857\n",
      "Average minibatch loss at step 6804: 1.648\n",
      "Average minibatch loss at step 6806: 1.961\n",
      "Average minibatch loss at step 6808: 2.201\n",
      "Average minibatch loss at step 6810: 2.004\n",
      "Average minibatch loss at step 6812: 1.786\n",
      "Average minibatch loss at step 6814: 1.855\n",
      "Average minibatch loss at step 6816: 0.905\n",
      "Average minibatch loss at step 6818: 1.508\n",
      "Average minibatch loss at step 6820: 1.848\n",
      "Average minibatch loss at step 6822: 1.861\n",
      "Average minibatch loss at step 6824: 1.899\n",
      "Average minibatch loss at step 6826: 1.730\n",
      "Average minibatch loss at step 6828: 1.784\n",
      "Average minibatch loss at step 6830: 1.648\n",
      "Average minibatch loss at step 6832: 1.868\n",
      "Average minibatch loss at step 6834: 1.932\n",
      "Average minibatch loss at step 6836: 1.711\n",
      "Average minibatch loss at step 6838: 1.655\n",
      "Average minibatch loss at step 6840: 1.819\n",
      "Average minibatch loss at step 6842: 1.826\n",
      "Average minibatch loss at step 6844: 1.829\n",
      "Average minibatch loss at step 6846: 1.766\n",
      "Average minibatch loss at step 6848: 0.741\n",
      "Average minibatch loss at step 6850: 1.404\n",
      "Average minibatch loss at step 6852: 1.689\n",
      "Average minibatch loss at step 6854: 1.851\n",
      "Average minibatch loss at step 6856: 2.028\n",
      "Average minibatch loss at step 6858: 1.666\n",
      "Average minibatch loss at step 6860: 1.587\n",
      "Average minibatch loss at step 6862: 1.496\n",
      "Average minibatch loss at step 6864: 1.648\n",
      "Average minibatch loss at step 6866: 1.843\n",
      "Average minibatch loss at step 6868: 1.503\n",
      "Average minibatch loss at step 6870: 1.432\n",
      "Average minibatch loss at step 6872: 1.546\n",
      "Average minibatch loss at step 6874: 1.637\n",
      "Average minibatch loss at step 6876: 1.515\n",
      "Average minibatch loss at step 6878: 1.687\n",
      "Average minibatch loss at step 6880: 0.668\n",
      "Average minibatch loss at step 6882: 1.357\n",
      "Average minibatch loss at step 6884: 1.576\n",
      "Average minibatch loss at step 6886: 1.879\n",
      "Average minibatch loss at step 6888: 1.838\n",
      "Average minibatch loss at step 6890: 1.654\n",
      "Average minibatch loss at step 6892: 1.509\n",
      "Average minibatch loss at step 6894: 1.461\n",
      "Average minibatch loss at step 6896: 1.537\n",
      "Average minibatch loss at step 6898: 1.615\n",
      "Average minibatch loss at step 6900: 1.666\n",
      "Average minibatch loss at step 6902: 1.568\n",
      "Average minibatch loss at step 6904: 1.909\n",
      "Average minibatch loss at step 6906: 2.135\n",
      "Average minibatch loss at step 6908: 1.736\n",
      "Average minibatch loss at step 6910: 1.677\n",
      "Average minibatch loss at step 6912: 0.737\n",
      "Average minibatch loss at step 6914: 1.409\n",
      "Average minibatch loss at step 6916: 1.583\n",
      "Average minibatch loss at step 6918: 1.672\n",
      "Average minibatch loss at step 6920: 1.726\n",
      "Average minibatch loss at step 6922: 1.609\n",
      "Average minibatch loss at step 6924: 1.507\n",
      "Average minibatch loss at step 6926: 1.471\n",
      "Average minibatch loss at step 6928: 1.599\n",
      "Average minibatch loss at step 6930: 1.680\n",
      "Average minibatch loss at step 6932: 1.463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 6934: 1.351\n",
      "Average minibatch loss at step 6936: 1.499\n",
      "Average minibatch loss at step 6938: 1.692\n",
      "Average minibatch loss at step 6940: 1.903\n",
      "Average minibatch loss at step 6942: 2.538\n",
      "Average minibatch loss at step 6944: 1.973\n",
      "Average minibatch loss at step 6946: 2.867\n",
      "Average minibatch loss at step 6948: 2.129\n",
      "Average minibatch loss at step 6950: 2.401\n",
      "Average minibatch loss at step 6952: 1.936\n",
      "Average minibatch loss at step 6954: 1.690\n",
      "Average minibatch loss at step 6956: 1.620\n",
      "Average minibatch loss at step 6958: 1.465\n",
      "Average minibatch loss at step 6960: 1.571\n",
      "Average minibatch loss at step 6962: 1.528\n",
      "Average minibatch loss at step 6964: 1.523\n",
      "Average minibatch loss at step 6966: 1.327\n",
      "Average minibatch loss at step 6968: 1.394\n",
      "Average minibatch loss at step 6970: 1.572\n",
      "Average minibatch loss at step 6972: 1.503\n",
      "Average minibatch loss at step 6974: 1.572\n",
      "Average minibatch loss at step 6976: 0.649\n",
      "Average minibatch loss at step 6978: 1.311\n",
      "Average minibatch loss at step 6980: 1.528\n",
      "Average minibatch loss at step 6982: 1.694\n",
      "Average minibatch loss at step 6984: 1.653\n",
      "Average minibatch loss at step 6986: 1.476\n",
      "Average minibatch loss at step 6988: 1.413\n",
      "Average minibatch loss at step 6990: 1.481\n",
      "Average minibatch loss at step 6992: 1.538\n",
      "Average minibatch loss at step 6994: 1.522\n",
      "Average minibatch loss at step 6996: 1.338\n",
      "Average minibatch loss at step 6998: 1.317\n",
      "Average minibatch loss at step 7000: 1.504\n",
      "Average minibatch loss at step 7002: 1.523\n",
      "Average minibatch loss at step 7004: 1.412\n",
      "Average minibatch loss at step 7006: 1.554\n",
      "Average minibatch loss at step 7008: 0.657\n",
      "Average minibatch loss at step 7010: 1.215\n",
      "Average minibatch loss at step 7012: 1.414\n",
      "Average minibatch loss at step 7014: 1.528\n",
      "Average minibatch loss at step 7016: 1.712\n",
      "Average minibatch loss at step 7018: 1.472\n",
      "Average minibatch loss at step 7020: 1.416\n",
      "Average minibatch loss at step 7022: 1.296\n",
      "Average minibatch loss at step 7024: 1.443\n",
      "Average minibatch loss at step 7026: 1.402\n",
      "Average minibatch loss at step 7028: 1.219\n",
      "Average minibatch loss at step 7030: 1.238\n",
      "Average minibatch loss at step 7032: 1.407\n",
      "Average minibatch loss at step 7034: 1.473\n",
      "Average minibatch loss at step 7036: 1.327\n",
      "Average minibatch loss at step 7038: 1.439\n",
      "Average minibatch loss at step 7040: 0.573\n",
      "Average minibatch loss at step 7042: 1.131\n",
      "Average minibatch loss at step 7044: 1.310\n",
      "Average minibatch loss at step 7046: 1.396\n",
      "Average minibatch loss at step 7048: 1.561\n",
      "Average minibatch loss at step 7050: 1.445\n",
      "Average minibatch loss at step 7052: 1.355\n",
      "Average minibatch loss at step 7054: 1.223\n",
      "Average minibatch loss at step 7056: 1.311\n",
      "Average minibatch loss at step 7058: 1.308\n",
      "Average minibatch loss at step 7060: 1.228\n",
      "Average minibatch loss at step 7062: 1.164\n",
      "Average minibatch loss at step 7064: 1.290\n",
      "Average minibatch loss at step 7066: 1.351\n",
      "Average minibatch loss at step 7068: 1.394\n",
      "Average minibatch loss at step 7070: 1.657\n",
      "Average minibatch loss at step 7072: 0.703\n",
      "Average minibatch loss at step 7074: 1.138\n",
      "Average minibatch loss at step 7076: 1.287\n",
      "Average minibatch loss at step 7078: 1.415\n",
      "Average minibatch loss at step 7080: 1.492\n",
      "Average minibatch loss at step 7082: 1.328\n",
      "Average minibatch loss at step 7084: 1.294\n",
      "Average minibatch loss at step 7086: 1.177\n",
      "Average minibatch loss at step 7088: 1.295\n",
      "Average minibatch loss at step 7090: 1.349\n",
      "Average minibatch loss at step 7092: 1.172\n",
      "Average minibatch loss at step 7094: 1.075\n",
      "Average minibatch loss at step 7096: 1.240\n",
      "Average minibatch loss at step 7098: 1.336\n",
      "Average minibatch loss at step 7100: 1.166\n",
      "Average minibatch loss at step 7102: 1.272\n",
      "Average minibatch loss at step 7104: 0.477\n",
      "Average minibatch loss at step 7106: 1.050\n",
      "Average minibatch loss at step 7108: 1.259\n",
      "Average minibatch loss at step 7110: 1.406\n",
      "Average minibatch loss at step 7112: 1.595\n",
      "Average minibatch loss at step 7114: 1.337\n",
      "Average minibatch loss at step 7116: 1.186\n",
      "Average minibatch loss at step 7118: 1.130\n",
      "Average minibatch loss at step 7120: 1.246\n",
      "Average minibatch loss at step 7122: 1.301\n",
      "Average minibatch loss at step 7124: 1.108\n",
      "Average minibatch loss at step 7126: 0.998\n",
      "Average minibatch loss at step 7128: 1.100\n",
      "Average minibatch loss at step 7130: 1.248\n",
      "Average minibatch loss at step 7132: 1.173\n",
      "Average minibatch loss at step 7134: 1.418\n",
      "Average minibatch loss at step 7136: 0.671\n",
      "Average minibatch loss at step 7138: 1.076\n",
      "Average minibatch loss at step 7140: 1.281\n",
      "Average minibatch loss at step 7142: 1.288\n",
      "Average minibatch loss at step 7144: 1.379\n",
      "Average minibatch loss at step 7146: 1.263\n",
      "Average minibatch loss at step 7148: 1.412\n",
      "Average minibatch loss at step 7150: 1.430\n",
      "Average minibatch loss at step 7152: 1.442\n",
      "Average minibatch loss at step 7154: 1.321\n",
      "Average minibatch loss at step 7156: 1.149\n",
      "Average minibatch loss at step 7158: 1.083\n",
      "Average minibatch loss at step 7160: 1.179\n",
      "Average minibatch loss at step 7162: 1.382\n",
      "Average minibatch loss at step 7164: 1.536\n",
      "Average minibatch loss at step 7166: 1.361\n",
      "Average minibatch loss at step 7168: 0.567\n",
      "Average minibatch loss at step 7170: 1.088\n",
      "Average minibatch loss at step 7172: 1.257\n",
      "Average minibatch loss at step 7174: 1.378\n",
      "Average minibatch loss at step 7176: 1.568\n",
      "Average minibatch loss at step 7178: 1.384\n",
      "Average minibatch loss at step 7180: 1.403\n",
      "Average minibatch loss at step 7182: 1.569\n",
      "Average minibatch loss at step 7184: 1.671\n",
      "Average minibatch loss at step 7186: 1.792\n",
      "Average minibatch loss at step 7188: 1.380\n",
      "Average minibatch loss at step 7190: 1.092\n",
      "Average minibatch loss at step 7192: 1.214\n",
      "Average minibatch loss at step 7194: 1.436\n",
      "Average minibatch loss at step 7196: 1.849\n",
      "Average minibatch loss at step 7198: 1.842\n",
      "Average minibatch loss at step 7200: 0.588\n",
      "Average minibatch loss at step 7202: 1.141\n",
      "Average minibatch loss at step 7204: 1.242\n",
      "Average minibatch loss at step 7206: 1.326\n",
      "Average minibatch loss at step 7208: 1.482\n",
      "Average minibatch loss at step 7210: 1.315\n",
      "Average minibatch loss at step 7212: 1.180\n",
      "Average minibatch loss at step 7214: 1.031\n",
      "Average minibatch loss at step 7216: 1.090\n",
      "Average minibatch loss at step 7218: 1.148\n",
      "Average minibatch loss at step 7220: 1.019\n",
      "Average minibatch loss at step 7222: 0.967\n",
      "Average minibatch loss at step 7224: 1.050\n",
      "Average minibatch loss at step 7226: 1.212\n",
      "Average minibatch loss at step 7228: 1.394\n",
      "Average minibatch loss at step 7230: 1.402\n",
      "Average minibatch loss at step 7232: 0.543\n",
      "Average minibatch loss at step 7234: 1.019\n",
      "Average minibatch loss at step 7236: 1.134\n",
      "Average minibatch loss at step 7238: 1.186\n",
      "Average minibatch loss at step 7240: 1.330\n",
      "Average minibatch loss at step 7242: 1.229\n",
      "Average minibatch loss at step 7244: 1.116\n",
      "Average minibatch loss at step 7246: 1.044\n",
      "Average minibatch loss at step 7248: 1.037\n",
      "Average minibatch loss at step 7250: 1.072\n",
      "Average minibatch loss at step 7252: 0.958\n",
      "Average minibatch loss at step 7254: 0.913\n",
      "Average minibatch loss at step 7256: 0.994\n",
      "Average minibatch loss at step 7258: 1.102\n",
      "Average minibatch loss at step 7260: 1.155\n",
      "Average minibatch loss at step 7262: 1.150\n",
      "Average minibatch loss at step 7264: 0.385\n",
      "Average minibatch loss at step 7266: 0.958\n",
      "Average minibatch loss at step 7268: 1.168\n",
      "Average minibatch loss at step 7270: 1.437\n",
      "Average minibatch loss at step 7272: 1.632\n",
      "Average minibatch loss at step 7274: 1.141\n",
      "Average minibatch loss at step 7276: 1.008\n",
      "Average minibatch loss at step 7278: 0.950\n",
      "Average minibatch loss at step 7280: 1.031\n",
      "Average minibatch loss at step 7282: 1.069\n",
      "Average minibatch loss at step 7284: 0.944\n",
      "Average minibatch loss at step 7286: 0.906\n",
      "Average minibatch loss at step 7288: 0.967\n",
      "Average minibatch loss at step 7290: 1.079\n",
      "Average minibatch loss at step 7292: 0.993\n",
      "Average minibatch loss at step 7294: 1.032\n",
      "Average minibatch loss at step 7296: 0.403\n",
      "Average minibatch loss at step 7298: 0.862\n",
      "Average minibatch loss at step 7300: 0.968\n",
      "Average minibatch loss at step 7302: 1.009\n",
      "Average minibatch loss at step 7304: 1.117\n",
      "Average minibatch loss at step 7306: 1.013\n",
      "Average minibatch loss at step 7308: 0.930\n",
      "Average minibatch loss at step 7310: 0.896\n",
      "Average minibatch loss at step 7312: 0.916\n",
      "Average minibatch loss at step 7314: 1.015\n",
      "Average minibatch loss at step 7316: 0.927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 7318: 0.884\n",
      "Average minibatch loss at step 7320: 0.937\n",
      "Average minibatch loss at step 7322: 0.985\n",
      "Average minibatch loss at step 7324: 0.920\n",
      "Average minibatch loss at step 7326: 0.971\n",
      "Average minibatch loss at step 7328: 0.377\n",
      "Average minibatch loss at step 7330: 0.801\n",
      "Average minibatch loss at step 7332: 0.934\n",
      "Average minibatch loss at step 7334: 1.016\n",
      "Average minibatch loss at step 7336: 1.093\n",
      "Average minibatch loss at step 7338: 0.909\n",
      "Average minibatch loss at step 7340: 0.847\n",
      "Average minibatch loss at step 7342: 0.818\n",
      "Average minibatch loss at step 7344: 0.968\n",
      "Average minibatch loss at step 7346: 0.976\n",
      "Average minibatch loss at step 7348: 0.796\n",
      "Average minibatch loss at step 7350: 0.774\n",
      "Average minibatch loss at step 7352: 0.917\n",
      "Average minibatch loss at step 7354: 1.038\n",
      "Average minibatch loss at step 7356: 0.960\n",
      "Average minibatch loss at step 7358: 0.995\n",
      "Average minibatch loss at step 7360: 0.373\n",
      "Average minibatch loss at step 7362: 0.800\n",
      "Average minibatch loss at step 7364: 0.918\n",
      "Average minibatch loss at step 7366: 1.034\n",
      "Average minibatch loss at step 7368: 1.160\n",
      "Average minibatch loss at step 7370: 0.984\n",
      "Average minibatch loss at step 7372: 0.848\n",
      "Average minibatch loss at step 7374: 0.824\n",
      "Average minibatch loss at step 7376: 0.876\n",
      "Average minibatch loss at step 7378: 0.904\n",
      "Average minibatch loss at step 7380: 0.778\n",
      "Average minibatch loss at step 7382: 0.732\n",
      "Average minibatch loss at step 7384: 0.829\n",
      "Average minibatch loss at step 7386: 0.919\n",
      "Average minibatch loss at step 7388: 0.855\n",
      "Average minibatch loss at step 7390: 0.942\n",
      "Average minibatch loss at step 7392: 0.388\n",
      "Average minibatch loss at step 7394: 0.722\n",
      "Average minibatch loss at step 7396: 0.839\n",
      "Average minibatch loss at step 7398: 0.958\n",
      "Average minibatch loss at step 7400: 1.210\n",
      "Average minibatch loss at step 7402: 1.088\n",
      "Average minibatch loss at step 7404: 0.861\n",
      "Average minibatch loss at step 7406: 0.771\n",
      "Average minibatch loss at step 7408: 0.825\n",
      "Average minibatch loss at step 7410: 0.915\n",
      "Average minibatch loss at step 7412: 0.778\n",
      "Average minibatch loss at step 7414: 0.747\n",
      "Average minibatch loss at step 7416: 0.863\n",
      "Average minibatch loss at step 7418: 0.970\n",
      "Average minibatch loss at step 7420: 0.804\n",
      "Average minibatch loss at step 7422: 0.851\n",
      "Average minibatch loss at step 7424: 0.345\n",
      "Average minibatch loss at step 7426: 0.719\n",
      "Average minibatch loss at step 7428: 0.858\n",
      "Average minibatch loss at step 7430: 0.913\n",
      "Average minibatch loss at step 7432: 1.050\n",
      "Average minibatch loss at step 7434: 0.901\n",
      "Average minibatch loss at step 7436: 0.798\n",
      "Average minibatch loss at step 7438: 0.728\n",
      "Average minibatch loss at step 7440: 0.787\n",
      "Average minibatch loss at step 7442: 0.834\n",
      "Average minibatch loss at step 7444: 0.737\n",
      "Average minibatch loss at step 7446: 0.675\n",
      "Average minibatch loss at step 7448: 0.745\n",
      "Average minibatch loss at step 7450: 0.834\n",
      "Average minibatch loss at step 7452: 0.767\n",
      "Average minibatch loss at step 7454: 0.805\n",
      "Average minibatch loss at step 7456: 0.313\n",
      "Average minibatch loss at step 7458: 0.665\n",
      "Average minibatch loss at step 7460: 0.778\n",
      "Average minibatch loss at step 7462: 0.851\n",
      "Average minibatch loss at step 7464: 1.005\n",
      "Average minibatch loss at step 7466: 0.904\n",
      "Average minibatch loss at step 7468: 0.799\n",
      "Average minibatch loss at step 7470: 0.700\n",
      "Average minibatch loss at step 7472: 0.737\n",
      "Average minibatch loss at step 7474: 0.824\n",
      "Average minibatch loss at step 7476: 0.714\n",
      "Average minibatch loss at step 7478: 0.666\n",
      "Average minibatch loss at step 7480: 0.738\n",
      "Average minibatch loss at step 7482: 0.786\n",
      "Average minibatch loss at step 7484: 0.751\n",
      "Average minibatch loss at step 7486: 0.901\n",
      "Average minibatch loss at step 7488: 0.379\n",
      "Average minibatch loss at step 7490: 0.680\n",
      "Average minibatch loss at step 7492: 0.805\n",
      "Average minibatch loss at step 7494: 0.764\n",
      "Average minibatch loss at step 7496: 0.978\n",
      "Average minibatch loss at step 7498: 0.831\n",
      "Average minibatch loss at step 7500: 0.744\n",
      "Average minibatch loss at step 7502: 0.657\n",
      "Average minibatch loss at step 7504: 0.709\n",
      "Average minibatch loss at step 7506: 0.791\n",
      "Average minibatch loss at step 7508: 0.688\n",
      "Average minibatch loss at step 7510: 0.659\n",
      "Average minibatch loss at step 7512: 0.740\n",
      "Average minibatch loss at step 7514: 0.819\n",
      "Average minibatch loss at step 7516: 0.931\n",
      "Average minibatch loss at step 7518: 0.972\n",
      "Average minibatch loss at step 7520: 0.328\n",
      "Average minibatch loss at step 7522: 0.680\n",
      "Average minibatch loss at step 7524: 0.770\n",
      "Average minibatch loss at step 7526: 0.768\n",
      "Average minibatch loss at step 7528: 0.892\n",
      "Average minibatch loss at step 7530: 0.828\n",
      "Average minibatch loss at step 7532: 0.737\n",
      "Average minibatch loss at step 7534: 0.670\n",
      "Average minibatch loss at step 7536: 0.766\n",
      "Average minibatch loss at step 7538: 0.767\n",
      "Average minibatch loss at step 7540: 0.694\n",
      "Average minibatch loss at step 7542: 0.694\n",
      "Average minibatch loss at step 7544: 0.756\n",
      "Average minibatch loss at step 7546: 0.740\n",
      "Average minibatch loss at step 7548: 0.698\n",
      "Average minibatch loss at step 7550: 0.752\n",
      "Average minibatch loss at step 7552: 0.315\n",
      "Average minibatch loss at step 7554: 0.636\n",
      "Average minibatch loss at step 7556: 0.685\n",
      "Average minibatch loss at step 7558: 0.735\n",
      "Average minibatch loss at step 7560: 1.010\n",
      "Average minibatch loss at step 7562: 0.867\n",
      "Average minibatch loss at step 7564: 0.848\n",
      "Average minibatch loss at step 7566: 0.924\n",
      "Average minibatch loss at step 7568: 1.261\n",
      "Average minibatch loss at step 7570: 1.771\n",
      "Average minibatch loss at step 7572: 1.507\n",
      "Average minibatch loss at step 7574: 1.692\n",
      "Average minibatch loss at step 7576: 2.607\n",
      "Average minibatch loss at step 7578: 3.082\n",
      "Average minibatch loss at step 7580: 2.247\n",
      "Average minibatch loss at step 7582: 2.835\n",
      "Average minibatch loss at step 7584: 1.659\n",
      "Average minibatch loss at step 7586: 1.822\n",
      "Average minibatch loss at step 7588: 1.632\n",
      "Average minibatch loss at step 7590: 1.555\n",
      "Average minibatch loss at step 7592: 1.603\n",
      "Average minibatch loss at step 7594: 1.510\n",
      "Average minibatch loss at step 7596: 1.310\n",
      "Average minibatch loss at step 7598: 1.173\n",
      "Average minibatch loss at step 7600: 1.482\n",
      "Average minibatch loss at step 7602: 1.752\n",
      "Average minibatch loss at step 7604: 1.201\n",
      "Average minibatch loss at step 7606: 1.059\n",
      "Average minibatch loss at step 7608: 1.098\n",
      "Average minibatch loss at step 7610: 1.260\n",
      "Average minibatch loss at step 7612: 1.282\n",
      "Average minibatch loss at step 7614: 1.123\n",
      "Average minibatch loss at step 7616: 0.488\n",
      "Average minibatch loss at step 7618: 0.893\n",
      "Average minibatch loss at step 7620: 1.495\n",
      "Average minibatch loss at step 7622: 1.608\n",
      "Average minibatch loss at step 7624: 1.316\n",
      "Average minibatch loss at step 7626: 1.134\n",
      "Average minibatch loss at step 7628: 1.059\n",
      "Average minibatch loss at step 7630: 0.936\n",
      "Average minibatch loss at step 7632: 0.959\n",
      "Average minibatch loss at step 7634: 0.911\n",
      "Average minibatch loss at step 7636: 0.787\n",
      "Average minibatch loss at step 7638: 0.763\n",
      "Average minibatch loss at step 7640: 0.821\n",
      "Average minibatch loss at step 7642: 0.895\n",
      "Average minibatch loss at step 7644: 0.769\n",
      "Average minibatch loss at step 7646: 0.799\n",
      "Average minibatch loss at step 7648: 0.299\n",
      "Average minibatch loss at step 7650: 0.701\n",
      "Average minibatch loss at step 7652: 0.751\n",
      "Average minibatch loss at step 7654: 0.944\n",
      "Average minibatch loss at step 7656: 0.939\n",
      "Average minibatch loss at step 7658: 0.793\n",
      "Average minibatch loss at step 7660: 0.680\n",
      "Average minibatch loss at step 7662: 0.671\n",
      "Average minibatch loss at step 7664: 0.703\n",
      "Average minibatch loss at step 7666: 0.714\n",
      "Average minibatch loss at step 7668: 0.612\n",
      "Average minibatch loss at step 7670: 0.600\n",
      "Average minibatch loss at step 7672: 0.694\n",
      "Average minibatch loss at step 7674: 0.735\n",
      "Average minibatch loss at step 7676: 0.671\n",
      "Average minibatch loss at step 7678: 0.683\n",
      "Average minibatch loss at step 7680: 0.266\n",
      "Average minibatch loss at step 7682: 0.596\n",
      "Average minibatch loss at step 7684: 0.637\n",
      "Average minibatch loss at step 7686: 0.659\n",
      "Average minibatch loss at step 7688: 0.885\n",
      "Average minibatch loss at step 7690: 0.698\n",
      "Average minibatch loss at step 7692: 0.612\n",
      "Average minibatch loss at step 7694: 0.567\n",
      "Average minibatch loss at step 7696: 0.602\n",
      "Average minibatch loss at step 7698: 0.625\n",
      "Average minibatch loss at step 7700: 0.555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 7702: 0.504\n",
      "Average minibatch loss at step 7704: 0.560\n",
      "Average minibatch loss at step 7706: 0.593\n",
      "Average minibatch loss at step 7708: 0.575\n",
      "Average minibatch loss at step 7710: 0.606\n",
      "Average minibatch loss at step 7712: 0.247\n",
      "Average minibatch loss at step 7714: 0.525\n",
      "Average minibatch loss at step 7716: 0.568\n",
      "Average minibatch loss at step 7718: 0.591\n",
      "Average minibatch loss at step 7720: 0.753\n",
      "Average minibatch loss at step 7722: 0.618\n",
      "Average minibatch loss at step 7724: 0.532\n",
      "Average minibatch loss at step 7726: 0.496\n",
      "Average minibatch loss at step 7728: 0.549\n",
      "Average minibatch loss at step 7730: 0.566\n",
      "Average minibatch loss at step 7732: 0.494\n",
      "Average minibatch loss at step 7734: 0.458\n",
      "Average minibatch loss at step 7736: 0.519\n",
      "Average minibatch loss at step 7738: 0.561\n",
      "Average minibatch loss at step 7740: 0.515\n",
      "Average minibatch loss at step 7742: 0.542\n",
      "Average minibatch loss at step 7744: 0.210\n",
      "Average minibatch loss at step 7746: 0.474\n",
      "Average minibatch loss at step 7748: 0.517\n",
      "Average minibatch loss at step 7750: 0.525\n",
      "Average minibatch loss at step 7752: 0.629\n",
      "Average minibatch loss at step 7754: 0.542\n",
      "Average minibatch loss at step 7756: 0.479\n",
      "Average minibatch loss at step 7758: 0.449\n",
      "Average minibatch loss at step 7760: 0.513\n",
      "Average minibatch loss at step 7762: 0.539\n",
      "Average minibatch loss at step 7764: 0.490\n",
      "Average minibatch loss at step 7766: 0.453\n",
      "Average minibatch loss at step 7768: 0.488\n",
      "Average minibatch loss at step 7770: 0.520\n",
      "Average minibatch loss at step 7772: 0.477\n",
      "Average minibatch loss at step 7774: 0.560\n",
      "Average minibatch loss at step 7776: 0.395\n",
      "Average minibatch loss at step 7778: 0.477\n",
      "Average minibatch loss at step 7780: 0.520\n",
      "Average minibatch loss at step 7782: 0.572\n",
      "Average minibatch loss at step 7784: 0.656\n",
      "Average minibatch loss at step 7786: 0.534\n",
      "Average minibatch loss at step 7788: 0.452\n",
      "Average minibatch loss at step 7790: 0.440\n",
      "Average minibatch loss at step 7792: 0.495\n",
      "Average minibatch loss at step 7794: 0.504\n",
      "Average minibatch loss at step 7796: 0.445\n",
      "Average minibatch loss at step 7798: 0.422\n",
      "Average minibatch loss at step 7800: 0.463\n",
      "Average minibatch loss at step 7802: 0.488\n",
      "Average minibatch loss at step 7804: 0.448\n",
      "Average minibatch loss at step 7806: 0.500\n",
      "Average minibatch loss at step 7808: 0.234\n",
      "Average minibatch loss at step 7810: 0.468\n",
      "Average minibatch loss at step 7812: 0.490\n",
      "Average minibatch loss at step 7814: 0.596\n",
      "Average minibatch loss at step 7816: 0.565\n",
      "Average minibatch loss at step 7818: 0.553\n",
      "Average minibatch loss at step 7820: 0.461\n",
      "Average minibatch loss at step 7822: 0.431\n",
      "Average minibatch loss at step 7824: 0.461\n",
      "Average minibatch loss at step 7826: 0.487\n",
      "Average minibatch loss at step 7828: 0.438\n",
      "Average minibatch loss at step 7830: 0.441\n",
      "Average minibatch loss at step 7832: 0.439\n",
      "Average minibatch loss at step 7834: 0.478\n",
      "Average minibatch loss at step 7836: 0.440\n",
      "Average minibatch loss at step 7838: 0.461\n",
      "Average minibatch loss at step 7840: 0.189\n",
      "Average minibatch loss at step 7842: 0.425\n",
      "Average minibatch loss at step 7844: 0.465\n",
      "Average minibatch loss at step 7846: 0.509\n",
      "Average minibatch loss at step 7848: 0.611\n",
      "Average minibatch loss at step 7850: 0.489\n",
      "Average minibatch loss at step 7852: 0.443\n",
      "Average minibatch loss at step 7854: 0.480\n",
      "Average minibatch loss at step 7856: 0.469\n",
      "Average minibatch loss at step 7858: 0.550\n",
      "Average minibatch loss at step 7860: 0.431\n",
      "Average minibatch loss at step 7862: 0.405\n",
      "Average minibatch loss at step 7864: 0.439\n",
      "Average minibatch loss at step 7866: 0.464\n",
      "Average minibatch loss at step 7868: 0.466\n",
      "Average minibatch loss at step 7870: 0.442\n",
      "Average minibatch loss at step 7872: 0.182\n",
      "Average minibatch loss at step 7874: 0.446\n",
      "Average minibatch loss at step 7876: 0.527\n",
      "Average minibatch loss at step 7878: 0.485\n",
      "Average minibatch loss at step 7880: 0.544\n",
      "Average minibatch loss at step 7882: 0.572\n",
      "Average minibatch loss at step 7884: 0.434\n",
      "Average minibatch loss at step 7886: 0.398\n",
      "Average minibatch loss at step 7888: 0.486\n",
      "Average minibatch loss at step 7890: 0.486\n",
      "Average minibatch loss at step 7892: 0.428\n",
      "Average minibatch loss at step 7894: 0.409\n",
      "Average minibatch loss at step 7896: 0.417\n",
      "Average minibatch loss at step 7898: 0.430\n",
      "Average minibatch loss at step 7900: 0.419\n",
      "Average minibatch loss at step 7902: 0.444\n",
      "Average minibatch loss at step 7904: 0.175\n",
      "Average minibatch loss at step 7906: 0.388\n",
      "Average minibatch loss at step 7908: 0.429\n",
      "Average minibatch loss at step 7910: 0.481\n",
      "Average minibatch loss at step 7912: 0.529\n",
      "Average minibatch loss at step 7914: 0.464\n",
      "Average minibatch loss at step 7916: 0.399\n",
      "Average minibatch loss at step 7918: 0.370\n",
      "Average minibatch loss at step 7920: 0.428\n",
      "Average minibatch loss at step 7922: 0.471\n",
      "Average minibatch loss at step 7924: 0.387\n",
      "Average minibatch loss at step 7926: 0.383\n",
      "Average minibatch loss at step 7928: 0.389\n",
      "Average minibatch loss at step 7930: 0.412\n",
      "Average minibatch loss at step 7932: 0.377\n",
      "Average minibatch loss at step 7934: 0.408\n",
      "Average minibatch loss at step 7936: 0.164\n",
      "Average minibatch loss at step 7938: 0.359\n",
      "Average minibatch loss at step 7940: 0.398\n",
      "Average minibatch loss at step 7942: 0.410\n",
      "Average minibatch loss at step 7944: 0.495\n",
      "Average minibatch loss at step 7946: 0.418\n",
      "Average minibatch loss at step 7948: 0.371\n",
      "Average minibatch loss at step 7950: 0.349\n",
      "Average minibatch loss at step 7952: 0.373\n",
      "Average minibatch loss at step 7954: 0.432\n",
      "Average minibatch loss at step 7956: 0.433\n",
      "Average minibatch loss at step 7958: 0.375\n",
      "Average minibatch loss at step 7960: 0.429\n",
      "Average minibatch loss at step 7962: 0.410\n",
      "Average minibatch loss at step 7964: 0.396\n",
      "Average minibatch loss at step 7966: 0.375\n",
      "Average minibatch loss at step 7968: 0.149\n",
      "Average minibatch loss at step 7970: 0.335\n",
      "Average minibatch loss at step 7972: 0.420\n",
      "Average minibatch loss at step 7974: 0.392\n",
      "Average minibatch loss at step 7976: 0.468\n",
      "Average minibatch loss at step 7978: 0.411\n",
      "Average minibatch loss at step 7980: 0.367\n",
      "Average minibatch loss at step 7982: 0.316\n",
      "Average minibatch loss at step 7984: 0.357\n",
      "Average minibatch loss at step 7986: 0.398\n",
      "Average minibatch loss at step 7988: 0.412\n",
      "Average minibatch loss at step 7990: 0.414\n",
      "Average minibatch loss at step 7992: 0.381\n",
      "Average minibatch loss at step 7994: 0.440\n",
      "Average minibatch loss at step 7996: 0.346\n",
      "Average minibatch loss at step 7998: 0.361\n",
      "Average minibatch loss at step 8000: 0.160\n",
      "Average minibatch loss at step 8002: 0.316\n",
      "Average minibatch loss at step 8004: 0.371\n",
      "Average minibatch loss at step 8006: 0.389\n",
      "Average minibatch loss at step 8008: 0.404\n",
      "Average minibatch loss at step 8010: 0.391\n",
      "Average minibatch loss at step 8012: 0.334\n",
      "Average minibatch loss at step 8014: 0.298\n",
      "Average minibatch loss at step 8016: 0.345\n",
      "Average minibatch loss at step 8018: 0.385\n",
      "Average minibatch loss at step 8020: 0.341\n",
      "Average minibatch loss at step 8022: 0.351\n",
      "Average minibatch loss at step 8024: 0.398\n",
      "Average minibatch loss at step 8026: 0.399\n",
      "Average minibatch loss at step 8028: 0.334\n",
      "Average minibatch loss at step 8030: 0.342\n",
      "Average minibatch loss at step 8032: 0.149\n",
      "Average minibatch loss at step 8034: 0.304\n",
      "Average minibatch loss at step 8036: 0.335\n",
      "Average minibatch loss at step 8038: 0.357\n",
      "Average minibatch loss at step 8040: 0.484\n",
      "Average minibatch loss at step 8042: 0.436\n",
      "Average minibatch loss at step 8044: 0.348\n",
      "Average minibatch loss at step 8046: 0.307\n",
      "Average minibatch loss at step 8048: 0.340\n",
      "Average minibatch loss at step 8050: 0.379\n",
      "Average minibatch loss at step 8052: 0.319\n",
      "Average minibatch loss at step 8054: 0.343\n",
      "Average minibatch loss at step 8056: 0.351\n",
      "Average minibatch loss at step 8058: 0.358\n",
      "Average minibatch loss at step 8060: 0.327\n",
      "Average minibatch loss at step 8062: 0.319\n",
      "Average minibatch loss at step 8064: 0.135\n",
      "Average minibatch loss at step 8066: 0.312\n",
      "Average minibatch loss at step 8068: 0.337\n",
      "Average minibatch loss at step 8070: 0.336\n",
      "Average minibatch loss at step 8072: 0.372\n",
      "Average minibatch loss at step 8074: 0.380\n",
      "Average minibatch loss at step 8076: 0.351\n",
      "Average minibatch loss at step 8078: 0.284\n",
      "Average minibatch loss at step 8080: 0.308\n",
      "Average minibatch loss at step 8082: 0.419\n",
      "Average minibatch loss at step 8084: 0.337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 8086: 0.314\n",
      "Average minibatch loss at step 8088: 0.335\n",
      "Average minibatch loss at step 8090: 0.324\n",
      "Average minibatch loss at step 8092: 0.322\n",
      "Average minibatch loss at step 8094: 0.306\n",
      "Average minibatch loss at step 8096: 0.130\n",
      "Average minibatch loss at step 8098: 0.298\n",
      "Average minibatch loss at step 8100: 0.323\n",
      "Average minibatch loss at step 8102: 0.394\n",
      "Average minibatch loss at step 8104: 0.388\n",
      "Average minibatch loss at step 8106: 0.366\n",
      "Average minibatch loss at step 8108: 0.287\n",
      "Average minibatch loss at step 8110: 0.275\n",
      "Average minibatch loss at step 8112: 0.304\n",
      "Average minibatch loss at step 8114: 0.350\n",
      "Average minibatch loss at step 8116: 0.292\n",
      "Average minibatch loss at step 8118: 0.288\n",
      "Average minibatch loss at step 8120: 0.305\n",
      "Average minibatch loss at step 8122: 0.306\n",
      "Average minibatch loss at step 8124: 0.285\n",
      "Average minibatch loss at step 8126: 0.286\n",
      "Average minibatch loss at step 8128: 0.135\n",
      "Average minibatch loss at step 8130: 0.274\n",
      "Average minibatch loss at step 8132: 0.279\n",
      "Average minibatch loss at step 8134: 0.326\n",
      "Average minibatch loss at step 8136: 0.331\n",
      "Average minibatch loss at step 8138: 0.307\n",
      "Average minibatch loss at step 8140: 0.278\n",
      "Average minibatch loss at step 8142: 0.262\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-404c4336e0a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average minibatch loss at step %d: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_scalars_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./all_scalars.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__float__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__float__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__float__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__float__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         raise TypeError(\"only 1-element tensors can be converted \"\n\u001b[1;32m    402\u001b[0m                         \"to Python scalars\")\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.fasttest = True\n",
    "epochs = 7000 #7000\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "train_df = pd.read_csv('datasets/train.csv')\n",
    "val_df = pd.read_csv('datasets/val.csv')\n",
    "iteration = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    if epoch % 1500 == 0: #500, 275\n",
    "        learning_rate = learning_rate / 2 #2\n",
    "        # Filter parameters that do not require gradients\n",
    "        encoder_parameters = filter(lambda p: p.requires_grad, encoder.parameters())\n",
    "        decoder_parameters = filter(lambda p: p.requires_grad, decoder.parameters())\n",
    "        # Optimizers\n",
    "        encoder_optimizer = torch.optim.SGD(encoder_parameters, lr=learning_rate)\n",
    "        decoder_optimizer = torch.optim.SGD(decoder_parameters, lr=learning_rate)\n",
    "        print('')\n",
    "        print('learning rate: %f' % learning_rate)\n",
    "        print('')\n",
    "        \n",
    "    generator = BatchGenerator(batch_size, train_df[:64]) #64\n",
    "\n",
    "    while True:\n",
    "        try: \n",
    "            batch = generator.get_batch()\n",
    "        except StopIteration: break\n",
    "        loss = train_model(batch)\n",
    "        \n",
    "        if iteration % 2 == 0:\n",
    "            print('Average minibatch loss at step %d: %.3f' % (iteration, loss))\n",
    "            writer.add_scalar('train_loss', loss, iteration)\n",
    "            writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "        \n",
    "        \"\"\"if iteration % 8 == 0:    \n",
    "            encoder.eval()\n",
    "            decoder.eval()\n",
    "            val_loss = validation_loss(val_df[:8]) # truncating validation dataframe\n",
    "            print('Validation loss: %.3f' % val_loss)\n",
    "            \n",
    "            writer.add_scalar('valid_loss', val_loss, iteration)\n",
    "            writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "            \n",
    "            encoder.train()\n",
    "            decoder.train()\"\"\"\n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.save(encoder.state_dict(), 'encoder')\n",
    "torch.save(decoder.state_dict(), 'decoder')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
